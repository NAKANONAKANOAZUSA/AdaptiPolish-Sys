"""
train_pointnet.py (improved)

æ”¹è¿›ç‚¹ï¼š
1) ç±»æ„ŸçŸ¥é‡‡æ ·ï¼šé‡‡æ ·4096ç‚¹æ—¶ï¼Œä¼˜å…ˆä¿ç•™ç‘•ç–µç‚¹ï¼ˆç±»2ï¼‰ï¼Œå†éšæœºè¡¥é½ã€‚
2) ç±»æƒé‡æ”¹ä¸º sqrt(1/count) + clampï¼Œé¿å…æƒé‡æžç«¯ä¸ç¨³å®šã€‚
"""

import os
import time
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from dianyun.cse.pointcloud_project.src.dataset_pointcloud import PointCloudDataset
from dianyun.cse.pointcloud_project.src.model_pointnet import SimplePointNetSeg


def compute_class_weights(dataset, num_classes=3, max_ratio=10.0):
    """
    æ”¹è¿›ç‰ˆç±»åˆ«æƒé‡ï¼š
      w = 1/sqrt(count)
      å†å½’ä¸€åŒ–åˆ°å‡å€¼=1
      å† clamp æœ€å¤§æƒé‡å€æ•°ï¼Œé¿å…æžç«¯ä¸ç¨³å®š
    """
    counts = np.zeros(num_classes, dtype=np.float64)

    print("\nðŸ”¢ æ­£åœ¨ç»Ÿè®¡æ•´ä¸ªæ•°æ®é›†ä¸­å„ç±»åˆ«çš„ç‚¹æ•°...")
    for idx in range(len(dataset)):
        _, label = dataset[idx]
        label_np = label.numpy()
        for c in range(num_classes):
            counts[c] += (label_np == c).sum()

    print("ðŸ“Š å„ç±»åˆ«ç‚¹æ•°ç»Ÿè®¡ï¼š")
    for c in range(num_classes):
        print(f"  ç±» {c}: {int(counts[c])} ä¸ªç‚¹")

    # sqrt inverse frequency
    class_weights = 1.0 / np.sqrt(counts + 1e-6)
    class_weights = class_weights / class_weights.mean()

    # clamp to avoid huge ratios
    class_weights = np.clip(class_weights, 1.0 / max_ratio, max_ratio)

    print("\nâš– æ”¹è¿›åŽçš„ç±»åˆ«æƒé‡ï¼ˆsqrté€†é¢‘çŽ‡ + clampï¼‰ï¼š")
    for c in range(num_classes):
        print(f"  ç±» {c}: {class_weights[c]:.4f}")

    return torch.tensor(class_weights, dtype=torch.float32)


def class_aware_sample(xyz, label, num_points=4096, defect_class=2):
    """
    ç±»æ„ŸçŸ¥é‡‡æ ·ï¼š
    - ä¼˜å…ˆæŠŠ defect_class çš„ç‚¹å…¨é€‰è¿›æ¥ï¼ˆå¦‚æžœè¶…è¿‡ num_points å°±éšæœºæˆªæ–­ï¼‰
    - å‰©ä¸‹çš„ç‚¹å†ä»Žéž defect ä¸­éšæœºè¡¥é½
    """
    xyz_np = xyz.cpu().numpy()
    label_np = label.cpu().numpy()

    defect_idx = np.where(label_np == defect_class)[0]
    other_idx  = np.where(label_np != defect_class)[0]

    if len(defect_idx) >= num_points:
        chosen_defect = np.random.choice(defect_idx, num_points, replace=False)
        final_idx = chosen_defect
    else:
        # å…ˆæ”¾å…¨éƒ¨ç‘•ç–µç‚¹
        need = num_points - len(defect_idx)
        chosen_other = np.random.choice(other_idx, need, replace=(len(other_idx) < need))
        final_idx = np.concatenate([defect_idx, chosen_other])

    np.random.shuffle(final_idx)

    xyz_s = torch.from_numpy(xyz_np[final_idx]).to(xyz.device)
    label_s = torch.from_numpy(label_np[final_idx]).to(label.device)
    return xyz_s, label_s


def train():
    # -------- é…ç½® --------
    data_root = r"C:\Users\SRIT\Desktop\ai\5\pointcloud_project\data\train"
    checkpoint_dir = r"C:\Users\SRIT\Desktop\ai\5\pointcloud_project\checkpoints"
    os.makedirs(checkpoint_dir, exist_ok=True)

    num_points = 4096
    num_classes = 3
    batch_size = 2
    num_epochs = 30
    learning_rate = 1e-3

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("å½“å‰è®¾å¤‡:", device)

    # -------- Dataset & Loader --------
    dataset = PointCloudDataset(data_root=data_root, num_points=num_points)

    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=True
    )

    # -------- ç±»æƒé‡ --------
    class_weights = compute_class_weights(dataset, num_classes=num_classes).to(device)

    # -------- æ¨¡åž‹/ä¼˜åŒ–å™¨/loss --------
    model = SimplePointNetSeg(num_classes=num_classes).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    criterion = nn.CrossEntropyLoss(weight=class_weights)

    print("\nâœ… å¼€å§‹è®­ç»ƒï¼ˆå¸¦ç‘•ç–µå¢žå¼ºé‡‡æ ·ï¼‰...\n")

    best_loss = float("inf")
    best_model_path = os.path.join(checkpoint_dir, "pointnet_seg_best.pth")

    for epoch in range(1, num_epochs + 1):
        model.train()
        epoch_loss = 0.0
        total_points = 0
        correct_points = 0

        start_time = time.time()

        for batch_idx, (xyz, label) in enumerate(dataloader):
            xyz = xyz.to(device)     # (B,N,3)
            label = label.to(device) # (B,N)

            # --- ç±»æ„ŸçŸ¥é‡‡æ ·ï¼šå¯¹ batch å†…æ¯ä¸ªæ ·æœ¬å•ç‹¬å¢žå¼º ---
            xyz_list = []
            label_list = []
            for b in range(xyz.shape[0]):
                xyz_s, label_s = class_aware_sample(xyz[b], label[b], num_points=num_points, defect_class=2)
                xyz_list.append(xyz_s)
                label_list.append(label_s)

            xyz = torch.stack(xyz_list, dim=0)       # (B,4096,3)
            label = torch.stack(label_list, dim=0)   # (B,4096)

            xyz_transposed = xyz.transpose(1, 2)     # (B,3,4096)

            pred = model(xyz_transposed)             # (B,4096,3)

            B, N, C = pred.shape
            pred_2d = pred.reshape(B * N, C)
            label_1d = label.reshape(B * N)

            loss = criterion(pred_2d, label_1d)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()
            total_points += B * N

            with torch.no_grad():
                pred_labels = pred.argmax(dim=-1)
                correct_points += (pred_labels == label).sum().item()

            if (batch_idx + 1) % 10 == 0:
                print(f"  [Epoch {epoch:03d}] Batch {batch_idx+1:03d} | Loss: {loss.item():.4f}")

        avg_loss = epoch_loss / len(dataloader)
        acc = correct_points / total_points

        elapsed = time.time() - start_time
        print(f"\nðŸ“Ž Epoch {epoch:03d}/{num_epochs} å®Œæˆ | "
              f"å¹³å‡ Loss: {avg_loss:.4f} | ç‚¹çº§ç²¾åº¦: {acc*100:.2f}% | "
              f"ç”¨æ—¶: {elapsed:.1f} ç§’")

        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(model.state_dict(), best_model_path)
            print(f"ðŸ’¾ å·²ä¿å­˜å½“å‰æœ€ä¼˜æ¨¡åž‹åˆ°: {best_model_path}\n")
        else:
            print("ï¼ˆæœ¬è½®æ²¡æœ‰è¶…è¶Šæœ€ä¼˜æ¨¡åž‹ï¼‰\n")

    print("ðŸŽ‰ è®­ç»ƒç»“æŸï¼")
    print(f"æœ€ä¼˜å¹³å‡ Loss: {best_loss:.4f}")
    print(f"æœ€ä¼˜æ¨¡åž‹å·²ä¿å­˜åœ¨: {best_model_path}")


if __name__ == "__main__":
    train()
