import asyncio
import os
import socket
import re
import time
import json
import math
import threading
import cv2
import cn2an
import numpy as np

from pypinyin import lazy_pinyin, Style
from PyQt5.QtWidgets import (QApplication, QWidget, QVBoxLayout, QHBoxLayout,
                             QLabel, QLineEdit, QPushButton, QGroupBox,
                             QListWidget, QListWidgetItem, QAbstractItemView,
                             QMessageBox, QInputDialog, QProgressBar,
                             QComboBox, QSlider, QGridLayout,
                             QMainWindow, QFileDialog, QSplitter, QFrame, QCheckBox, QScrollArea)
from PyQt5.QtCore import Qt, QTimer
from PyQt5.QtGui import QFont, QColor, QBrush, QImage, QPixmap, QIcon, QDoubleValidator, QIntValidator
from hardware.robot_basic import RobotConnection
from hardware.motor import MotorController
from vision.ONNXDetectionThread import ONNXDetectionThread
from vision.camera_thread import CameraThread
from vision.contour_manager import FixedContourManager
from vision.CameraDetectionSystem import CameraDetectionSystem
from audio.audio_server import AudioServerThread
from audio.audio_system import AudioSystem
from audio.MicrophoneCalibrator import MicrophoneCalibrator
from audio.RecordingThread import RecordingThread
from UI.manual_control_dialog import MotorControlDialog
from UI.UART.lib.TOF_Sense import TOF_Sense
from UI.ManualControlDialog import ManualControlDialog
from UI.ThreadPoolManager import  ThreadPoolManager
from Polish.MyCobotGrindingController import MyCobotGrindingController

class RobotControlUI(QMainWindow):
    """æœºå™¨äººæ§åˆ¶ä¸»ç•Œé¢"""
    def __init__(self, config):
        super().__init__()
        self.config = config
        # self.audio_server = AudioServerThread(config=config,parent=self)
        self.audio_system = AudioSystem(config=config)
        # self.motor = MotorController()
        # self.robot_basic = RobotConnection(config=config,port=None,ip=None)
        # self.manual_control_dialog = MotorControlDialog()
        self.camera_thread = CameraThread(config=config)
        # self.contour_manager = FixedContourManager(config=config)
        # self.ONNXDetectionThread = ONNXDetectionThread(config=config,ip='0.0.0.0', port=9999)
        self.CameraDetectionSystem = CameraDetectionSystem(config=config,server_ip='0.0.0.0', server_port=9999)
        self.grinding_controller = None
        self.current_grinding_task_id = None
        # åˆ›å»ºçº¿ç¨‹æ± ç®¡ç†å™¨
        self.thread_pool = ThreadPoolManager(max_workers=5)
        self.thread_pool.task_completed.connect(self.handle_task_completed)
        self.thread_pool.task_failed.connect(self.handle_task_failed)

        # ä»»åŠ¡IDæ˜ å°„ï¼Œç”¨äºè·Ÿè¸ªç‰¹å®šç±»å‹çš„ä»»åŠ¡
        self.task_ids = {
            'camera': None,
            'detection': None,
            'audio': None,
            'motion': None,
            'calibration': None,
            'grinding': None
        }

        # ===== çª—å£è®¾ç½® =====
        self.setWindowTitle("æœºå™¨äººæ§åˆ¶ç³»ç»Ÿ")       # è®¾ç½®çª—å£æ ‡é¢˜
        self.setGeometry(100, 100, 1200, 800)      # è®¾ç½®çª—å£ä½ç½®å’Œå¤§å°
        self.setMinimumSize(800, 600)              # è®¾ç½®æœ€å°çª—å£å°ºå¯¸
        self.setWindowIcon(QIcon("Icon.ico"))      # è®¾ç½®çª—å£å›¾æ ‡

        # ===== æ‰§è¡Œæ§åˆ¶ç›¸å…³ =====
        self.execution_paused = False              # æ‰§è¡Œæš‚åœæ ‡å¿—
        self.execution_stopped = False             # æ‰§è¡Œåœæ­¢æ ‡å¿—
        self.execution_thread = None               # æ‰§è¡Œçº¿ç¨‹
        self.execution_progress = 0                # æ‰§è¡Œè¿›åº¦
        self.verification_enabled = True           # ä½ç½®éªŒè¯å¯ç”¨æ ‡å¿—
        self.angle_tolerance = 3.0                 # è§’åº¦å®¹å·®ï¼ˆåº¦ï¼‰
        self.coord_tolerance = 5.0                 # åæ ‡å®¹å·®ï¼ˆæ¯«ç±³ï¼‰

        # ===== æ£€æµ‹ä¸æ‰“ç£¨å‚æ•° =====
        self.detection_thread = None               # ç›®æ ‡æ£€æµ‹çº¿ç¨‹
        self.detection_active = False              # æ£€æµ‹æ´»åŠ¨çŠ¶æ€
        self.grinding_loops = 1                    # æ‰“ç£¨å¾ªç¯æ¬¡æ•°
        self.grinding_x_step = 0.0                 # Xæ–¹å‘è¿›æ·±ï¼ˆæ¯«ç±³ï¼‰
        self.grinding_y_step = 0.0                 # Yæ–¹å‘è¿›æ·±ï¼ˆæ¯«ç±³ï¼‰
        self.grinding_z_step = 0.0                 # Zæ–¹å‘è¿›æ·±ï¼ˆæ¯«ç±³ï¼‰
        self.path_scale_factor_X = 1.0             # è·¯å¾„ç¼©æ”¾æ¯”ä¾‹X
        self.path_scale_factor_Y = 1.0             # è·¯å¾„ç¼©æ”¾æ¯”ä¾‹Y
        self.grinding_current_loop = 0             # å½“å‰æ‰“ç£¨å¾ªç¯æ¬¡æ•°
        self.base_distance = 245                   # åŸºå‡†è·ç¦»245mm
        self.base_scale_x = 0.67                 # åŸºå‡†Xç¼©æ”¾
        self.base_scale_y = 0.55                   # åŸºå‡†Yç¼©æ”¾
        self.current_distance = 245                # å½“å‰è·ç¦»ï¼ˆé»˜è®¤åŸºå‡†å€¼ï¼‰

        self.history_paths = []                    # å­˜å‚¨å†å²è·¯å¾„
        self.current_history_path = None           # å½“å‰é€‰æ‹©çš„å†å²è·¯å¾„
        self.use_history_path = False              # æ˜¯å¦ä½¿ç”¨å†å²è·¯å¾„çš„æ ‡å¿—
        self.coordinate_rotation = 270

        # ===== ç¤ºæ•™ç‚¹ç®¡ç† =====
        self.teach_points = []                     # å­˜å‚¨ç¤ºæ•™ç‚¹åˆ—è¡¨
        self.current_point = None                  # å½“å‰é€‰ä¸­çš„ç¤ºæ•™ç‚¹
        self.last_executed_point = None            # æœ€åæ‰§è¡Œçš„ç¤ºæ•™ç‚¹
        self.load_teach_points()                   # åŠ è½½ä¿å­˜çš„ç¤ºæ•™ç‚¹

        # ===== æ‘„åƒå¤´ä¸æ¨¡å‹ =====
        self.camera_type = "local"                 # æ‘„åƒå¤´ç±»å‹ï¼ˆlocal/networkï¼‰
        self.onnx_model_path = ""                  # ONNXæ¨¡å‹è·¯å¾„

        # è¯­éŸ³è¯†åˆ«ç›¸å…³
        self.microphone_btn = None
        self.mic_status_label = None
        self.speech_recognition_btn = None
        self.calibration_recognition_btn = None
        self.load_calibration_recognition_btn= None
        self.speech_recognition_active = False  # è¯­éŸ³è¯†åˆ«æ¿€æ´»çŠ¶æ€
        self.recording_thread = None
        self.is_recording = False
        self.audio_threshold = 0.02  # é»˜è®¤é˜ˆå€¼
        self.background_level = 0.01  # èƒŒæ™¯å™ªéŸ³æ°´å¹³
        self.speech_level = 0.05     # æ­£å¸¸è¯´è¯æ°´å¹³
        self.calibrator = None        # éº¦å…‹é£æ ¡å‡†å™¨

        # å”¤é†’è¯ç›¸å…³çŠ¶æ€
        self.wake_word = "å°æ™º"  # å”¤é†’è¯
        self.is_waiting_for_wake_word = False  # æ˜¯å¦åœ¨ç­‰å¾…å”¤é†’è¯
        self.is_in_command_mode = False  # æ˜¯å¦åœ¨æŒ‡ä»¤æ¨¡å¼
        self.wake_word_detected = False  # æ˜¯å¦æ£€æµ‹åˆ°å”¤é†’è¯

        # å®šæ—¶å™¨ç”¨äºæ§åˆ¶å½•éŸ³æ—¶é•¿
        self.recording_timer = QTimer(self)
        self.recording_timer.timeout.connect(self.stop_recording_for_processing)

        # å”¤é†’è¯æ£€æµ‹çº¿ç¨‹
        self.wake_word_thread = None

        # åˆå§‹åŒ–UI
        self.init_ui()                             # åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢




        # ===== æœºå™¨äººè¿æ¥ä¸çŠ¶æ€ =====
        self.connection = None                     # æœºå™¨äººè¿æ¥å¯¹è±¡
        self.mc = None                             # æœºå™¨äººæ§åˆ¶å¯¹è±¡
        self.update_ui_state(False)                # åˆå§‹åŒ–UIçŠ¶æ€

        # ===== ç”¨æˆ·åç§»é‡ =====
        self.user_offset_x = 0                     # ç”¨æˆ·è‡ªå®šä¹‰Xåç§»é‡
        self.user_offset_y = 0                     # ç”¨æˆ·è‡ªå®šä¹‰Yåç§»é‡
        self.user_offset_z = 0                     # ç”¨æˆ·è‡ªå®šä¹‰Zåç§»é‡

        # ===== éŸ³é¢‘ä¸è¯­éŸ³è¯†åˆ« =====
        self.audio_thread = None                   # éŸ³é¢‘å¤„ç†çº¿ç¨‹
        self.speech_recognition_active = False     # è¯­éŸ³è¯†åˆ«æ¿€æ´»çŠ¶æ€

        # from llm import LlmModel
        # self.llm_model = LlmModel()
        self.llm_model = None
        #
        # from asr import AsrModel
        # self.asr_model = AsrModel()  # è¯­éŸ³è¯†åˆ«æ¨¡å‹
        self.asr_model = None
        # # åˆ›å»ºTTSæ¨¡å‹å®ä¾‹
        # from tts import TtsModel
        # self.tts_model = TtsModel()
        self.tts_model = None

        # self.audio_system = AudioSystem(self.tts_model)
        self.wait_for_audio_preload()
        self.speak_response("ç³»ç»Ÿå‡†å¤‡å°±ç»ª")
        self.speak_response("å°æ™ºå·²å¯åŠ¨")
        # ===== å…¶ä»–ç»„ä»¶ =====
        self.motor_dialog = MotorControlDialog()   # ç”µæœºæ§åˆ¶å¯¹è¯æ¡†
        self.motor_controller = MotorController()  # ç”µæœºæ§åˆ¶å™¨å¯¹è±¡



    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        # è®¾ç½®å…¨å±€æ ·å¼
        self.setStyleSheet("""
            QMainWindow {
                background-color: #0F0F0F;
                color: #E0E0E0;
            }
            QGroupBox {
                background-color: #252526;
                color: #E6E6E6;
                border: 1px solid #404040;
                border-radius: 6px;
                margin-top: 10px;
                padding-top: 15px;
                padding-bottom: 15px;
                font-weight: 500;
                font-size: 10pt;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px;
                color: #A0A0A0;
            }
            QLabel {
                color: #A0A0A0;
                font-size: 9pt;
            }
            QPushButton {
                background-color: #007ACC;
                color: #FFFFFF;
                border: 1px solid #005B9F;
                border-radius: 4px;
                padding: 7px 14px;
                font-weight: 500;
                font-size: 9pt;
            }
            QPushButton:hover {
                background-color: #1E90FF;
                border: 1px solid #007ACC;
            }
            QPushButton:pressed {
                background-color: #005B9F;
                border: 1px solid #004080;
            }
            QPushButton:disabled {
                background-color: #3F3F46;
                color: #707070;
                border: 1px solid #333333;
            }
            QLineEdit {
                background-color: #2D2D2D;
                border: 1px solid #404040;
                border-radius: 4px;
                padding: 6px 8px;
                color: #E6E6E6;
                font-size: 9pt;
                selection-background-color: #007ACC;
            }
            QListWidget {
                background-color: #2D2D2D;
                border: 1px solid #404040;
                border-radius: 4px;
                color: #E6E6E6;
                font-size: 9pt;
            }
            QListWidget::item {
                padding: 8px;
                border-bottom: 1px solid #404040;
            }
            QListWidget::item:selected {
                background-color: #007ACC;
                color: white;
                border: none;
            }
            QProgressBar {
                border: 1px solid #404040;
                border-radius: 4px;
                text-align: center;
                background-color: #2D2D2D;
                font-size: 9pt;
            }
            QProgressBar::chunk {
                background-color: #007ACC;
                border-radius: 4px;
            }
            QComboBox {
                background-color: #3C3C40;
                border: 1px solid #555555;
                border-radius: 4px;
                padding: 6px 10px;
                color: #E0E0E0;
                font-size: 10pt;
                selection-background-color: #007ACC;
                min-height: 30px;
            }
            QComboBox:hover {
                border: 1px solid #707070;
            }
            QComboBox::drop-down {
                subcontrol-origin: padding;
                subcontrol-position: top right;
                width: 25px;
                border-left: 1px solid #555555;
            }
            QComboBox::down-arrow {
                image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1MTIgNTEyIj48cGF0aCBmaWxsPSIjQTBBMEEwIiBkPSJNMTQ4LjggMTQ0Yy02LjQgNi40LTYuNCAxNi44IDAgMjMuMmwxMzYgMTM2YzYuNCA2LjQgMTYuOCA2LjQgMjMuMiAwbDEzNi0xMzZjNi40LTYuNCA2LjQtMTYuOCAwLTIzLjJzLTE2LjgtNi40LTIzLjIgMEwyODggMjQ3LjIgMTcyIDE0NGMtNi40LTYuNC0xNi44LTYuNC0yMy4yIDB6Ii8+PC9zdmc+);
                width: 12px;
                height: 12px;
            }
            QComboBox QAbstractItemView {
                background-color: #3C3C40;
                border: 1px solid #555555;
                color: #E0E0E0;
                selection-background-color: #007ACC;
                selection-color: white;
                outline: none;
            }
            QComboBox QAbstractItemView::item {
                padding: 8px;
                border-bottom: 1px solid #404040;
            }
            QComboBox QAbstractItemView::item:selected {
                background-color: #007ACC;
                color: white;
                border: none;
            }
            QSlider {
                padding: 0px;
                margin: 0px;
            }
            QSlider::groove:horizontal {
                background: #404040;     
                height: 6px;               
                border-radius: 3px;         
                margin: 0 8px;             
            }
            QSlider::sub-page:horizontal {
                background: #007ACC;       
                border-radius: 3px;         
            }    
            QSlider::handle:horizontal {
                background: #007ACC;     
                border: 1px solid #005B9F; 
                width: 16px;              
                height: 16px;             
                border-radius: 8px;        
                margin: -5px 0;            
            }
            QSlider::handle:horizontal:hover {
                background: #1C97EA;      
                border: 1px solid #007ACC; 
                width: 18px;                
                height: 18px;               
                margin: -6px 0;           
            }
            QSlider::handle:horizontal:pressed {
                background: #005B9F;        
                border: 1px solid #004080;  
            }  
            QSlider::groove:vertical {
                background: #404040;     
                width: 6px;               
                border-radius: 3px;       
                margin: 8px 0;            
            }
            QSlider::sub-page:vertical {
                background: #007ACC;       
                border-radius: 3px;        
            }
            QSlider::handle:vertical {
                background: #007ACC;       
                border: 1px solid #005B9F;  
                width: 16px;               
                height: 16px;             
                border-radius: 8px;        
                margin: 0 -5px;           
            }
            QSlider::handle:vertical:hover {
                background: #1C97EA;      
                border: 1px solid #007ACC;  
                width: 18px;                
                height: 18px;             
                margin: 0 -6px;             
            }
            QSlider::handle:vertical:pressed {
                background: #005B9F;       
                border: 1px solid #004080; 
            }
            QScrollArea {
                background-color: transparent;   
                border: 0px  
            }
            QScrollArea::viewport {
                background-color: #0F0F0F;
            }
            QScrollArea > QWidget > QWidget {
                background-color: #0F0F0F;
            }
            QScrollBar:vertical {
                background: transparent;       
                width: 0px;

            }

            QScrollBar::handle:vertical {
                background: transparent;       

            }

            QScrollBar::handle:vertical:hover {
                background: transparent;        
            }


            QScrollBar:horizontal {
                background: transparent;        
                height: 0px;
            }

            QScrollBar::handle:horizontal {
                background: transparent;        
            }

            QScrollBar::handle:horizontal:hover {
                background: #303030;        
            }

            QScrollBar::add-line:horizontal, 
            QScrollBar::sub-line:horizontal {
                background: none;
                width: 0px;
            }
            QSplitter::handle {
                background-color: #404040;
            }
            QCheckBox {
                color: #A0A0A0;
                font-size: 9pt;
                spacing: 5px;
            }
            QCheckBox::indicator {
                width: 16px;
                height: 16px;
                border: 1px solid #555555;
                border-radius: 3px;
                background: #2D2D2D;
            }
            QCheckBox::indicator:checked {
                background: #007ACC;
                border: 1px solid #007ACC;
            }
            QCheckBox::indicator:unchecked:hover {
                border: 1px solid #707070;
            }
            QTabWidget::pane {
                border: 1px solid #404040;
                background: #252526;
            }
            QTabBar::tab {
                background: #2D2D2D;
                color: #A0A0A0;
                border: 1px solid #404040;
                border-bottom: none;
                padding: 5px 10px;
            }
            QTabBar::tab:selected {
                background: #252526;
                color: #E6E6E6;
                border-bottom: 2px solid #007ACC;
            }
            #cameraContainer, #centerContainer, #rightContainer {
                border: 1px solid #404040;
                border-radius: 4px;
            }
        """)


        # ä¸»çª—å£è®¾ç½®
        self.setWindowTitle("æœºå™¨äººæ§åˆ¶ç³»ç»Ÿ")
        self.setGeometry(100, 100, 1280, 800)
        self.setMinimumSize(1000, 700)

        # åˆ›å»ºä¸­å¤®éƒ¨ä»¶å’Œä¸»å¸ƒå±€
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)
        main_layout.setSpacing(10)
        main_layout.setContentsMargins(15, 15, 15, 15)

        # åˆ›å»ºä¸»åˆ†å‰²å™¨
        main_splitter = QSplitter(Qt.Horizontal)

        # === å·¦ä¾§åŒºåŸŸï¼šæ‘„åƒå¤´ç”»é¢ ===
        camera_container = QWidget()
        camera_layout = QVBoxLayout(camera_container)
        camera_layout.setContentsMargins(0, 0, 0, 0)
        camera_layout.setSpacing(10)

        # æ‘„åƒå¤´ç”»é¢ç»„
        camera_group = QGroupBox("æ‘„åƒå¤´ç”»é¢")
        camera_group.setMinimumWidth(650)
        camera_group_layout = QVBoxLayout(camera_group)
        camera_group_layout.setContentsMargins(10, 15, 10, 10)

        # æ‘„åƒå¤´æ ‡ç­¾
        self.detection_label = QLabel("æ‘„åƒå¤´æœªå¯åŠ¨")
        self.detection_label.setAlignment(Qt.AlignCenter)
        self.detection_label.setMinimumSize(640, 480)
        self.detection_label.setStyleSheet("""
            background-color: #1E1E1E;
            border: 1px solid #007ACC;
            border-radius: 4px;
        """)
        camera_group_layout.addWidget(self.detection_label)

        # æ‘„åƒå¤´æ§åˆ¶æŒ‰é’®
        cam_control_layout = QHBoxLayout()
        cam_control_layout.setContentsMargins(5, 10, 5, 5)
        self.camera_status_label = QLabel("çŠ¶æ€: æœªè¿æ¥")
        self.camera_status_label.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)

        self.open_camera_btn = QPushButton("å¯åŠ¨æ‘„åƒå¤´")
        self.open_camera_btn.setFixedHeight(40)
        self.open_camera_btn.clicked.connect(self.toggle_camera)

        self.close_camera_btn = QPushButton("å…³é—­æ‘„åƒå¤´")
        self.close_camera_btn.setFixedHeight(40)
        self.close_camera_btn.setEnabled(False)
        self.close_camera_btn.clicked.connect(self.close_camera)

        cam_control_layout.addWidget(self.camera_status_label)
        cam_control_layout.addStretch()
        cam_control_layout.addWidget(self.open_camera_btn)
        cam_control_layout.addWidget(self.close_camera_btn)

        camera_group_layout.addLayout(cam_control_layout)
        camera_layout.addWidget(camera_group)

        # === ä¸­é—´åŒºåŸŸï¼šæ§åˆ¶é¢æ¿ ===
        control_container = QScrollArea()
        control_container.setWidgetResizable(True)
        control_container.setFrameShape(QFrame.NoFrame)

        control_content = QWidget()
        control_layout = QVBoxLayout(control_content)
        control_layout.setContentsMargins(5, 5, 5, 5)
        control_layout.setSpacing(15)

        # ç¤ºæ•™ç‚¹ç®¡ç†ç»„
        teach_group = QGroupBox("ç¤ºæ•™ç‚¹ç®¡ç†")
        teach_layout = QVBoxLayout(teach_group)
        teach_layout.setSpacing(10)

        # ä¿å­˜æ–°ç‚¹åŒºåŸŸ
        save_layout = QHBoxLayout()
        self.teach_name_input = QLineEdit()
        self.teach_name_input.setPlaceholderText("è¾“å…¥ç¤ºæ•™ç‚¹åç§°")
        self.save_teach_button = QPushButton("ä¿å­˜å½“å‰ä½ç½®")
        self.save_teach_button.setFixedHeight(40)
        self.save_teach_button.setEnabled(False)
        self.save_teach_button.clicked.connect(self.save_teach_point)

        save_layout.addWidget(self.teach_name_input, 70)
        save_layout.addWidget(self.save_teach_button, 30)
        teach_layout.addLayout(save_layout)

        # ç¤ºæ•™ç‚¹åˆ—è¡¨
        self.teach_point_list = QListWidget()
        self.teach_point_list.setMinimumHeight(180)
        self.teach_point_list.setSelectionMode(QAbstractItemView.SingleSelection)
        self.teach_point_list.itemDoubleClicked.connect(self.move_to_teach_point)
        self.update_teach_point_list()
        teach_layout.addWidget(self.teach_point_list)

        # æ“ä½œæŒ‰é’®
        point_btns_layout = QHBoxLayout()
        self.move_button = QPushButton("ç§»åŠ¨åˆ°é€‰å®šç‚¹")
        self.move_button.setFixedHeight(40)
        self.move_button.setEnabled(False)
        self.move_button.clicked.connect(self.move_to_selected_point)

        self.delete_button = QPushButton("åˆ é™¤é€‰å®šç‚¹")
        self.delete_button.setFixedHeight(40)
        self.delete_button.clicked.connect(self.delete_selected_point)

        point_btns_layout.addWidget(self.move_button)
        point_btns_layout.addWidget(self.delete_button)
        teach_layout.addLayout(point_btns_layout)

        control_layout.addWidget(teach_group)

        # æ‰“ç£¨æ§åˆ¶ç»„
        grinding_group = QGroupBox("æ‰“ç£¨æ§åˆ¶")
        grinding_layout = QVBoxLayout(grinding_group)
        grinding_layout.setSpacing(10)

        # åæ ‡åç§»è®¾ç½®
        offset_group = QGroupBox("åæ ‡åç§»è®¾ç½®")
        offset_layout = QGridLayout(offset_group)
        offset_layout.setHorizontalSpacing(10)
        offset_layout.setVerticalSpacing(8)

        offset_layout.addWidget(QLabel("Xåç§»(mm):"), 0, 0)
        self.offset_x_input = QLineEdit("0")
        self.offset_x_input.setPlaceholderText("Xåç§»")
        self.offset_x_input.setValidator(QDoubleValidator(-50, 50, 2))
        offset_layout.addWidget(self.offset_x_input, 0, 1)

        offset_layout.addWidget(QLabel("Yåç§»(mm):"), 1, 0)
        self.offset_y_input = QLineEdit("0")
        self.offset_y_input.setPlaceholderText("Yåç§»")
        self.offset_y_input.setValidator(QDoubleValidator(-50, 50, 2))
        offset_layout.addWidget(self.offset_y_input, 1, 1)

        offset_layout.addWidget(QLabel("Zåç§»(mm):"), 2, 0)
        self.offset_z_input = QLineEdit("260")
        self.offset_z_input.setPlaceholderText("Zåç§»")
        self.offset_z_input.setValidator(QDoubleValidator(-50, 50, 2))
        offset_layout.addWidget(self.offset_z_input, 2, 1)

        self.apply_offset_btn = QPushButton("åº”ç”¨åç§»")
        self.apply_offset_btn.setFixedHeight(35)
        self.apply_offset_btn.clicked.connect(self.apply_offsets)
        offset_layout.addWidget(self.apply_offset_btn, 3, 0, 1, 2)

        grinding_layout.addWidget(offset_group)

        # æ‰“ç£¨å‚æ•°è®¾ç½®
        params_group = QGroupBox("æ‰“ç£¨å‚æ•°")
        params_layout = QGridLayout(params_group)
        params_layout.setHorizontalSpacing(10)
        params_layout.setVerticalSpacing(8)

        params_layout.addWidget(QLabel("å¾ªç¯æ¬¡æ•°:"), 0, 0)
        self.loop_count_input = QLineEdit("1")
        self.loop_count_input.setValidator(QIntValidator(1, 100))
        params_layout.addWidget(self.loop_count_input, 0, 1)

        params_layout.addWidget(QLabel("Xè¿›æ·±(mm):"), 1, 0)
        self.x_step_input = QLineEdit("0.0")
        self.x_step_input.setValidator(QDoubleValidator(-10.0, 10.0, 2))
        params_layout.addWidget(self.x_step_input, 1, 1)

        params_layout.addWidget(QLabel("Yè¿›æ·±(mm):"), 2, 0)
        self.y_step_input = QLineEdit("0.0")
        self.y_step_input.setValidator(QDoubleValidator(-10.0, 10.0, 2))
        params_layout.addWidget(self.y_step_input, 2, 1)

        params_layout.addWidget(QLabel("Zè¿›æ·±(mm):"), 3, 0)
        self.z_step_input = QLineEdit("0.0")
        self.z_step_input.setValidator(QDoubleValidator(-10.0, 10.0, 2))
        params_layout.addWidget(self.z_step_input, 3, 1)

        params_layout.addWidget(QLabel("è·¯å¾„ç¼©æ”¾æ¯”ä¾‹X:"), 4, 0)
        self.scale_factor_X_input = QLineEdit("0.6625")
        self.scale_factor_X_input.setValidator(QDoubleValidator(0.1, 10.0, 10))
        params_layout.addWidget(self.scale_factor_X_input, 4, 1)

        params_layout.addWidget(QLabel("è·¯å¾„ç¼©æ”¾æ¯”ä¾‹Y:"), 5, 0)
        self.scale_factor_Y_input = QLineEdit("0.56")
        self.scale_factor_Y_input.setValidator(QDoubleValidator(0.1, 10.0, 10))
        params_layout.addWidget(self.scale_factor_Y_input, 5, 1)

        distance_layout = QHBoxLayout()
        distance_layout.addWidget(QLabel("å½“å‰è·ç¦»(mm):"))
        self.distance_display = QLineEdit("245")
        distance_layout.addWidget(self.distance_display)

        self.update_distance_btn = QPushButton("æ›´æ–°æµ‹è·æ•°æ®")
        self.update_distance_btn.setFixedHeight(35)
        self.update_distance_btn.clicked.connect(self.update_distance_from_sensor)
        distance_layout.addWidget(self.update_distance_btn)
        params_layout.addLayout(distance_layout, 6, 0, 1, 2)

        self.apply_grinding_params_btn = QPushButton("åº”ç”¨å‚æ•°")
        self.apply_grinding_params_btn.setFixedHeight(35)
        self.apply_grinding_params_btn.clicked.connect(self.apply_grinding_params)
        params_layout.addWidget(self.apply_grinding_params_btn, 7, 0, 1, 2)

        grinding_layout.addWidget(params_group)

        # å†å²è·¯å¾„ç®¡ç†
        history_group = QGroupBox("å†å²è·¯å¾„ç®¡ç†")
        history_layout = QVBoxLayout(history_group)
        history_layout.setSpacing(8)

        self.history_list = QListWidget()
        self.history_list.setMinimumHeight(120)
        history_layout.addWidget(self.history_list)

        self.use_history_checkbox = QCheckBox("ä½¿ç”¨å†å²è·¯å¾„ï¼ˆè·³è¿‡æ£€æµ‹ï¼‰")
        self.use_history_checkbox.stateChanged.connect(self.toggle_history_path_usage)
        history_layout.addWidget(self.use_history_checkbox)

        history_btns_layout = QHBoxLayout()
        self.save_path_btn = QPushButton("ä¿å­˜å½“å‰è·¯å¾„")
        self.save_path_btn.setFixedHeight(35)
        self.save_path_btn.clicked.connect(self.save_current_path)

        self.load_path_btn = QPushButton("åŠ è½½å†å²è·¯å¾„")
        self.load_path_btn.setFixedHeight(35)
        self.load_path_btn.clicked.connect(self.load_history_path)

        self.apply_path_btn = QPushButton("åº”ç”¨é€‰ä¸­è·¯å¾„")
        self.apply_path_btn.setFixedHeight(35)
        self.apply_path_btn.clicked.connect(self.apply_history_path)

        history_btns_layout.addWidget(self.save_path_btn)
        history_btns_layout.addWidget(self.load_path_btn)
        history_btns_layout.addWidget(self.apply_path_btn)
        history_layout.addLayout(history_btns_layout)

        grinding_layout.addWidget(history_group)

        # å¯åŠ¨æ‰“ç£¨æŒ‰é’®
        self.grinding_button = QPushButton("å¯åŠ¨æ‰“ç£¨")
        self.grinding_button.setFixedHeight(50)
        self.grinding_button.setFont(QFont("Arial", 12, QFont.Bold))
        self.grinding_button.clicked.connect(self.toggle_grinding)
        grinding_layout.addWidget(self.grinding_button)

        # æ‰“ç£¨çŠ¶æ€æŒ‡ç¤º
        status_layout = QHBoxLayout()
        status_layout.addWidget(QLabel("æ‰“ç£¨çŠ¶æ€:"))

        self.grinding_status_indicator = QLabel()
        self.grinding_status_indicator.setFixedSize(20, 20)
        self.grinding_status_indicator.setStyleSheet("background-color: #505050; border-radius: 10px;")

        status_layout.addWidget(self.grinding_status_indicator)
        status_layout.addStretch()

        self.grinding_progress_label = QLabel("æ‰“ç£¨: æœªè¿è¡Œ")
        status_layout.addWidget(self.grinding_progress_label)

        grinding_layout.addLayout(status_layout)

        control_layout.addWidget(grinding_group)

        # æ‰§è¡Œæ§åˆ¶ç»„
        exec_group = QGroupBox("æ‰§è¡Œæ§åˆ¶")
        exec_layout = QVBoxLayout(exec_group)
        exec_layout.setSpacing(10)

        # XYZç§»åŠ¨æ§åˆ¶
        xyz_group = QGroupBox("XYZåæ ‡ç§»åŠ¨")
        xyz_layout = QGridLayout(xyz_group)
        xyz_layout.setHorizontalSpacing(10)
        xyz_layout.setVerticalSpacing(8)

        xyz_layout.addWidget(QLabel("ç›®æ ‡åæ ‡:"), 0, 0)
        self.target_x_input = QLineEdit()
        self.target_x_input.setPlaceholderText("X")
        xyz_layout.addWidget(self.target_x_input, 0, 1)

        self.target_y_input = QLineEdit()
        self.target_y_input.setPlaceholderText("Y")
        xyz_layout.addWidget(self.target_y_input, 0, 2)

        self.target_z_input = QLineEdit()
        self.target_z_input.setPlaceholderText("Z")
        xyz_layout.addWidget(self.target_z_input, 0, 3)

        self.move_xyz_button = QPushButton("ç§»åŠ¨")
        self.move_xyz_button.setFixedHeight(35)
        self.move_xyz_button.clicked.connect(self.move_to_xyz)
        xyz_layout.addWidget(self.move_xyz_button, 0, 4)

        self.angle_correction_checkbox = QCheckBox("å¯ç”¨è§’åº¦ä¿®æ­£")
        self.angle_correction_checkbox.setChecked(True)
        xyz_layout.addWidget(self.angle_correction_checkbox, 1, 0, 1, 5)

        exec_layout.addWidget(xyz_group)

        # æ‰§è¡Œé€‰é¡¹
        options_layout = QGridLayout()
        options_layout.setHorizontalSpacing(10)
        options_layout.setVerticalSpacing(8)

        options_layout.addWidget(QLabel("è¿åŠ¨ç±»å‹:"), 0, 0)
        self.move_type_combo = QComboBox()
        self.move_type_combo.addItems(["å…³èŠ‚è¿åŠ¨ (MOVEJ)", "ç›´çº¿è¿åŠ¨ (MOVEL)"])
        options_layout.addWidget(self.move_type_combo, 0, 1, 1, 2)

        options_layout.addWidget(QLabel("é€Ÿåº¦:"), 1, 0)
        self.speed_slider = QSlider(Qt.Horizontal)
        self.speed_slider.setRange(1, 100)
        self.speed_slider.setValue(50)
        options_layout.addWidget(self.speed_slider, 1, 1)

        self.speed_label = QLabel("é€Ÿåº¦: 50")
        options_layout.addWidget(self.speed_label, 1, 2)

        exec_layout.addLayout(options_layout)

        # æ‰§è¡ŒæŒ‰é’®
        execute_layout = QHBoxLayout()
        self.execute_all_button = QPushButton("æ‰§è¡Œæ‰€æœ‰ç‚¹")
        self.execute_all_button.setFixedHeight(40)
        self.execute_all_button.clicked.connect(self.execute_all_points)

        self.execute_selected_button = QPushButton("æ‰§è¡Œé€‰å®šç‚¹")
        self.execute_selected_button.setFixedHeight(40)
        self.execute_selected_button.clicked.connect(self.execute_selected_point)

        execute_layout.addWidget(self.execute_all_button)
        execute_layout.addWidget(self.execute_selected_button)
        exec_layout.addLayout(execute_layout)

        # æ§åˆ¶æŒ‰é’®
        control_btns_layout = QHBoxLayout()
        self.pause_button = QPushButton("æš‚åœ")
        self.pause_button.setFixedHeight(40)
        self.pause_button.clicked.connect(self.pause_execution)

        self.resume_button = QPushButton("æ¢å¤")
        self.resume_button.setFixedHeight(40)
        self.resume_button.clicked.connect(self.resume_execution)

        self.stop_button = QPushButton("åœæ­¢")
        self.stop_button.setFixedHeight(40)
        self.stop_button.clicked.connect(self.stop_execution)

        control_btns_layout.addWidget(self.pause_button)
        control_btns_layout.addWidget(self.resume_button)
        control_btns_layout.addWidget(self.stop_button)
        exec_layout.addLayout(control_btns_layout)

        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        exec_layout.addWidget(self.progress_bar)

        control_layout.addWidget(exec_group)

        # è®¾ç½®æ§åˆ¶å†…å®¹
        control_container.setWidget(control_content)

        # === å³ä¾§åŒºåŸŸï¼šè¿æ¥è®¾ç½® ===
        right_container = QScrollArea()
        right_container.setWidgetResizable(True)
        right_container.setFrameShape(QFrame.NoFrame)

        right_content = QWidget()
        right_layout = QVBoxLayout(right_content)
        right_layout.setContentsMargins(5, 5, 5, 5)
        right_layout.setSpacing(15)

        # æ‘„åƒå¤´è®¾ç½®ç»„
        camera_setting_group = QGroupBox("æ‘„åƒå¤´è®¾ç½®")
        camera_setting_layout = QVBoxLayout(camera_setting_group)
        camera_setting_layout.setSpacing(10)

        # æ‘„åƒå¤´ç±»å‹é€‰æ‹©
        cam_type_layout = QHBoxLayout()
        cam_type_layout.addWidget(QLabel("æ‘„åƒå¤´ç±»å‹:"))
        self.camera_type_combo = QComboBox()
        self.camera_type_combo.addItems(["æœ¬åœ°æ‘„åƒå¤´", "ç½‘ç»œæ‘„åƒå¤´"])
        self.camera_type_combo.currentIndexChanged.connect(self.change_camera_type)
        cam_type_layout.addWidget(self.camera_type_combo, 1)
        camera_setting_layout.addLayout(cam_type_layout)

        # IPåœ°å€è¾“å…¥
        ip_layout = QHBoxLayout()
        ip_layout.addWidget(QLabel("IPåœ°å€:"))
        self.camera_ip_input = QLineEdit("0.0.0.0")
        ip_layout.addWidget(self.camera_ip_input, 1)
        camera_setting_layout.addLayout(ip_layout)

        # ç«¯å£è¾“å…¥
        port_layout = QHBoxLayout()
        port_layout.addWidget(QLabel("ç«¯å£:"))
        self.camera_port_input = QLineEdit("9999")
        port_layout.addWidget(self.camera_port_input, 1)
        camera_setting_layout.addLayout(port_layout)

        # æ¨¡å‹é€‰æ‹©
        model_layout = QHBoxLayout()
        model_layout.addWidget(QLabel("ONNXæ¨¡å‹:"))
        self.onnx_model_path_input = QLineEdit()
        self.onnx_model_path_input.setPlaceholderText("é€‰æ‹©ONNXæ¨¡å‹æ–‡ä»¶")
        model_layout.addWidget(self.onnx_model_path_input, 1)

        self.load_model_btn = QPushButton("åŠ è½½")
        self.load_model_btn.setFixedHeight(30)
        self.load_model_btn.clicked.connect(self.load_onnx_model)
        model_layout.addWidget(self.load_model_btn)
        camera_setting_layout.addLayout(model_layout)

        # æ ‡å®šæŒ‰é’®
        calibration_layout = QHBoxLayout()
        self.calibrate_button = QPushButton("æ ‡å®š")
        self.calibrate_button.setFixedHeight(40)
        self.calibrate_button.clicked.connect(self.start_calibration)

        self.single_image_calibrate_btn = QPushButton("å›¾åƒæ ‡å®š")
        self.single_image_calibrate_btn.setFixedHeight(40)
        self.single_image_calibrate_btn.clicked.connect(self.calibrate_single_image)

        calibration_layout.addWidget(self.calibrate_button)
        calibration_layout.addWidget(self.single_image_calibrate_btn)
        camera_setting_layout.addLayout(calibration_layout)

        # ç‚¹äº‘
        point_cloud_group = QGroupBox("ç‚¹äº‘æ¨¡å‹")
        point_cloud_layout = QVBoxLayout(point_cloud_group)


        #å–ç‚¹äº‘æ•°æ®æŒ‰é’®
        self.get_3d_coordinates_btn = QPushButton("è·å–ç‚¹äº‘æ•°æ®")
        self.get_3d_coordinates_btn.setFixedHeight(40)
        self.get_3d_coordinates_btn.clicked.connect(self.get_3d_coordinates)  # è¿æ¥æ–¹æ³•
        point_cloud_layout.addWidget(self.get_3d_coordinates_btn)

        self.point_cloud_btn = QPushButton("ç‚¹äº‘é…ç½®")
        self.point_cloud_btn.setFixedHeight(40)
        self.point_cloud_btn.clicked.connect(self.open_point_cloud_config)

        point_cloud_layout.addWidget(self.point_cloud_btn)
        right_layout.addWidget(point_cloud_group)

        # æ ‡å®šæ–‡ä»¶æ“ä½œ
        calib_file_layout = QHBoxLayout()
        self.load_calibration_recognition_btn = QPushButton("åŠ è½½æ ‡å®š")
        self.load_calibration_recognition_btn.setFixedHeight(40)
        self.load_calibration_recognition_btn.clicked.connect(self.load_calibration_file)

        self.save_calibration_recognition_btn = QPushButton("ä¿å­˜æ ‡å®š")
        self.save_calibration_recognition_btn.setFixedHeight(40)
        self.save_calibration_recognition_btn.clicked.connect(self.save_calibration_file)

        calib_file_layout.addWidget(self.load_calibration_recognition_btn)
        calib_file_layout.addWidget(self.save_calibration_recognition_btn)
        camera_setting_layout.addLayout(calib_file_layout)

        right_layout.addWidget(camera_setting_group)

        # æœºå™¨äººè¿æ¥ç»„
        connection_group = QGroupBox("æœºå™¨äººè¿æ¥")
        connection_layout = QVBoxLayout(connection_group)
        connection_layout.setSpacing(10)

        # IPåœ°å€è¾“å…¥
        robot_ip_layout = QHBoxLayout()
        robot_ip_layout.addWidget(QLabel("IPåœ°å€:"))
        self.ip_input = QLineEdit(self.config.ROBOT_IP)
        self.ip_input.setPlaceholderText("192.168.25.185")
        robot_ip_layout.addWidget(self.ip_input, 1)
        connection_layout.addLayout(robot_ip_layout)

        # ç«¯å£è¾“å…¥
        robot_port_layout = QHBoxLayout()
        robot_port_layout.addWidget(QLabel("ç«¯å£å·:"))
        self.port_input = QLineEdit(str(self.config.ROBOT_PORT))
        self.port_input.setPlaceholderText("ä¾‹å¦‚ï¼š8080")
        robot_port_layout.addWidget(self.port_input, 1)
        connection_layout.addLayout(robot_port_layout)

        # è¿æ¥æŒ‰é’®
        self.connect_button = QPushButton("è¿æ¥æœºå™¨äºº")
        self.connect_button.setFixedHeight(45)
        self.connect_button.clicked.connect(self.toggle_connection)
        connection_layout.addWidget(self.connect_button)

        # çŠ¶æ€æŒ‡ç¤ºç¯
        status_layout = QHBoxLayout()
        status_layout.addWidget(QLabel("æœºå™¨äººçŠ¶æ€:"))

        self.status_indicator = QLabel()
        self.status_indicator.setFixedSize(20, 20)
        self.status_indicator.setStyleSheet("background-color: #505050; border-radius: 10px;")

        status_layout.addWidget(self.status_indicator)
        status_layout.addStretch()
        connection_layout.addLayout(status_layout)

        # æ§åˆ¶æŒ‰é’®
        control_btns_layout = QGridLayout()
        control_btns_layout.setHorizontalSpacing(10)
        control_btns_layout.setVerticalSpacing(10)

        self.manual_control_btn = QPushButton("æ‰‹åŠ¨æ§åˆ¶")
        self.manual_control_btn.setFixedHeight(40)
        self.manual_control_btn.clicked.connect(self.open_manual_control)

        self.motor_control_btn = QPushButton("ç”µæœºæ§åˆ¶")
        self.motor_control_btn.setFixedHeight(40)
        self.motor_control_btn.clicked.connect(self.open_motor_control)

        control_btns_layout.addWidget(self.manual_control_btn, 0, 0)
        control_btns_layout.addWidget(self.motor_control_btn, 0, 1)

        connection_layout.addLayout(control_btns_layout)

        right_layout.addWidget(connection_group)

        # è¯­éŸ³æ§åˆ¶ç»„
        recognition_group = QGroupBox("è¯­éŸ³æ§åˆ¶")
        recognition_layout = QVBoxLayout(recognition_group)
        recognition_layout.setSpacing(10)

        self.speech_recognition_btn = QPushButton("å¯åŠ¨è¯­éŸ³è¯†åˆ«")
        self.speech_recognition_btn.setFixedHeight(40)
        self.speech_recognition_btn.clicked.connect(self.toggle_speech_recognition)

        self.calibration_recognition_btn = QPushButton("æ ¡å‡†éº¦å…‹é£")
        self.calibration_recognition_btn.setFixedHeight(40)
        self.calibration_recognition_btn.clicked.connect(self.calibrate_microphone)

        self.load_calibration_recognition_btn = QPushButton("åŠ è½½éº¦å…‹é£æ ¡å‡†é…ç½®")
        self.load_calibration_recognition_btn.setFixedHeight(40)
        self.load_calibration_recognition_btn.clicked.connect(self.load_calibration_settings)

        recognition_layout.addWidget(self.speech_recognition_btn)
        recognition_layout.addWidget(self.calibration_recognition_btn)
        recognition_layout.addWidget(self.load_calibration_recognition_btn)

        right_layout.addWidget(recognition_group)

        # è®¾ç½®å³ä¾§å†…å®¹
        right_container.setWidget(right_content)

        # æ£€æµ‹æŒ‰é’®
        detect_group = QGroupBox("ç›®æ ‡æ£€æµ‹")
        detect_layout = QVBoxLayout(detect_group)

        self.detect_button = QPushButton("å¯åŠ¨æ£€æµ‹")
        self.detect_button.setFixedHeight(40)
        self.detect_button.clicked.connect(self.toggle_detection)

        self.detect_image_btn = QPushButton("æ£€æµ‹å›¾åƒ")
        self.detect_image_btn.setFixedHeight(40)
        self.detect_image_btn.clicked.connect(self.detect_image)

        detect_layout.addWidget(self.detect_button)
        detect_layout.addWidget(self.detect_image_btn)

        right_layout.addWidget(detect_group)

        # === ç»„è£…ä¸»ç•Œé¢ ===
        main_splitter.addWidget(camera_container)
        main_splitter.addWidget(control_container)
        main_splitter.addWidget(right_container)

        # è®¾ç½®åˆ†å‰²å™¨åˆå§‹å¤§å°
        main_splitter.setSizes([650, 500, 300])

        main_layout.addWidget(main_splitter)

        # çŠ¶æ€æ 
        self.status_bar = self.statusBar()
        self.status_label = QLabel("ç³»ç»Ÿå°±ç»ª")
        self.status_bar.addPermanentWidget(self.status_label)

        self.audio_status_label = QLabel("éº¦å…‹é£: æœªè¿æ¥")
        self.status_bar.addPermanentWidget(self.audio_status_label)

        # è¿æ¥ä¿¡å·
        self.speed_slider.valueChanged.connect(self.update_speed_label)



    # ========== TCP æœåŠ¡ç«¯ï¼ˆå¤§é¡¹ç›®ç”¨æ¥æ¥æ”¶ä¿¡å·ï¼‰ ==========
    def start_stop_server(self,host="0.0.0.0", port=50007):
        """
        å¯åŠ¨TCPæœåŠ¡ç«¯ï¼Œæ¥æ”¶å°é¡¹ç›®çš„ STOP ä¿¡å·
        :param host: ç»‘å®šçš„IPåœ°å€ï¼Œé»˜è®¤ç›‘å¬æ‰€æœ‰ç½‘å¡
        :param port: ç›‘å¬çš„ç«¯å£å·ï¼Œéœ€ä¸å°é¡¹ç›®ä¸€è‡´
        """
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:
            server_socket.bind((host, port))
            server_socket.listen(1)
            print(f"ğŸŸ¢ STOP æœåŠ¡ç«¯å·²å¯åŠ¨ï¼Œç­‰å¾…å°é¡¹ç›®è¿æ¥... (ç«¯å£ {port})")

            while True:
                conn, addr = server_socket.accept()
                with conn:
                    print(f"ğŸ“¡ æ¥è‡ª {addr} çš„è¿æ¥")
                    data = conn.recv(1024)
                    if not data:
                        continue
                    message = data.decode("utf-8").strip()
                    if message == "STOP":
                        print("ğŸ›‘ æ”¶åˆ° STOP ä¿¡å·ï¼æ€¥åœæœºå™¨äººï¼")
                        # TODO: åœ¨è¿™é‡Œå†™ä½ çš„å¤„ç†ä»£ç 

    def wait_for_audio_preload(self):
        """ç­‰å¾…éŸ³é¢‘é¢„åŠ è½½å®Œæˆ"""
        while not self.audio_system.preload_complete:
            time.sleep(0.1)
            QApplication.processEvents()  # ä¿æŒUIå“åº”


    def calibrate_microphone(self):
        """å¯åŠ¨éº¦å…‹é£æ ¡å‡†"""
        # å¦‚æœå·²æœ‰æ ¡å‡†åœ¨è¿›è¡Œï¼Œåˆ™å…ˆåœæ­¢
        if self.calibrator and self.calibrator.isRunning():
            self.calibrator.stop_calibration = True
            self.calibrator.wait(1000)

        # åˆ›å»ºæ–°çš„æ ¡å‡†å™¨
        self.calibrator = MicrophoneCalibrator()
        self.calibrator.status_updated.connect(self.update_calibration_status)
        self.calibrator.calibration_done.connect(self.handle_calibration_result)
        self.calibrator.start()
        self.status_label.setText("éº¦å…‹é£æ ¡å‡†å·²å¯åŠ¨...")
        self.speak_response("èƒŒæ™¯å™ªéŸ³æ ¡å‡†ä¸­ï¼Œè¯·ä¿æŒå®‰é™")

    def update_calibration_status(self, message):
        """æ›´æ–°æ ¡å‡†çŠ¶æ€"""
        self.status_label.setText(message)
        print(f"æ ¡å‡†çŠ¶æ€: {message}")

    def handle_calibration_result(self, background, speech, threshold):
        """å¤„ç†æ ¡å‡†ç»“æœ"""
        self.background_level = background
        self.speech_level = speech
        self.audio_threshold = threshold

        self.status_label.setText(f"æ ¡å‡†å®Œæˆ! é˜ˆå€¼={threshold:.4f}")
        print(f"æ ¡å‡†ç»“æœ: èƒŒæ™¯å™ªéŸ³={background:.4f}, è¯´è¯éŸ³é‡={speech:.4f}, é˜ˆå€¼={threshold:.4f}")
        self.speak_response("æ ¡å‡†å®Œæˆï¼Œé˜ˆå€¼å·²è®¾å®š")
        # ä¿å­˜æ ¡å‡†ç»“æœåˆ°é…ç½®æ–‡ä»¶
        self.save_calibration_settings()

    def save_calibration_settings(self):
        """ä¿å­˜æ ¡å‡†è®¾ç½®åˆ°é…ç½®æ–‡ä»¶"""
        settings = {
            'background_level': self.background_level,
            'speech_level': self.speech_level,
            'threshold': self.audio_threshold,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }

        try:
            with open('microphone_calibration.json', 'w') as f:
                json.dump(settings, f, indent=4)
            print("æ ¡å‡†è®¾ç½®å·²ä¿å­˜")
        except Exception as e:
            print(f"ä¿å­˜æ ¡å‡†è®¾ç½®å¤±è´¥: {str(e)}")

    def load_calibration_settings(self):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½æ ¡å‡†è®¾ç½®"""
        try:
            if os.path.exists('microphone_calibration.json'):
                with open('microphone_calibration.json', 'r') as f:
                    settings = json.load(f)

                self.background_level = settings.get('background_level', 0.01)
                self.speech_level = settings.get('speech_level', 0.05)
                self.audio_threshold = settings.get('threshold', 0.02)

                print(f"åŠ è½½æ ¡å‡†è®¾ç½®: é˜ˆå€¼={self.audio_threshold:.4f}")
                return True
        except Exception as e:
            print(f"åŠ è½½æ ¡å‡†è®¾ç½®å¤±è´¥: {str(e)}")

        return False

    def stop_recording_for_processing(self):
        """åœæ­¢å½•éŸ³ä»¥ä¾¿å¤„ç†"""
        if self.recording_thread:
            self.recording_thread.stop_recording = True
        self.recording_timer.stop()

    def update_scaling_factors(self, distance):
        """æ ¹æ®æµ‹è·è·ç¦»æ›´æ–°ç¼©æ”¾æ¯”ä¾‹"""
        try:
            # ç¡®ä¿è·ç¦»æœ‰æ•ˆï¼ˆå¤§äº10mmï¼‰
            if distance < 10:
                distance = self.base_distance

            self.current_distance = distance

            # è®¡ç®—æ–°ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿ç•™4ä½å°æ•°ï¼‰
            new_scale_x = round((self.base_distance * self.base_scale_x) / distance, 4)
            new_scale_y = round((self.base_distance * self.base_scale_y) / distance, 4)

            # æ›´æ–°UIæ˜¾ç¤º
            self.scale_factor_X_input.setText(str(new_scale_x))
            self.scale_factor_Y_input.setText(str(new_scale_y))

            # æ›´æ–°å†…å­˜å˜é‡
            self.path_scale_factor_X = new_scale_x
            self.path_scale_factor_Y = new_scale_y

            print(f"è·ç¦»{distance}mmå¤„ç¼©æ”¾æ¯”ä¾‹æ›´æ–°: X={new_scale_x}, Y={new_scale_y}")
            return True
        except Exception as e:
            print(f"æ›´æ–°ç¼©æ”¾æ¯”ä¾‹å¤±è´¥: {str(e)}")
            return False

    def update_distance_from_sensor(self):
        """ä»æµ‹è·ä¼ æ„Ÿå™¨è·å–æœ€æ–°è·ç¦»å¹¶æ›´æ–°æ¯”ä¾‹"""
        try:
            distance = float(self.distance_display.text())

            try:
                # åˆå§‹åŒ–ä¼ æ„Ÿå™¨
                tof = TOF_Sense("/dev/ttyUSB0", 921600)

                # ä½¿ç”¨ç±»æ–¹æ³•è·å–è·ç¦»
                distance = tof.get_distance()
                if distance is not None:
                    print(f"è·ç¦»: {distance} mm")
                else:
                    print("æœªèƒ½è·å–æœ‰æ•ˆè·ç¦»æ•°æ®")

            except KeyboardInterrupt:
                print("ç¨‹åºå·²é€€å‡º")

            # æ›´æ–°UIæ˜¾ç¤º
            self.distance_display.setText(str(distance))

            # è‡ªåŠ¨æ›´æ–°ç¼©æ”¾æ¯”ä¾‹
            self.update_scaling_factors(distance)
            return True

        except Exception as e:
            QMessageBox.warning(self, "æµ‹è·å¤±è´¥", f"æ— æ³•è·å–è·ç¦»æ•°æ®: {str(e)}")
            return False


    def open_point_cloud_config(self):
        """æ‰“å¼€ç‚¹äº‘é…ç½®å¯¹è¯æ¡†"""

    def toggle_history_path_usage(self, state):
        """åˆ‡æ¢å†å²è·¯å¾„ä½¿ç”¨çŠ¶æ€"""
        self.use_history_path = (state == Qt.Checked)
        if self.use_history_path and not self.current_history_path:
            QMessageBox.warning(self, "æœªé€‰æ‹©è·¯å¾„", "è¯·å…ˆé€‰æ‹©å¹¶åº”ç”¨ä¸€ä¸ªå†å²è·¯å¾„")
            self.use_history_checkbox.setChecked(False)
            self.use_history_path = False
        else:
            status = "å¯ç”¨" if self.use_history_path else "ç¦ç”¨"
            self.status_label.setText(f"å†å²è·¯å¾„ä½¿ç”¨çŠ¶æ€: {status}")

    def save_current_path(self):
        """ä¿å­˜å½“å‰è·¯å¾„åˆ°å†å²è®°å½•"""
        if not hasattr(self.detection_thread, 'detection_system') or not self.detection_thread.detection_system.fixed_contour:
            QMessageBox.warning(self, "æ— è·¯å¾„", "å½“å‰æ²¡æœ‰å¯ä¿å­˜çš„è·¯å¾„")
            return

        # è·å–è·¯å¾„åç§°
        name, ok = QInputDialog.getText(self, "è·¯å¾„å‘½å", "è¾“å…¥è·¯å¾„åç§°:")
        if not ok or not name:
            return

        # è·å–å½“å‰æ—¶é—´
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

        # è·å–å½“å‰æ—‹è½¬è§’åº¦
        rotation = self.coordinate_rotation

        # åˆ›å»ºè·¯å¾„æ•°æ®å¯¹è±¡
        path_data = {
            "name": name,
            "timestamp": timestamp,
            "points": self.detection_thread.detection_system.fixed_contour,
            "original_size": self.detection_thread.detection_system.fixed_contour_size,
            "rotation": rotation,  # ä¿å­˜æ—‹è½¬è§’åº¦
            "world_coords": []  # å­˜å‚¨è½¬æ¢åçš„ä¸–ç•Œåæ ‡
        }

        # æ·»åŠ åˆ°å†å²åˆ—è¡¨
        self.history_paths.append(path_data)
        self.update_history_list()

        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open("history_paths.json", "w") as f:
                json.dump(self.history_paths, f)
            QMessageBox.information(self, "ä¿å­˜æˆåŠŸ", f"å·²ä¿å­˜è·¯å¾„: {name}")
        except Exception as e:
            QMessageBox.warning(self, "ä¿å­˜å¤±è´¥", f"æ— æ³•ä¿å­˜å†å²è·¯å¾„: {str(e)}")

    def load_history_path(self):
        """ä»æ–‡ä»¶åŠ è½½å†å²è·¯å¾„"""
        try:
            with open("history_paths.json", "r") as f:
                self.history_paths = json.load(f)
            self.update_history_list()
            QMessageBox.information(self, "åŠ è½½æˆåŠŸ", f"å·²åŠ è½½ {len(self.history_paths)} æ¡å†å²è·¯å¾„")
        except FileNotFoundError:
            QMessageBox.warning(self, "æ–‡ä»¶æœªæ‰¾åˆ°", "å†å²è·¯å¾„æ–‡ä»¶ä¸å­˜åœ¨")
        except Exception as e:
            QMessageBox.warning(self, "åŠ è½½å¤±è´¥", f"æ— æ³•åŠ è½½å†å²è·¯å¾„: {str(e)}")

    def update_history_list(self):
        """æ›´æ–°å†å²è·¯å¾„åˆ—è¡¨æ˜¾ç¤º"""
        self.history_list.clear()
        for path in self.history_paths:
            points_count = len(path["points"])
            item = QListWidgetItem(f"{path['name']} - {path['timestamp']} ({points_count}ç‚¹)")
            item.setData(Qt.UserRole, path)
            self.history_list.addItem(item)

    def apply_history_path(self):
        """åº”ç”¨é€‰ä¸­çš„å†å²è·¯å¾„"""
        selected = self.history_list.currentItem()
        if not selected:
            QMessageBox.warning(self, "æœªé€‰æ‹©", "è¯·å…ˆé€‰æ‹©ä¸€æ¡å†å²è·¯å¾„")
            return

        path_data = selected.data(Qt.UserRole)
        self.current_history_path = path_data

        # æ›´æ–°ä½¿ç”¨å†å²è·¯å¾„å¤é€‰æ¡†çŠ¶æ€
        self.use_history_checkbox.setChecked(True)
        self.use_history_path = True

        QMessageBox.information(self, "è·¯å¾„åº”ç”¨", f"å·²åº”ç”¨è·¯å¾„: {path_data['name']}")

    def apply_grinding_params(self, show_message=True):
        """åº”ç”¨æ‰“ç£¨å‚æ•°ï¼ˆshow_messageæ§åˆ¶æ˜¯å¦æ˜¾ç¤ºæç¤ºæ¡†ï¼‰"""
        try:
            # è·å–å¾ªç¯æ¬¡æ•°
            loops = int(self.loop_count_input.text())
            if loops < 1 or loops > 100:
                if show_message:
                    QMessageBox.warning(self, "å‚æ•°é”™è¯¯", "å¾ªç¯æ¬¡æ•°å¿…é¡»åœ¨1-100ä¹‹é—´")
                return False
            self.grinding_loops = loops

            # è·å–Xè¿›æ·±
            x_step = float(self.x_step_input.text())
            if abs(x_step) > 10:
                if show_message:
                    QMessageBox.warning(self, "å‚æ•°é”™è¯¯", "Xè¿›æ·±ä¸èƒ½è¶…è¿‡Â±10mm")
                return False
            self.grinding_x_step = x_step

            # è·å–Yè¿›æ·±
            y_step = float(self.y_step_input.text())
            if abs(y_step) > 10:
                if show_message:
                    QMessageBox.warning(self, "å‚æ•°é”™è¯¯", "Yè¿›æ·±ä¸èƒ½è¶…è¿‡Â±10mm")
                return False
            self.grinding_y_step = y_step

            # è·å–Zè¿›æ·±
            z_step = float(self.z_step_input.text())
            if abs(z_step) > 10:
                if show_message:
                    QMessageBox.warning(self, "å‚æ•°é”™è¯¯", "Zè¿›æ·±ä¸èƒ½è¶…è¿‡Â±10mm")
                return False
            self.grinding_z_step = z_step

            # è·å–ç¼©æ”¾æ¯”ä¾‹
            scale_factor_X = float(self.scale_factor_X_input.text())
            scale_factor_Y = float(self.scale_factor_Y_input.text())
            if scale_factor_X < 0.1 or scale_factor_X > 10.0:
                if show_message:
                    QMessageBox.warning(self, "å‚æ•°é”™è¯¯", "ç¼©æ”¾æ¯”ä¾‹å¿…é¡»åœ¨0.1-10.0ä¹‹é—´")
                return False
            self.path_scale_factor_X = scale_factor_X
            if scale_factor_Y < 0.1 or scale_factor_Y > 10.0:
                if show_message:
                    QMessageBox.warning(self, "å‚æ•°é”™è¯¯", "ç¼©æ”¾æ¯”ä¾‹å¿…é¡»åœ¨0.1-10.0ä¹‹é—´")
                return False
            self.path_scale_factor_Y = scale_factor_Y

            # åªåœ¨éœ€è¦æ—¶æ˜¾ç¤ºæ¶ˆæ¯æ¡†
            if show_message:
                QMessageBox.information(self, "å‚æ•°è®¾ç½®",
                                    f"æ‰“ç£¨å‚æ•°å·²æ›´æ–°:\nå¾ªç¯æ¬¡æ•°: {self.grinding_loops}\n"
                                    f"Xè¿›æ·±: {self.grinding_x_step}mm\n"
                                    f"Yè¿›æ·±: {self.grinding_y_step}mm\n"
                                    f"Zè¿›æ·±: {self.grinding_z_step}mm\n"
                                    f"Xç¼©æ”¾æ¯”ä¾‹: {scale_factor_X}\n"
                                    f"Yç¼©æ”¾æ¯”ä¾‹: {scale_factor_Y}")

            return True
        except ValueError:
            if show_message:
                QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—å‚æ•°")
            return False

    def update_frame(self, frame):
        """æ›´æ–°æ£€æµ‹ç”»é¢"""
        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºQtå›¾åƒ
        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_image.shape
        bytes_per_line = ch * w
        q_img = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_img)

        # ç¼©æ”¾å›¾åƒä»¥é€‚åº”æ ‡ç­¾å¤§å°
        scaled_pixmap = pixmap.scaled(
            self.detection_label.width(),
            self.detection_label.height(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )

        self.detection_label.setPixmap(scaled_pixmap)

    def start_calibration(self):
        """å¯åŠ¨æ‘„åƒå¤´æ ‡å®š"""
        # ç¡®ä¿æ£€æµ‹çº¿ç¨‹å·²ç»å¯åŠ¨
        if not self.detection_thread or not self.detection_thread.isRunning():
            # å…ˆåˆ›å»ºæ£€æµ‹çº¿ç¨‹
            self.create_detection_thread()

            # å¦‚æœçº¿ç¨‹åˆ›å»ºæˆåŠŸï¼Œå¯åŠ¨å®ƒ
            if self.detection_thread:
                self.detection_thread.start()
                self.detect_button.setText("åœæ­¢æ£€æµ‹")
                self.detect_button.setStyleSheet("background-color: #FF4D4D;")

        # ç¡®ä¿æ£€æµ‹çº¿ç¨‹å·²æ­£ç¡®åˆå§‹åŒ–
        if self.detection_thread and self.detection_thread.isRunning():
            try:
                self.detection_thread.perform_calibration()
            except Exception as e:
                QMessageBox.critical(self, "æ ‡å®šé”™è¯¯", f"æ ‡å®šè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        else:
            QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•å¯åŠ¨æ ‡å®šï¼Œè¯·å…ˆç¡®ä¿æ‘„åƒå¤´æ£€æµ‹å·²æ­£å¸¸å¯åŠ¨")

    def update_detection_result(self, result):
        """æ›´æ–°æ£€æµ‹ç»“æœæ–‡æœ¬"""

    # æ·»åŠ æ–°çš„æ ‡å®šæ–‡ä»¶æ“ä½œæ–¹æ³•
    def load_calibration_file(self):
        """åŠ è½½æ ‡å®šæ–‡ä»¶"""
        options = QFileDialog.Options()
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©æ ‡å®šæ–‡ä»¶", "",
            "JSONæ–‡ä»¶ (*.json);;æ‰€æœ‰æ–‡ä»¶ (*)",
            options=options
        )

        if file_path:
            if self.detection_thread and self.detection_thread.detection_system:
                if self.detection_thread.detection_system.load_calibration_params(file_path):
                    QMessageBox.information(self, "åŠ è½½æˆåŠŸ", "æ ‡å®šå‚æ•°å·²åŠ è½½")
                    # æ›´æ–°UIçŠ¶æ€
                    self.calibration_status.setText("æ ‡å®šçŠ¶æ€: å·²åŠ è½½")
                else:
                    QMessageBox.warning(self, "åŠ è½½å¤±è´¥", "æ— æ³•åŠ è½½æ ‡å®šå‚æ•°")

    def save_calibration_file(self):
        """ä¿å­˜æ ‡å®šæ–‡ä»¶"""
        options = QFileDialog.Options()
        file_path = QFileDialog.getSaveFileName(
            self, "ä¿å­˜æ ‡å®šæ–‡ä»¶", "",
            "JSONæ–‡ä»¶ (*.json);;æ‰€æœ‰æ–‡ä»¶ (*)",
            options=options
        )

        if file_path:
            if self.detection_thread and self.detection_thread.detection_system:
                if self.detection_thread.detection_system.save_calibration_params(file_path):
                    QMessageBox.information(self, "ä¿å­˜æˆåŠŸ", f"æ ‡å®šå‚æ•°å·²ä¿å­˜åˆ°:\n{file_path}")
                else:
                    QMessageBox.warning(self, "ä¿å­˜å¤±è´¥", "æ— æ³•ä¿å­˜æ ‡å®šå‚æ•°")

    def toggle_detection(self):
        if hasattr(self, 'camera_thread') and self.camera_thread and self.camera_thread.isRunning():
            self.close_camera()
            time.sleep(0.5)
        if self.detect_button.text() == "å¯åŠ¨æ£€æµ‹":
            try:
                # è·å–æ‘„åƒå¤´ç±»å‹å’Œå‚æ•°
                camera_type = "network" if self.camera_type_combo.currentIndex() == 1 else "local"
                ip = self.camera_ip_input.text()
                port = int(self.camera_port_input.text())

                # åˆ›å»ºæ£€æµ‹çº¿ç¨‹ï¼Œä¼ å…¥æ­£ç¡®çš„å‚æ•°
                self.detection_thread = ONNXDetectionThread(
                    config=self.config,
                    model_path=self.onnx_model_path,
                    ip=ip,
                    port=port
                )
                self.detection_thread.camera_type = camera_type
                # è¿æ¥ä¿¡å·
                self.detection_thread.update_frame.connect(self.update_frame)
                self.detection_thread.detection_result.connect(self.update_detection_result)
                self.detection_thread.detection_coords.connect(self.handle_detection_coords)
                # ç¡®ä¿çº¿ç¨‹è¢«æ­£ç¡®åˆ›å»º
                if not self.detection_thread:
                    raise RuntimeError("æ— æ³•åˆ›å»ºæ£€æµ‹çº¿ç¨‹")
                # å¯åŠ¨çº¿ç¨‹
                self.detection_thread.start()
                self.detect_button.setText("åœæ­¢æ£€æµ‹")
                self.detect_button.setStyleSheet("background-color: #FF4D4D;")
            except Exception as e:
                QMessageBox.critical(self, "é”™è¯¯", f"æ— æ³•å¯åŠ¨ç›®æ ‡æ£€æµ‹: {str(e)}")
                print(self, "é”™è¯¯", f"æ— æ³•å¯åŠ¨ç›®æ ‡æ£€æµ‹: {str(e)}",flush=True)
                self.detection_thread.stop()
                self.detection_thread.wait(2000)  # ç­‰å¾…çº¿ç¨‹å®‰å…¨é€€å‡º
                self.detection_thread = None
                self.detect_button.setText("å¯åŠ¨æ£€æµ‹")
                self.detect_button.setStyleSheet("")
                self.detection_label.clear()
                self.detection_label.setText("æ‘„åƒå¤´æœªå¯åŠ¨")
                self.detection_result.setText("æ£€æµ‹å·²åœæ­¢")
                cv2.destroyAllWindows()
        else:
            # åœæ­¢æ‘„åƒå¤´æ£€æµ‹
            if self.detection_thread and self.detection_thread.isRunning():
                self.detection_thread.stop()
                self.detection_thread.wait(2000)  # ç­‰å¾…çº¿ç¨‹å®‰å…¨é€€å‡º
                self.detection_thread = None
                self.detect_button.setText("å¯åŠ¨æ£€æµ‹")
                self.detect_button.setStyleSheet("")
                self.detection_label.clear()
                self.detection_label.setText("æ‘„åƒå¤´æœªå¯åŠ¨")
                self.detection_label.setText("æ£€æµ‹å·²åœæ­¢")
                cv2.destroyAllWindows()


    def handle_single_image_result(self, result_frame, result_text):
        """å¤„ç†å•å¼ å›¾åƒæ£€æµ‹ç»“æœ"""
        if result_frame is None:
            QMessageBox.warning(self, "é”™è¯¯", result_text)
            self.detection_label.setText("æ£€æµ‹å¤±è´¥")
            self.detection_result.setText(result_text)
            return

        # æ˜¾ç¤ºç»“æœå›¾åƒ
        self.display_image(result_frame)

        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
        self.detection_result.setText("æ£€æµ‹ç»“æœ: " + result_text)

    def display_image(self, frame):
        """æ˜¾ç¤ºå›¾åƒåœ¨QLabelä¸­"""
        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_image.shape
        bytes_per_line = ch * w
        q_img = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_img)

        # ç¼©æ”¾å›¾åƒä»¥é€‚åº”æ ‡ç­¾å¤§å°
        scaled_pixmap = pixmap.scaled(
            self.detection_label.width(),
            self.detection_label.height(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.detection_label.setPixmap(scaled_pixmap)

    def load_yolo_model(self):
        """åŠ è½½YOLOæ¨¡å‹"""
        options = QFileDialog.Options()
        model_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶", "",
            "æ¨¡å‹æ–‡ä»¶ (*.pt);;æ‰€æœ‰æ–‡ä»¶ (*)",
            options=options
        )

        if model_path:
            global YOLO_MODEL_PATH
            YOLO_MODEL_PATH = model_path
            QMessageBox.information(self, "æˆåŠŸ", f"å·²åŠ è½½æ¨¡å‹: {model_path}")

            # é‡æ–°åˆå§‹åŒ–æ£€æµ‹çº¿ç¨‹
            if self.detection_thread:
                self.detection_thread.stop()
                self.detection_thread = None
                self.detect_button.setText("å¯åŠ¨æ£€æµ‹")
                self.detect_button.setStyleSheet("")

    def camera_settings(self):
        """æ‘„åƒå¤´è®¾ç½®"""
        QMessageBox.information(self, "æ‘„åƒå¤´è®¾ç½®", "å½“å‰ä½¿ç”¨é»˜è®¤æ‘„åƒå¤´")

    def update_speed_label(self, value):
        """æ›´æ–°é€Ÿåº¦æ ‡ç­¾"""
        self.speed_label.setText(f"é€Ÿåº¦: {value}")

    def update_ui_state(self, connected):
        """æ›´æ–°UIçŠ¶æ€"""
        if connected:
            self.connect_button.setText("æ–­å¼€è¿æ¥")
            self.grinding_button.setEnabled(True)
            self.save_teach_button.setEnabled(True)
            self.move_button.setEnabled(True)
            self.execute_all_button.setEnabled(True)
            self.execute_selected_button.setEnabled(True)
            self.status_indicator.setStyleSheet("background-color: #00FF00; border-radius: 10px;")
        else:
            self.connect_button.setText("é“¾æ¥æœºå™¨äºº")
            self.grinding_button.setEnabled(False)
            self.save_teach_button.setEnabled(False)
            self.move_button.setEnabled(False)
            self.execute_all_button.setEnabled(False)
            self.execute_selected_button.setEnabled(False)
            self.status_indicator.setStyleSheet("background-color: #FF0000; border-radius: 10px;")

    def toggle_connection(self):
        """åˆ‡æ¢è¿æ¥çŠ¶æ€"""
        if self.connect_button.text() == "é“¾æ¥æœºå™¨äºº":
            ip = self.ip_input.text() or self.config.ROBOT_IP
            port = int(self.port_input.text() or self.config.ROBOT_PORT)
            if not ip or not port:
                QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "è¯·å¡«å†™IPåœ°å€å’Œç«¯å£å·ï¼")
                return

            print(f"æ­£åœ¨è¿æ¥åˆ° {ip}:{port}...")
            thread_server = threading.Thread(target=self.start_stop_server)
            thread_server.start()
            try:
                self.connection = RobotConnection(ip, port)
                if self.connection.is_connected():
                    self.update_ui_state(True)
                else:
                    QMessageBox.critical(self, "è¿æ¥å¤±è´¥", "æ— æ³•è¿æ¥åˆ°æœºæ¢°è‡‚ï¼Œè¯·æ£€æŸ¥IPå’Œç«¯å£")
                    self.speak_response("è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œç”µæº")
            except Exception as e:
                QMessageBox.critical(self, "è¿æ¥é”™è¯¯", f"è¿æ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        else:
            print("æ–­å¼€æœºå™¨äººè¿æ¥...")
            if self.connection:
                self.connection.disconnect()
                self.connection.stop_heartbeat()
            self.update_ui_state(False)
            self.stop_speech_recognition()

    def open_manual_control(self):
        """æ‰“å¼€æ‰‹åŠ¨æ§åˆ¶å¯¹è¯æ¡†"""
        if not self.connection or not self.connection.is_connected():
            self.speak_response("æœºå™¨äººæœªè¿æ¥ï¼Œè¯·å…ˆå»ºç«‹è¿æ¥")
            QMessageBox.warning(self, "æœªè¿æ¥", "è¯·å…ˆè¿æ¥æœºæ¢°è‡‚")
            return

        dialog = ManualControlDialog(self.connection, self)
        dialog.exec()

    def open_motor_control(self):
        """æ‰“å¼€ç”µæœºæ§åˆ¶å¯¹è¯æ¡†"""
        self.motor_dialog.show()

    def load_teach_points(self):
        """ä»æ–‡ä»¶åŠ è½½ä¿å­˜çš„ç¤ºæ•™ç‚¹"""
        try:
            if os.path.exists(self.config.TEACH_POINTS_FILE):
                with open(self.config.TEACH_POINTS_FILE, 'r') as f:
                    self.teach_points = json.load(f)
                print(f"æˆåŠŸåŠ è½½ {len(self.teach_points)} ä¸ªç¤ºæ•™ç‚¹")
            else:
                self.teach_points = []
                print("æ²¡æœ‰æ‰¾åˆ°ç¤ºæ•™ç‚¹æ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
        except Exception as e:
            print(f"åŠ è½½ç¤ºæ•™ç‚¹å¤±è´¥: {str(e)}")
            self.teach_points = []

    def save_teach_points(self):
        """ä¿å­˜ç¤ºæ•™ç‚¹åˆ°æ–‡ä»¶"""
        try:
            with open(self.config.TEACH_POINTS_FILE, 'w') as f:
                json.dump(self.teach_points, f, indent=4)
            print("ç¤ºæ•™ç‚¹å·²ä¿å­˜åˆ°æ–‡ä»¶")
            return True
        except Exception as e:
            print(f"ä¿å­˜ç¤ºæ•™ç‚¹å¤±è´¥: {str(e)}")
            return False

    def update_teach_point_list(self):
        """æ›´æ–°ç¤ºæ•™ç‚¹åˆ—è¡¨æ˜¾ç¤º"""
        self.teach_point_list.clear()
        for point in self.teach_points:
            name = point.get('name', 'æœªå‘½å')
            if 'positions' in point:
                positions = ", ".join([f"{p:.2f}" for p in point['positions']])
            elif 'angles' in point:
                positions = ", ".join([f"{p:.2f}" for p in point['angles']])
            else:
                positions = "æœªçŸ¥ä½ç½®"
            time_str = point.get('timestamp', point.get('time', 'æœªçŸ¥æ—¶é—´'))
            item = QListWidgetItem(f"{name} - {time_str}\nä½ç½®: [{positions}]")
            self.teach_point_list.addItem(item)

    def save_teach_point_object(self, point):
        """ä¿å­˜ç¤ºæ•™ç‚¹å¯¹è±¡"""
        if any(p['name'] == point['name'] for p in self.teach_points):
            QMessageBox.warning(self, "åç§°é‡å¤", f"ç¤ºæ•™ç‚¹åç§° '{point['name']}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨ä¸åŒçš„åç§°")
            return

        self.teach_points.append(point)
        if self.save_teach_points():
            self.update_teach_point_list()
            QMessageBox.information(self, "ä¿å­˜æˆåŠŸ", f"æˆåŠŸä¿å­˜ç¤ºæ•™ç‚¹: {point['name']}")
        else:
            self.teach_points.pop()
            QMessageBox.critical(self, "ä¿å­˜å¤±è´¥", "æ— æ³•ä¿å­˜ç¤ºæ•™ç‚¹åˆ°æ–‡ä»¶")

    def save_teach_point(self):
        """ä¿å­˜å½“å‰ä½ç½®ä¸ºç¤ºæ•™ç‚¹"""
        if not self.connection or not self.connection.is_connected():
            QMessageBox.warning(self, "æœªè¿æ¥", "æœªè¿æ¥åˆ°æœºå™¨äººï¼Œæ— æ³•ä¿å­˜ç¤ºæ•™ç‚¹")
            return

        name = self.teach_name_input.text().strip()
        if not name:
            QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥ç¤ºæ•™ç‚¹åç§°")
            return

        if any(p.get('name') == name for p in self.teach_points):
            QMessageBox.warning(self, "åç§°é‡å¤", f"ç¤ºæ•™ç‚¹åç§° '{name}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨ä¸åŒçš„åç§°")
            return

        try:
            mc = self.connection.get_robot()
            coords = mc.get_coords()
            angles = mc.get_angles()

            if angles:
                point = {
                    'name': name,
                    'coords': coords,
                    'angles': angles,
                    'positions': angles,
                    'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
                }
                self.teach_points.append(point)

                if self.save_teach_points():
                    self.update_teach_point_list()
                    QMessageBox.information(self, "ä¿å­˜æˆåŠŸ", f"æˆåŠŸä¿å­˜ç¤ºæ•™ç‚¹: {name}")
                    self.teach_name_input.clear()
                else:
                    self.teach_points.pop()
                    QMessageBox.critical(self, "ä¿å­˜å¤±è´¥", "æ— æ³•ä¿å­˜ç¤ºæ•™ç‚¹åˆ°æ–‡ä»¶")
            else:
                QMessageBox.warning(self, "è·å–ä½ç½®å¤±è´¥", "æ— æ³•è·å–æœºå™¨äººå½“å‰ä½ç½®")
        except Exception as e:
            QMessageBox.critical(self, "ä¿å­˜é”™è¯¯", f"ä¿å­˜ç¤ºæ•™ç‚¹æ—¶å‡ºé”™: {str(e)}")

    def get_selected_point(self):
        """è·å–é€‰å®šçš„ç¤ºæ•™ç‚¹"""
        selected_items = self.teach_point_list.selectedItems()
        if not selected_items:
            return None
        index = self.teach_point_list.row(selected_items[0])
        if 0 <= index < len(self.teach_points):
            return self.teach_points[index]
        return None

    def move_to_selected_point(self):
        """ç§»åŠ¨åˆ°é€‰å®šçš„ç¤ºæ•™ç‚¹"""
        point = self.get_selected_point()
        if point:
            self.move_to_teach_point(point)

    def move_to_teach_point(self, point=None):
        """ç§»åŠ¨åˆ°æŒ‡å®šçš„ç¤ºæ•™ç‚¹"""
        if not self.connection or not self.connection.is_connected():
            QMessageBox.warning(self, "æœªè¿æ¥", "æœªè¿æ¥åˆ°æœºå™¨äººï¼Œæ— æ³•ç§»åŠ¨")
            return

        if point is None:
            selected_items = self.teach_point_list.selectedItems()
            if selected_items:
                idx = self.teach_point_list.row(selected_items[0])
                point = self.teach_points[idx] if idx < len(self.teach_points) else None

        if not point:
            return

        try:
            point_name = point.get('name', 'æœªå‘½åç‚¹ä½')
            print(f"ç§»åŠ¨åˆ°: {point_name}")
            mc = self.connection.get_robot()
            target = point.get('positions', point.get('angles', []))

            # æ·»åŠ å…³èŠ‚è§’åº¦é™åˆ¶æ£€æŸ¥
            safe_target = self.apply_joint_limits(target)

            # ä½¿ç”¨å®‰å…¨è§’åº¦
            mc.send_angles(safe_target, 50)

            # é«˜äº®æ˜¾ç¤º
            for i in range(self.teach_point_list.count()):
                if self.teach_points[i].get('name') == point.get('name'):
                    item = self.teach_point_list.item(i)
                    item.setBackground(QBrush(QColor("#007ACC")))
                    break

            QMessageBox.information(self, "ç§»åŠ¨æˆåŠŸ", f"æ­£åœ¨ç§»åŠ¨åˆ°: {point_name}")
        except Exception as e:
            QMessageBox.critical(self, "ç§»åŠ¨å¤±è´¥", f"ç§»åŠ¨è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

    def apply_joint_limits(self, angles):
        """åº”ç”¨å…³èŠ‚è§’åº¦é™åˆ¶ç¡®ä¿å®‰å…¨ç§»åŠ¨"""
        # å…³èŠ‚è§’åº¦é™åˆ¶
        limits = [
            (-168, 168),  # å…³èŠ‚1
            (-135, 135),  # å…³èŠ‚2
            (-150, 150),  # å…³èŠ‚3
            (-145, 145),  # å…³èŠ‚4
            (-165, 165),  # å…³èŠ‚5
            (-180, 180)  # å…³èŠ‚6
        ]

        safe_angles = []
        for i, angle in enumerate(angles):
            if i < len(limits):
                min_val, max_val = limits[i]
                # ç¡®ä¿è§’åº¦åœ¨é™åˆ¶èŒƒå›´å†…
                safe_angle = max(min_val, min(angle, max_val))
                safe_angles.append(safe_angle)
            else:
                safe_angles.append(angle)

        return safe_angles

    def delete_selected_point(self):
        """åˆ é™¤é€‰å®šçš„ç¤ºæ•™ç‚¹"""
        point = self.get_selected_point()
        if point:
            reply = QMessageBox.question(self, "ç¡®è®¤åˆ é™¤",
                                         f"ç¡®å®šè¦åˆ é™¤ç¤ºæ•™ç‚¹ '{point['name']}' å—?",
                                         QMessageBox.Yes | QMessageBox.No)
            if reply == QMessageBox.Yes:
                self.teach_points = [p for p in self.teach_points if p['name'] != point['name']]
                if self.save_teach_points():
                    self.update_teach_point_list()
                    QMessageBox.information(self, "åˆ é™¤æˆåŠŸ", f"å·²åˆ é™¤ç¤ºæ•™ç‚¹: {point['name']}")
                else:
                    self.load_teach_points()
                    QMessageBox.critical(self, "åˆ é™¤å¤±è´¥", "æ— æ³•ä¿å­˜æ›´æ”¹")

    def toggle_grinding(self):
        """åˆ‡æ¢æ‰“ç£¨çŠ¶æ€"""
        # åœ¨å¯åŠ¨æ‰“ç£¨å‰æ£€æŸ¥è¿æ¥å¯¹è±¡
        if not self.connection or not hasattr(self.connection, 'reconnect'):
            QMessageBox.warning(self, "è¿æ¥é”™è¯¯", "æœºå™¨äººè¿æ¥å¯¹è±¡æ— æ•ˆ")
            return

        current_text = self.grinding_button.text()
        if current_text == "å¯åŠ¨æ‰“ç£¨":
            print("å¯åŠ¨æ‰“ç£¨ç¨‹åº...")
            self.grinding_button.setText("åœæ­¢æ‰“ç£¨")
            self.grinding_button.setStyleSheet("background-color: #FF4D4D;")
            self.grinding_status_indicator.setStyleSheet("background-color: #00FF00; border-radius: 10px;")

            # è·å–ä¸‰ç»´åæ ‡æ•°æ®
            camera_coordinates_3d = self.get_3d_coordinates()

            if not camera_coordinates_3d:
                QMessageBox.warning(self, "åæ ‡é”™è¯¯", "æ— æ³•è·å–æœ‰æ•ˆçš„ä¸‰ç»´åæ ‡æ•°æ®")
                # æ¢å¤æŒ‰é’®çŠ¶æ€
                self.grinding_button.setText("å¯åŠ¨æ‰“ç£¨")
                self.grinding_button.setStyleSheet("")
                self.grinding_status_indicator.setStyleSheet("background-color: #FF0000; border-radius: 10px;")
                return

            print(f"è·å–åˆ° {len(camera_coordinates_3d)} ä¸ªä¸‰ç»´åæ ‡ç‚¹")

            # åˆå§‹åŒ–æ‰“ç£¨æ§åˆ¶å™¨
            if not hasattr(self, 'grinding_controller') or self.grinding_controller is None:
                robot_instance = self.connection.get_robot()
                self.grinding_controller = MyCobotGrindingController(robot_instance)

            # ä½¿ç”¨çº¿ç¨‹æ± æäº¤æ‰“ç£¨ä»»åŠ¡
            task_id = self.thread_pool.submit_task(
                self._run_grinding_procedure,
                camera_coordinates_3d,
                self.user_offset_x,
                self.user_offset_y,
                self.user_offset_z
            )

            # å­˜å‚¨å½“å‰ä»»åŠ¡IDç”¨äºåç»­ç®¡ç†
            self.current_grinding_task_id = task_id
            self.task_ids['grinding'] = task_id
            self.speak_response("æ‰“ç£¨ç¨‹åºå·²å¯åŠ¨")

            self.DAMCX()

        else:
            print("åœæ­¢æ‰“ç£¨ç¨‹åº...")
            self._stop_grinding_procedure()

    def DAMCX(self):
        T = np.array([
            [-2.74280449e-02, -9.99601611e-01, -6.65752354e-03, 6.48263423e+01],
            [-9.99259510e-01, 2.72376602e-02, 2.71761376e-02, 2.04309745e+02],
            [-2.69839756e-02, 7.39798203e-03, -9.99608491e-01, 8.88548188e+02],
            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])

        # ç›´æ¥ä½¿ç”¨çŸ©é˜µæ±‚é€†
        def transform_point_inverse(T, point):
            """ä½¿ç”¨é€†çŸ©é˜µå˜æ¢ç‚¹"""
            # å°†ç‚¹è½¬æ¢ä¸ºé½æ¬¡åæ ‡
            point_homogeneous = np.append(point, 1.0)

            # è®¡ç®—å˜æ¢çŸ©é˜µçš„é€†
            T_inv = np.linalg.inv(T)

            # åº”ç”¨é€†å˜æ¢
            robot_point_homogeneous = T_inv @ point_homogeneous

            # è½¬æ¢å›3Dåæ ‡ (é½æ¬¡åæ ‡é™¤ä»¥wåˆ†é‡)
            robot_point = robot_point_homogeneous[:3] / robot_point_homogeneous[3]

            return robot_point

        try:
            mc = self.connection.get_robot()
            # è·å–å½“å‰ä½ç½®
            # current_pos = controller.get_current_position()
            # print(f"å½“å‰ä½ç½®: {current_pos}")

            mc.power_on()

            import time

            def move_to_point_clouds(point_cloud_list, speed=20, fixed_height=None):
                """
                å°†ç‚¹äº‘åæ ‡åˆ—è¡¨è½¬æ¢ä¸ºæœºå™¨äººåæ ‡å¹¶ä½¿ç”¨ç›´çº¿è¿åŠ¨æ¨¡å¼ä¾æ¬¡è¿åŠ¨åˆ°æ¯ä¸ªä½ç½®

                Args:
                    point_cloud_list: ç‚¹äº‘åæ ‡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º[x, y, z]æ ¼å¼çš„æ•°ç»„
                    speed: ç›´çº¿è¿åŠ¨é€Ÿåº¦ï¼ˆ1-100ï¼‰
                    fixed_height: å›ºå®šé«˜åº¦ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç‚¹äº‘ä¸­çš„Zåæ ‡
                """

                # åæ ‡è¡¥å¿å‡½æ•° - åŸºäºxå’Œyä¸­ç»å¯¹å€¼è¾ƒå¤§çš„å€¼åˆ¤æ–­
                def get_compensation_value(x, y):
                    max_abs_value = max(abs(x), abs(y))
                    if max_abs_value <= 100:
                        return 0  # 100mmä»¥å†…ä¸éœ€è¦è¡¥å¿
                    elif max_abs_value <= 200:
                        return 0  # 100-200mmè¡¥å¿2mm
                    else:
                        return 0  # 200mmä»¥ä¸Šè¡¥å¿4mm

                # åæ ‡èŒƒå›´é™åˆ¶å‡½æ•°
                def limit_coordinate(value, min_val, max_val):
                    return max(min(value, max_val), min_val)

                # è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»
                def distance_between_points(p1, p2):
                    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2 + (p1[2] - p2[2]) ** 2) ** 0.5

                # å­˜å‚¨æ‰€æœ‰ç¬›å¡å°”åæ ‡ç‚¹
                cartesian_points = []

                print(f"å¼€å§‹å¤„ç† {len(point_cloud_list)} ä¸ªç‚¹...")

                # è®¡ç®—æ‰€æœ‰ç‚¹çš„ç¬›å¡å°”åæ ‡
                for i, point_cloud in enumerate(point_cloud_list):
                    print(f"è®¡ç®—ç¬¬ {i + 1}/{len(point_cloud_list)} ä¸ªç‚¹çš„åæ ‡...")

                    # å°†ç‚¹äº‘åæ ‡è½¬æ¢ä¸ºæœºå™¨äººåæ ‡ç³»
                    robot_coords_inverse = transform_point_inverse(T, point_cloud)
                    # print("åŸæœºå™¨äººåæ ‡:" , robot_coords_inverse)
                    # è·å–è¡¥å¿å€¼ï¼ˆxå’Œyä½¿ç”¨ç›¸åŒçš„è¡¥å¿å€¼ï¼‰
                    compensation_value = get_compensation_value(robot_coords_inverse[0], robot_coords_inverse[1])
                    z_compensation = 0  # zè¡¥å¿æš‚æ—¶è®¾ä¸º0

                    # åº”ç”¨è¡¥å¿
                    compensated_x = robot_coords_inverse[0] + compensation_value
                    compensated_y = robot_coords_inverse[1] + compensation_value
                    compensated_z = robot_coords_inverse[2] + z_compensation

                    # é™åˆ¶åæ ‡èŒƒå›´
                    x_limited = limit_coordinate(compensated_x, -281.45, 281.45)
                    y_limited = limit_coordinate(compensated_y, -281.45, 281.45)
                    z_limited = limit_coordinate(compensated_z, -70, 412.67)

                    # è®¡ç®—æœ€ç»ˆåæ ‡
                    coords = [x_limited - 8, y_limited, z_limited + 130 + 5, 0, 180, 0]

                    # åªæœ‰åœ¨æ˜ç¡®éœ€è¦å›ºå®šé«˜åº¦æ—¶æ‰ä½¿ç”¨å›ºå®šé«˜åº¦
                    if fixed_height is not None:
                        coords[2] = fixed_height

                    cartesian_points.append(coords)

                    print(f"ç‚¹ {i + 1}: ä¸–ç•Œåæ ‡ {point_cloud} -> æœºå™¨äººåæ ‡ {coords}")

                # # æ£€æŸ¥ç‚¹ä¹‹é—´çš„è·ç¦»ï¼Œè¿‡æ»¤è¿‡äºæ¥è¿‘çš„ç‚¹
                # filtered_points = [cartesian_points[0]]
                # for i in range(1, len(cartesian_points)):
                #     dist = distance_between_points(cartesian_points[i], filtered_points[-1])
                #     if dist > 5:  # åªä¿ç•™è·ç¦»å¤§äº5mmçš„ç‚¹
                #         filtered_points.append(cartesian_points[i])
                #     else:
                #         print(f"è·³è¿‡ç‚¹ {i + 1}ï¼Œä¸ä¸Šä¸€ä¸ªç‚¹è·ç¦»å¤ªè¿‘: {dist:.2f}mm")

                filtered_points = cartesian_points.copy()
                print(f"è¿‡æ»¤åå‰©ä½™ {len(filtered_points)} ä¸ªç‚¹")

                if len(filtered_points) == 0:
                    print("æ²¡æœ‰æœ‰æ•ˆçš„ç‚¹éœ€è¦è¿åŠ¨")
                    return

                # ä½¿ç”¨ç›´çº¿è¿åŠ¨æ¨¡å¼æ‰§è¡Œæ‰€æœ‰ç‚¹
                print(f"\nå¼€å§‹ç›´çº¿è½¨è¿¹è¿åŠ¨ï¼Œå…± {len(filtered_points)} ä¸ªç‚¹...")

                # å…ˆç§»åŠ¨åˆ°ç¬¬ä¸€ä¸ªç‚¹ï¼ˆä½¿ç”¨éçº¿æ€§æ¨¡å¼ç¡®ä¿å¯è¾¾ï¼‰
                print(f"å‡†å¤‡è¿åŠ¨åˆ°èµ·å§‹ç‚¹...")
                mc.sync_send_angles([0.17, 31.2, -116.19, -13.27, 1.66, 116.63], 30, timeout=1)
                mc.sync_send_angles([39.55, -0.17, -59.76, -34.27, 2.54, 128.05], 30, timeout=1)
                result = mc.sync_send_coords(filtered_points[0], speed, mode=0, timeout=0.5)
                if result != 1:
                    print("ç§»åŠ¨åˆ°èµ·å§‹ç‚¹å¤±è´¥ï¼")
                    return

                time.sleep(0.5)

                # ç„¶åä½¿ç”¨ç›´çº¿è¿åŠ¨æ¨¡å¼ä¾æ¬¡è¿åŠ¨åˆ°å…¶ä»–ç‚¹
                success_count = 0
                for i, coords in enumerate(filtered_points):
                    if i == 0:  # ç¬¬ä¸€ä¸ªç‚¹å·²ç»å¤„ç†è¿‡
                        success_count += 1
                        continue

                    print(f"ç›´çº¿è¿åŠ¨åˆ°ç¬¬ {i + 1}/{len(filtered_points)} ä¸ªç‚¹...")

                    # ä½¿ç”¨ç›´çº¿è¿åŠ¨æ¨¡å¼ï¼ˆmode=1ï¼‰
                    result = mc.sync_send_coords(coords, speed, mode=1, timeout=0.05)

                    if result == 1:
                        success_count += 1
                        print(f"æˆåŠŸåˆ°è¾¾ç‚¹ {i + 1}")
                    else:
                        print(f"è¿åŠ¨åˆ°ç‚¹ {i + 1} å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨éçº¿æ€§æ¨¡å¼...")
                        # å¦‚æœç›´çº¿è¿åŠ¨å¤±è´¥ï¼Œå°è¯•éçº¿æ€§æ¨¡å¼
                        result = mc.sync_send_coords(coords, speed, mode=0, timeout=0.05)
                        if result == 1:
                            success_count += 1
                            print(f"ä½¿ç”¨éçº¿æ€§æ¨¡å¼æˆåŠŸåˆ°è¾¾ç‚¹ {i + 1}")
                        else:
                            print(f"ç‚¹ {i + 1} å®Œå…¨è¿åŠ¨å¤±è´¥ï¼Œè·³è¿‡è¯¥ç‚¹")

                    # åœ¨ç‚¹ä¹‹é—´æ·»åŠ çŸ­æš‚åœé¡¿ï¼ˆå¯é€‰ï¼‰
                    if i < len(filtered_points) - 1:
                        time.sleep(0.1)

                print(f"\nè¿åŠ¨å®Œæˆï¼æˆåŠŸåˆ°è¾¾ {success_count}/{len(filtered_points)} ä¸ªç‚¹")
                mc.sync_send_angles([39.55, -0.17, -59.76, -34.27, 2.54, 128.05], 30, timeout=1)
                mc.sync_send_angles([0.17, 31.2, -116.19, -13.27, 1.66, 116.63], 30, timeout=1)

            height = 790  # å›ºå®šé«˜åº¦å€¼
            # å®šä¹‰ç‚¹äº‘åæ ‡åˆ—è¡¨
            point_clouds = [
                # np.array([-85.107887, 78.239586, 870.622925]),
                # np.array([-2.596224, 20.766823, 868.374023]),
                # np.array([-40.959755, -13.706027, 868.326233]),
                # np.array([-115.630562, 5.762152, 869.585449]),
                # np.array([250,236.941483, 895.233643]),
                # np.array([250,236.941483, 895.233643]),
                # np.array([12.415163,-60.981064, 868.282288]),
                # np.array([135.874268,-37.065334, 868.502136]),
                # np.array([103.7227, 23.619373, 750.0898]),
                # np.array([103.722702, 23.61937332, 793.515564]),
                # np.array([45.334656, -40.731045, 790.805969]),

                # å‘¨äº”ç”¨
                np.array([19.08568304, 4.909702972, height]),
                np.array([16.92098316, 4.270843018, height]),
                np.array([15.20927383, 2.799748592, height]),
                np.array([14.25223887, 0.755695824, height]),
                np.array([14.21855292, -1.501056908, height]),
                np.array([15.11415302, -3.572763471, height]),
                np.array([16.78119226, -5.094291586, height]),
                np.array([18.9258598, -5.79747633, height]),
                np.array([21.1701642, -5.558383429, height]),
                np.array([23.1185533, -4.419152314, height]),
                np.array([24.42762918, -2.580569169, height]),
                np.array([24.866671, -0.366678947, height]),
                np.array([24.35829891, 1.832326614, height]),
                np.array([22.99211203, 3.628879154, height]),
                np.array([21.00889682, 4.706341492, height]),
                np.array([18.75818924, 4.874814012, height]),
                np.array([16.63666996, 4.104603922, height]),
                np.array([15.01825061, 2.531458517, height]),
                np.array([14.18817293, 0.432640119, height]),
                np.array([14.29273568, -1.821940611, height]),
                np.array([15.31351, -3.834920349, height]),
                np.array([17.07058737, -5.251517248, height]),
                np.array([19.25428798, -5.822060209, height]),
                np.array([21.47974093, -5.445992687, height]),
                np.array([23.35471659, -4.189595495, height]),
                np.array([24.54875593, -2.274304996, height]),
                np.array([24.85141297, -0.037685594, height]),
                np.array([24.20934529, 2.126065022, height]),
                np.array([22.73571545, 3.835592073, height]),
                np.array([20.69024645, 4.789596369, height]),
                np.array([18.43344627, 4.819937417, height]),
                np.array([16.36306941, 3.921267694, height]),
                np.array([14.84401378, 2.251975137, height]),
                np.array([14.14400855, 0.106267722, height]),
                np.array([14.38642761, -2.137679835, height]),
                np.array([15.52854529, -4.084378276, height]),
                np.array([17.36906668, -5.390727642, height]),
                np.array([19.5836052, -5.826487641, height]),
                np.array([21.78185486, -5.314856835, height]),
                np.array([23.57638051, -3.946008672, height]),
                np.array([24.65090223, -1.961198675, height]),
                np.array([24.81603865, 0.289756143, height]),
                np.array([24.04268498, 2.410131518, height]),
                np.array([22.46714255, 4.026217431, height]),
                np.array([20.36709615, 4.853183422, height]),
                np.array([18.11267287, 4.74527913, height]),
                np.array([16.1012083, 3.721522375, height]),
                np.array([14.68721722, 1.962347319, height]),
                np.array([14.11991148, -0.22219653, height]),
                np.array([14.49927707, -2.447089649, height]),
                np.array([15.75845189, -4.320201069, height]),
                np.array([17.67551004, -5.511400329, height]),
                np.array([19.91257558, -5.810742011, height]),
                np.array([22.07537217, -5.16546801, height]),
                np.array([23.78271319, -3.689305999, height]),
                np.array([24.73368472, -1.642425257, height]),
                np.array([24.7606808, 0.614417415, height]),
                np.array([23.85894343, 2.683460034, height]),
                np.array([22.18740123, 4.200039833, height]),
                np.array([20.04065865, 4.896864015, height]),
                np.array([17.79707286, 4.651119336, height]),
                np.array([15.85206936, 3.506117585, height]),
                np.array([14.54844937, 1.663662003, height]),
                np.array([14.11597215, -0.551519951, height]),
                np.array([14.63086056, -2.749008875, height]),
                np.array([16.00236699, -4.541503711, height]),
                np.array([17.98876742, -5.613082438, height]),
                np.array([20.23996452, -5.77488241, height]),
                np.array([22.35919133, -4.998386849, height]),
                np.array([23.97294027, -3.420450849, height]),
                np.array([24.79679274, -1.31918106, height]),
                np.array([24.68554716, 0.935079807, height]),
                np.array([23.65881021, 2.945024803, height]),
                np.array([21.89754133, 4.356406945, height]),
                np.array([19.71215904, 4.92047422, height]),
                np.array([17.48783065, 4.537811405, height]),
                np.array([15.61658758, 3.275861712, height]),
                np.array([14.42823102, 1.357040118, height]),
                np.array([14.13220535, -0.880466629, height]),
                np.array([14.78068426, -3.042304446, height]),
                np.array([16.2593752, -4.747455681, height]),
                np.array([18.30766318, -5.695392369, height]),
                np.array([20.56454339, -5.719043414, height]),
                np.array([22.63224722, -4.814240389, height]),
                np.array([24.14634786, -3.140452204, height]),
                np.array([24.83998946, -0.99267918, height]),
                np.array([24.5909197, 1.250539911, height]),
                np.array([23.4430364, 3.193844202, height]),
                np.array([21.59865067, 4.494731941, height]),
                np.array([19.38283014, 4.923925433, height]),
                np.array([17.18610678, 4.405780568, height]),
                np.array([15.39564671, 3.031618878, height]),
                np.array([14.32701332, 1.043632379, height]),
                np.array([14.16855016, -1.207802066, height]),
                np.array([14.9481859, -3.32587566, height]),
                np.array([16.528512, -4.937284067, height]),
                np.array([18.63100056, -5.758021223, height]),
                np.array([20.88509407, -5.643434582, height]),
                np.array([22.89351507, -4.613719708, height]),
                np.array([24.30228518, -2.850360865, height]),
                np.array([24.86311275, -0.664144939, height]),
                np.array([24.47715354, 1.559613844, height]),
                np.array([23.21243176, 3.428984442, height]),
                np.array([21.29185093, 4.614495702, height]),
                np.array([19.05390789, 4.907204699, height]),
                np.array([16.8930336, 4.25552232, height]),
                np.array([15.19007589, 2.774305697, height]),
                np.array([14.24517613, 0.724614968, height]),
                np.array([14.22487017, -1.532297814, height]),
                np.array([15.13273687, -3.598658308, height]),
                np.array([16.80876735, -5.110276463, height]),
                np.array([18.95756611, -5.80073396, height]),
                np.array([21.20041357, -5.548339663, height]),
                np.array([23.14201438, -4.397577338, height]),
                np.array([24.44016702, -2.551265509, height]),
                np.array([24.86607584, -0.334811288, height]),
                np.array([24.34467565, 1.861141688, height]),
                np.array([22.96786172, 3.649563071, height]),
                np.array([20.97829352, 4.715248771, height]),
                np.array([18.72662668, 4.870374771, height]),

            ]

            # æ‰§è¡Œè¿åŠ¨
            move_to_point_clouds(point_clouds)
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")

    def _stop_grinding_procedure(self):
        """åœæ­¢æ‰“ç£¨ç¨‹åº"""
        # æ›´æ–°UIçŠ¶æ€
        self.grinding_button.setText("å¯åŠ¨æ‰“ç£¨")
        self.grinding_button.setStyleSheet("")
        self.grinding_status_indicator.setStyleSheet("background-color: #FF0000; border-radius: 10px;")

        # åœæ­¢æœºæ¢°è‡‚
        if hasattr(self, 'grinding_controller') and self.grinding_controller:
            try:
                self.grinding_controller.mc.stop()
            except Exception as e:
                print(f"åœæ­¢æœºæ¢°è‡‚æ—¶å‡ºé”™: {e}")

        # åœæ­¢ç”µæœº
        if hasattr(self, 'motor_controller') and self.motor_controller:
            try:
                self.motor_controller.emergency_stop()
            except Exception as e:
                print(f"åœæ­¢ç”µæœºæ—¶å‡ºé”™: {e}")

    def _run_grinding_procedure(self, camera_coordinates_3d, user_offset_x, user_offset_y, user_offset_z=0):
        """ä½¿ç”¨çº¿ç¨‹æ± çš„æ‰“ç£¨å‡½æ•° - ä½¿ç”¨ç‚¹äº‘ç›´æ¥è¿åŠ¨æ¨¡å¼"""
        if not self.connection or not self.connection.is_connected():
            print("æœªè¿æ¥åˆ°æœºå™¨äººï¼Œæ— æ³•æ‰§è¡Œæ‰“ç£¨")
            return

        # é…ç½®æ ‡å®šçŸ©é˜µ
        self.T = np.array([
            [-2.74280449e-02, -9.99601611e-01, -6.65752354e-03, 6.48263423e+01],
            [-9.99259510e-01, 2.72376602e-02, 2.71761376e-02, 2.04309745e+02],
            [-2.69839756e-02, 7.39798203e-03, -9.99608491e-01, 8.88548188e+02],
            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]
        ])

        def transform_point_inverse(T, point):
            """ä½¿ç”¨é€†çŸ©é˜µå˜æ¢ç‚¹"""
            point_homogeneous = np.append(point, 1.0)
            T_inv = np.linalg.inv(T)
            robot_point_homogeneous = T_inv @ point_homogeneous
            robot_point = robot_point_homogeneous[:3] / robot_point_homogeneous[3]
            return robot_point

        # åæ ‡è¡¥å¿å‡½æ•° - åŸºäºxå’Œyä¸­ç»å¯¹å€¼è¾ƒå¤§çš„å€¼åˆ¤æ–­
        def get_compensation_value(x, y):
            max_abs_value = max(abs(x), abs(y))
            if max_abs_value <= 100:
                return 0  # 100mmä»¥å†…ä¸éœ€è¦è¡¥å¿
            elif max_abs_value <= 200:
                return 0  # 100-200mmè¡¥å¿2mm
            else:
                return 0  # 200mmä»¥ä¸Šè¡¥å¿4mm

        # åæ ‡èŒƒå›´é™åˆ¶å‡½æ•°
        def limit_coordinate(value, min_val, max_val):
            return max(min(value, max_val), min_val)

        # è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»
        def distance_between_points(p1, p2):
            return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2 + (p1[2] - p2[2]) ** 2) ** 0.5

        # ç”µæœºæ§åˆ¶æ ‡å¿—
        motor_started = False

        # è·å–æœºå™¨äººæ§åˆ¶å¯¹è±¡
        try:
            mc = self.connection.get_robot()  # è·å–å®é™…çš„æœºå™¨äººæ§åˆ¶å¯¹è±¡
            if mc is None:
                print("æ— æ³•è·å–æœºå™¨äººæ§åˆ¶å¯¹è±¡")
                return
        except Exception as e:
            print(f"è·å–æœºå™¨äººæ§åˆ¶å¯¹è±¡å¤±è´¥: {str(e)}")
            return

        try:
            # å¯åŠ¨ç”µæœº
            if hasattr(self, 'motor_controller') and self.motor_controller:
                try:
                    motor_speed = getattr(self, 'motor_max_speed', 400)
                    print(f"å¯åŠ¨æ‰“ç£¨ç”µæœºï¼Œè½¬é€Ÿ: {motor_speed} RPM")
                    self.motor_controller.stop()
                    self.motor_controller.set_speed(motor_speed)
                    self.motor_controller.forward()
                    motor_started = True
                    time.sleep(0.5)
                except Exception as motor_err:
                    print(f"å¯åŠ¨ç”µæœºå¤±è´¥: {motor_err}")

            # æ£€æŸ¥åæ ‡æ•°æ®
            if not camera_coordinates_3d or len(camera_coordinates_3d) == 0:
                print("æ²¡æœ‰æä¾›æœ‰æ•ˆçš„ä¸‰ç»´åæ ‡æ•°æ®")
                return

            print(f"å¼€å§‹å¤„ç† {len(camera_coordinates_3d)} ä¸ªä¸‰ç»´åæ ‡ç‚¹")
            print(f"ä½¿ç”¨çš„ç”¨æˆ·åç§»é‡: X={user_offset_x}, Y={user_offset_y}, Z={user_offset_z}")

            # å­˜å‚¨æ‰€æœ‰ç¬›å¡å°”åæ ‡ç‚¹
            cartesian_points = []

            # è®¡ç®—æ‰€æœ‰ç‚¹çš„ç¬›å¡å°”åæ ‡
            for i, point_cloud in enumerate(camera_coordinates_3d):
                # æ£€æŸ¥åœæ­¢è¯·æ±‚
                if hasattr(self, 'current_grinding_task_id'):
                    task_status = self.thread_pool.get_task_status(self.current_grinding_task_id)
                    if task_status != 'pending':  # å¦‚æœä»»åŠ¡ä¸å†æ˜¯pendingçŠ¶æ€ï¼Œè¯´æ˜è¢«å–æ¶ˆäº†
                        print("æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢åæ ‡è®¡ç®—")
                        return

                print(f"è®¡ç®—ç¬¬ {i + 1}/{len(camera_coordinates_3d)} ä¸ªç‚¹çš„åæ ‡...")

                # å°†ç‚¹äº‘åæ ‡è½¬æ¢ä¸ºæœºå™¨äººåæ ‡ç³»
                try:
                    robot_coords_inverse = transform_point_inverse(self.T, point_cloud)
                    print(f"ç‚¹äº‘åæ ‡ {point_cloud} -> æœºå™¨äººåæ ‡ {robot_coords_inverse}")
                except Exception as e:
                    print(f"åæ ‡è½¬æ¢å¤±è´¥: {str(e)}")
                    continue

                # åº”ç”¨ç”¨æˆ·åç§»é‡
                center_x = robot_coords_inverse[0] + user_offset_x
                center_y = robot_coords_inverse[1] + user_offset_y
                center_z = robot_coords_inverse[2] + user_offset_z

                # è·å–è¡¥å¿å€¼
                compensation_value = get_compensation_value(center_x, center_y)

                # åº”ç”¨è¡¥å¿
                compensated_x = center_x + compensation_value
                compensated_y = center_y + compensation_value
                compensated_z = center_z

                # é™åˆ¶åæ ‡èŒƒå›´
                x_limited = limit_coordinate(compensated_x, -281.45, 281.45)
                y_limited = limit_coordinate(compensated_y, -281.45, 281.45)
                z_limited = limit_coordinate(compensated_z, -70, 412.67)

                # è®¡ç®—æœ€ç»ˆåæ ‡
                coords = [x_limited, y_limited, z_limited, 0, 180, 0]
                cartesian_points.append(coords)

                print(f"ç‚¹ {i + 1}: æœ€ç»ˆåæ ‡ {coords}")

            filtered_points = cartesian_points.copy()
            print(f"è¿‡æ»¤åå‰©ä½™ {len(filtered_points)} ä¸ªç‚¹")

            if len(filtered_points) == 0:
                print("æ²¡æœ‰æœ‰æ•ˆçš„ç‚¹éœ€è¦è¿åŠ¨")
                return

            # ä½¿ç”¨ç›´çº¿è¿åŠ¨æ¨¡å¼æ‰§è¡Œæ‰€æœ‰ç‚¹
            print(f"\nå¼€å§‹ç›´çº¿è½¨è¿¹è¿åŠ¨ï¼Œå…± {len(filtered_points)} ä¸ªç‚¹...")

            # å…ˆç§»åŠ¨åˆ°å®‰å…¨ä½ç½®
            print("ç§»åŠ¨åˆ°å®‰å…¨ä½ç½®...")
            mc.sync_send_angles([0.17, 31.2, -116.19, -13.27, 1.66, 116.63], 30, timeout=2)
            mc.sync_send_angles([39.55, -0.17, -59.76, -34.27, 2.54, 128.05], 30, timeout=2)

            # ç§»åŠ¨åˆ°ç¬¬ä¸€ä¸ªç‚¹çš„å®‰å…¨é«˜åº¦
            if len(filtered_points) > 0:
                first_point_safe = filtered_points[0].copy()
                first_point_safe[2] += 100  # Zè½´é«˜åº¦+100
                print(f"ç§»åŠ¨åˆ°ç¬¬ä¸€ä¸ªç‚¹çš„å®‰å…¨é«˜åº¦: {first_point_safe}")
                result = mc.sync_send_coords(first_point_safe, 20, mode=0, timeout=2)
                if result != 1:
                    print("ç§»åŠ¨åˆ°å®‰å…¨é«˜åº¦å¤±è´¥ï¼Œç»ˆæ­¢è¿åŠ¨")
                    return

            # ä¾æ¬¡è¿åŠ¨åˆ°æ‰€æœ‰ç‚¹
            success_count = 0
            for i, coords in enumerate(filtered_points):
                # æ£€æŸ¥åœæ­¢è¯·æ±‚
                if hasattr(self, 'current_grinding_task_id'):
                    task_status = self.thread_pool.get_task_status(self.current_grinding_task_id)
                    if task_status != 'pending':
                        print("æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢è¿åŠ¨")
                        return

                print(f"ç›´çº¿è¿åŠ¨åˆ°ç¬¬ {i + 1}/{len(filtered_points)} ä¸ªç‚¹...")

                try:
                    # ä½¿ç”¨åŒæ­¥ç›´çº¿è¿åŠ¨æ¨¡å¼
                    result = mc.sync_send_coords(coords, 20, mode=0, timeout=2)
                    time.sleep(0.1)  # çŸ­æš‚åœé¡¿ï¼Œç¡®ä¿è¿åŠ¨å®Œæˆ

                    if result == 1:
                        success_count += 1
                        print(f"æˆåŠŸåˆ°è¾¾ç‚¹ {i + 1}")
                    else:
                        print(f"ç‚¹ {i + 1} è¿åŠ¨å¤±è´¥ï¼Œè·³è¿‡è¯¥ç‚¹")
                except Exception as coord_err:
                    print(f"ç›´çº¿è¿åŠ¨å¤±è´¥: {coord_err}ï¼Œè·³è¿‡è¯¥ç‚¹")

            print(f"\nè¿åŠ¨å®Œæˆï¼æˆåŠŸåˆ°è¾¾ {success_count}/{len(filtered_points)} ä¸ªç‚¹")

            # è¿”å›åˆ°å®‰å…¨ä½ç½®
            print("è¿”å›åˆ°å®‰å…¨ä½ç½®...")

            # å…ˆæŠ¬å‡åˆ°å®‰å…¨é«˜åº¦
            if len(filtered_points) > 0:
                last_point_safe = filtered_points[-1].copy()
                last_point_safe[2] += 100
                mc.sync_send_coords(last_point_safe, 20, mode=0, timeout=2)

            # ç»è¿‡è¿‡æ¸¡ç‚¹è¿”å›å®‰å…¨ä½ç½®
            mc.sync_send_angles([39.55, -0.17, -59.76, -34.27, 2.54, 128.05], 30, timeout=2)
            mc.sync_send_angles([0.17, 31.2, -116.19, -13.27, 1.66, 116.63], 30, timeout=2)

            safe_position = [110.4, -56.0, 205.6, 179.53, -6.68, 151.89]
            result = mc.sync_send_coords(safe_position, 50, 0, 2)

            print("æ‰€æœ‰åæ ‡ç‚¹æ‰“ç£¨å®Œæˆ")
            return "success"  # è¿”å›æˆåŠŸç»“æœ

        except Exception as e:
            print(f"æ‰“ç£¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            raise e
        finally:
            # åœæ­¢ç”µæœº
            if motor_started and hasattr(self, 'motor_controller') and self.motor_controller:
                try:
                    print("åœæ­¢æ‰“ç£¨ç”µæœº...")
                    self.motor_controller.emergency_stop()
                except Exception as motor_err:
                    print(f"åœæ­¢ç”µæœºæ—¶å‡ºé”™: {motor_err}")
            print("æ‰“ç£¨çº¿ç¨‹å®Œæˆ")

    def get_3d_coordinates(self, server_host='localhost', server_port=8888):
        """è·å–ä¸‰ç»´åæ ‡æ•°æ®çš„æ–¹æ³•"""
        # try:
        #     detector = PointCloudDefectDetector(
        #         defect_api_url="http://192.168.25.184:9000",
        #         camera_api_url="http://192.168.25.184:8000",
        #         standard_part_path=r"E:\pointcloud_ai_project2\data\npy\standard_part.npy"
        #     )
        #
        #     # æ‰§è¡Œå®Œæ•´æµç¨‹
        #     result = detector.get_3d_coordinates()
        #
        #
        #     if result['success']:
        #         print(f"âœ“ æ“ä½œæˆåŠŸ!")
        #         print(f"æ‰«æID: {result['scan_id']}")
        #         print(f"æœåŠ¡ç«¯è·¯å¾„: {result['server_path']}")
        #         print(f"ç‚¹äº‘æ–‡ä»¶: {result['pointcloud_file']}")
        #         print(f"å‘ç°ç¼ºé™·ç‚¹æ•°é‡: {result['num_defects']}")
        #         print(f"å•ä½: {result['unit']}")
        #
        #         # æ‰“å°æ‰€æœ‰ç¼ºé™·ç‚¹
        #         if result['defect_points']:
        #             print(f"\næ‰€æœ‰ {len(result['defect_points'])} ä¸ªç¼ºé™·ç‚¹åæ ‡:")
        #             for i, point in enumerate(result['defect_points']):
        #                 print(f"ç¼ºé™·ç‚¹ {i + 1}: ({point['x']:.3f}, {point['y']:.3f}, {point['z']:.3f}), "
        #                       f"è·ç¦»: {point['distance']:.3f}{result['unit']}")
        #     else:
        #         print(f"âœ— æ“ä½œå¤±è´¥: {result['message']}")
        #         if 'server_path' in result:
        #             print(f"æœåŠ¡ç«¯è·¯å¾„: {result.get('server_path', 'æœªçŸ¥')}")
        #         if 'pointcloud_file' in result:
        #             print(f"ç‚¹äº‘æ–‡ä»¶: {result.get('pointcloud_file', 'æœªçŸ¥')}")
        #         if 'tried_files' in result:
        #             print(f"å°è¯•çš„æ–‡ä»¶: {result.get('tried_files', [])}")
        #
        #     return result
        # except Exception as e:
        #     print(f"è·å–3Dåæ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        #     return {'success': False, 'message': str(e)}

        DY = [
    [19.08568304, 4.909702972, 790],
    [16.92098316, 4.270843018, 790],
    [15.20927383, 2.799748592, 790],
    [14.25223887, 0.755695824, 790],
    [14.21855292, -1.501056908, 790],
    [15.11415302, -3.572763471, 790],
    [16.78119226, -5.094291586, 790],
    [18.9258598, -5.79747633, 790],
    [21.1701642, -5.558383429, 790],
    [23.1185533, -4.419152314, 790],
    [24.42762918, -2.580569169, 790],
    [24.866671, -0.366678947, 790],
    [24.35829891, 1.832326614, 790],
    [22.99211203, 3.628879154, 790],
    [21.00889682, 4.706341492, 790],
    [18.75818924, 4.874814012, 790],
    [16.63666996, 4.104603922, 790],
    [15.01825061, 2.531458517, 790],
    [14.18817293, 0.432640119, 790],
    [14.29273568, -1.821940611, 790],
    [15.31351, -3.834920349, 790],
    [17.07058737, -5.251517248, 790],
    [19.25428798, -5.822060209, 790],
    [21.47974093, -5.445992687, 790],
    [23.35471659, -4.189595495, 790],
    [24.54875593, -2.274304996, 790],
    [24.85141297, -0.037685594, 790],
    [24.20934529, 2.126065022, 790],
    [22.73571545, 3.835592073, 790],
    [20.69024645, 4.789596369, 790],
    [18.43344627, 4.819937417, 790],
    [16.36306941, 3.921267694, 790],
    [14.84401378, 2.251975137, 790],
    [14.14400855, 0.106267722, 790],
    [14.38642761, -2.137679835, 790],
    [15.52854529, -4.084378276, 790],
    [17.36906668, -5.390727642, 790],
    [19.5836052, -5.826487641, 790],
    [21.78185486, -5.314856835, 790],
    [23.57638051, -3.946008672, 790],
    [24.65090223, -1.961198675, 790],
    [24.81603865, 0.289756143, 790],
    [24.04268498, 2.410131518, 790],
    [22.46714255, 4.026217431, 790],
    [20.36709615, 4.853183422, 790],
    [18.11267287, 4.74527913, 790],
    [16.1012083, 3.721522375, 790],
    [14.68721722, 1.962347319, 790],
    [14.11991148, -0.22219653, 790],
    [14.49927707, -2.447089649, 790],
    [15.75845189, -4.320201069, 790],
    [17.67551004, -5.511400329, 790],
    [19.91257558, -5.810742011, 790],
    [22.07537217, -5.16546801, 790],
    [23.78271319, -3.689305999, 790],
    [24.73368472, -1.642425257, 790],
    [24.7606808, 0.614417415, 790],
    [23.85894343, 2.683460034, 790],
    [22.18740123, 4.200039833, 790],
    [20.04065865, 4.896864015, 790],
    [17.79707286, 4.651119336, 790],
    [15.85206936, 3.506117585, 790],
    [14.54844937, 1.663662003, 790],
    [14.11597215, -0.551519951, 790],
    [14.63086056, -2.749008875, 790],
    [16.00236699, -4.541503711, 790],
    [17.98876742, -5.613082438, 790],
    [20.23996452, -5.77488241, 790],
    [22.35919133, -4.998386849, 790],
    [23.97294027, -3.420450849, 790],
    [24.79679274, -1.31918106, 790],
    [24.68554716, 0.935079807, 790],
    [23.65881021, 2.945024803, 790],
    [21.89754133, 4.356406945, 790],
    [19.71215904, 4.92047422, 790],
    [17.48783065, 4.537811405, 790],
    [15.61658758, 3.275861712, 790],
    [14.42823102, 1.357040118, 790],
    [14.13220535, -0.880466629, 790],
    [14.78068426, -3.042304446, 790],
    [16.2593752, -4.747455681, 790],
    [18.30766318, -5.695392369, 790],
    [20.56454339, -5.719043414, 790],
    [22.63224722, -4.814240389, 790],
    [24.14634786, -3.140452204, 790],
    [24.83998946, -0.99267918, 790],
    [24.5909197, 1.250539911, 790],
    [23.4430364, 3.193844202, 790],
    [21.59865067, 4.494731941, 790],
    [19.38283014, 4.923925433, 790],
    [17.18610678, 4.405780568, 790],
    [15.39564671, 3.031618878, 790],
    [14.32701332, 1.043632379, 790],
    [14.16855016, -1.207802066, 790],
    [14.9481859, -3.32587566, 790],
    [16.528512, -4.937284067, 790],
    [18.63100056, -5.758021223, 790],
    [20.88509407, -5.643434582, 790],
    [22.89351507, -4.613719708, 790],
    [24.30228518, -2.850360865, 790],
    [24.86311275, -0.664144939, 790],
    [24.47715354, 1.559613844, 790],
    [23.21243176, 3.428984442, 790],
    [21.29185093, 4.614495702, 790],
    [19.05390789, 4.907204699, 790],
    [16.8930336, 4.25552232, 790],
    [15.19007589, 2.774305697, 790],
    [14.24517613, 0.724614968, 790],
    [14.22487017, -1.532297814, 790],
    [15.13273687, -3.598658308, 790],
    [16.80876735, -5.110276463, 790],
    [18.95756611, -5.80073396, 790],
    [21.20041357, -5.548339663, 790],
    [23.14201438, -4.397577338, 790],
    [24.44016702, -2.551265509, 790],
    [24.86607584, -0.334811288, 790],
    [24.34467565, 1.861141688, 790],
    [22.96786172, 3.649563071, 790],
    [20.97829352, 4.715248771, 790],
    [18.72662668, 4.870374771, 790]
]
        return DY

    def _point_cloud_worker(self):
        """ç‚¹äº‘æ•°æ®è·å–çš„å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        return self.get_3d_coordinates()

    def keh(self):
        """è·å–ç‚¹äº‘æ•°æ®çš„ä¸»æ–¹æ³• - ä½¿ç”¨çº¿ç¨‹æ± """
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œ
        if self.task_ids.get('point_cloud') is not None:
            print("ç‚¹äº‘æ•°æ®è·å–ä»»åŠ¡å·²åœ¨è¿è¡Œ")
            return

        # æ˜¾ç¤ºåŠ è½½æç¤º
        self.show_loading_message("æ­£åœ¨è·å–3Dåæ ‡æ•°æ®...")
        time.sleep(3)
        # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        task_id = self.thread_pool.submit_task(self._point_cloud_worker)
        self.task_ids['point_cloud'] = task_id
        print(f"å¯åŠ¨ç‚¹äº‘æ•°æ®è·å–ä»»åŠ¡ï¼ŒID: {task_id}")

    def _handle_point_cloud_completed(self, result):
        """å¤„ç†ç‚¹äº‘æ•°æ®è·å–ä»»åŠ¡å®Œæˆ"""
        try:
            # ç¡®ä¿å…³é—­åŠ è½½æç¤º
            self.hide_loading_message()

            # è°ƒç”¨displayæ–¹æ³•
            self.display()

            # æ˜¾ç¤ºç»“æœå¼¹çª—
            self.show_result_dialog(result)

            print("ç‚¹äº‘æ•°æ®è·å–ä»»åŠ¡å®Œæˆï¼Œç»“æœ:", result)
        except Exception as e:
            print(f"å¤„ç†ç‚¹äº‘æ•°æ®ç»“æœæ—¶å‡ºé”™: {e}")
            self.hide_loading_message()

    def _handle_point_cloud_failed(self, exception):
        """å¤„ç†ç‚¹äº‘æ•°æ®è·å–ä»»åŠ¡å¤±è´¥"""
        try:
            self.hide_loading_message()
            from PyQt5.QtWidgets import QMessageBox
            QMessageBox.warning(self, "é”™è¯¯", f"è·å–3Dåæ ‡æ—¶å‘ç”Ÿé”™è¯¯: {str(exception)}")
        except Exception as e:
            print(f"å¤„ç†ç‚¹äº‘æ•°æ®è·å–å¤±è´¥æ—¶å‡ºé”™: {e}")

    def _process_3d_data_result(self, dy):
        """å¤„ç†3Dæ•°æ®ç»“æœï¼ˆåœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰"""
        try:
            # ç¡®ä¿å…³é—­åŠ è½½æç¤º
            self.hide_loading_message()

            # è°ƒç”¨displayæ–¹æ³•
            self.display()

            # æ˜¾ç¤ºç»“æœå¼¹çª—
            self.show_result_dialog(dy)

            print("è·å–åˆ°çš„æ•°æ®:", dy)
        except Exception as e:
            print(f"å¤„ç†3Dæ•°æ®ç»“æœæ—¶å‡ºé”™: {e}")
            self.hide_loading_message()

    def _handle_3d_data_error(self, error_msg):
        """å¤„ç†3Dæ•°æ®é”™è¯¯ï¼ˆåœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰"""
        try:
            self.hide_loading_message()
            from PyQt5.QtWidgets import QMessageBox
            QMessageBox.warning(self, "é”™è¯¯", f"è·å–3Dåæ ‡æ—¶å‘ç”Ÿé”™è¯¯: {error_msg}")
        except Exception as e:
            print(f"å¤„ç†é”™è¯¯æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

    def show_loading_message(self, message="å¤„ç†ä¸­..."):
        """æ˜¾ç¤ºåŠ è½½æç¤º - ç›´æ¥ä½¿ç”¨ä¸»ç•Œé¢æ ·å¼è¡¨"""
        try:
            # å…ˆå…³é—­å¯èƒ½å­˜åœ¨çš„æ—§å¯¹è¯æ¡†
            self.hide_loading_message()

            from PyQt5.QtWidgets import QMessageBox, QApplication, QLabel, QVBoxLayout, QDialog, QProgressBar
            from PyQt5.QtCore import Qt

            # åˆ›å»ºè‡ªå®šä¹‰åŠ è½½å¯¹è¯æ¡†
            self.loading_dialog = QDialog(self)
            self.loading_dialog.setWindowTitle("è¯·ç¨å€™")
            self.loading_dialog.setModal(True)
            self.loading_dialog.setFixedSize(300, 120)
            self.loading_dialog.setWindowFlags(Qt.Dialog | Qt.CustomizeWindowHint | Qt.WindowTitleHint)

            # ç›´æ¥åº”ç”¨ä¸»ç•Œé¢çš„æ ·å¼è¡¨
            self.loading_dialog.setStyleSheet(self.styleSheet())

            # åˆ›å»ºå¸ƒå±€å’Œæ§ä»¶
            layout = QVBoxLayout(self.loading_dialog)

            # æ·»åŠ æ¶ˆæ¯æ ‡ç­¾
            label = QLabel(message)
            label.setAlignment(Qt.AlignCenter)
            label.setStyleSheet("font-size: 10pt; padding: 10px;")
            layout.addWidget(label)

            # æ·»åŠ è¿›åº¦æ¡ï¼ˆä¸ç¡®å®šæ¨¡å¼ï¼‰
            progress_bar = QProgressBar()
            progress_bar.setRange(0, 0)  # ä¸ç¡®å®šæ¨¡å¼
            progress_bar.setTextVisible(False)
            layout.addWidget(progress_bar)

            # æ˜¾ç¤ºå¯¹è¯æ¡†
            self.loading_dialog.show()

            # å¼ºåˆ¶å¤„ç†äº‹ä»¶ï¼Œç¡®ä¿å¯¹è¯æ¡†æ˜¾ç¤º
            QApplication.processEvents()
        except Exception as e:
            print(f"æ˜¾ç¤ºåŠ è½½æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    def hide_loading_message(self):
        """éšè—åŠ è½½æç¤º - å®‰å…¨ç‰ˆæœ¬"""
        try:
            if hasattr(self, 'loading_dialog') and self.loading_dialog:
                self.loading_dialog.close()
                self.loading_dialog.deleteLater()
                del self.loading_dialog
        except Exception as e:
            print(f"éšè—åŠ è½½æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    def show_result_dialog(self, result):
        """æ˜¾ç¤ºç»“æœå¼¹çª— - ç›´æ¥ä½¿ç”¨ä¸»ç•Œé¢æ ·å¼è¡¨"""
        try:
            from PyQt5.QtWidgets import (QTextEdit, QVBoxLayout, QDialog,
                                         QPushButton, QScrollArea, QWidget, QLabel, QHBoxLayout)
            from PyQt5.QtCore import Qt

            # åˆ›å»ºè‡ªå®šä¹‰å¯¹è¯æ¡†
            dialog = QDialog(self)
            dialog.setWindowTitle("3Dåæ ‡è·å–ç»“æœ")
            dialog.setMinimumWidth(700)
            dialog.setMinimumHeight(600)

            # ç›´æ¥åº”ç”¨ä¸»ç•Œé¢çš„æ ·å¼è¡¨
            dialog.setStyleSheet(self.styleSheet())

            # ä¸»å¸ƒå±€
            main_layout = QVBoxLayout(dialog)

            # æ ‡é¢˜
            title_label = QLabel("3Dåæ ‡è·å–ç»“æœ")
            title_label.setStyleSheet("""
                QLabel {
                    font-size: 14pt;
                    font-weight: bold;
                    padding: 10px;
                    background-color: #252526;
                    border-radius: 3px;
                }
            """)
            title_label.setAlignment(Qt.AlignCenter)
            main_layout.addWidget(title_label)

            # åŸºæœ¬ä¿¡æ¯åŒºåŸŸ
            info_widget = QWidget()
            info_layout = QVBoxLayout(info_widget)

            if result['success']:
                status_text = "âœ“ 3Dåæ ‡è·å–æˆåŠŸï¼"
                status_style = "color: #4EC9B0; font-weight: bold;"
            else:
                status_text = "âœ— 3Dåæ ‡è·å–å¤±è´¥"
                status_style = "color: #F44747; font-weight: bold;"

            status_label = QLabel(status_text)
            status_label.setStyleSheet(f"QLabel {{ {status_style} font-size: 11pt; padding: 5px; }}")
            info_layout.addWidget(status_label)

            # è¯¦ç»†ä¿¡æ¯
            if result['success']:
                details_text = f"""
                <table>
                <tr><td style="color: #9CDCFE; padding-right: 10px;">æ‰«æID:</td><td>{result['scan_id']}</td></tr>
                <tr><td style="color: #9CDCFE; padding-right: 10px;">ç¼ºé™·ç‚¹æ•°é‡:</td><td>{result['num_defects']}</td></tr>
                <tr><td style="color: #9CDCFE; padding-right: 10px;">å•ä½:</td><td>{result['unit']}</td></tr>
                </table>
                """
            else:
                details_text = f"é”™è¯¯ä¿¡æ¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}"

            details_label = QLabel(details_text)
            details_label.setStyleSheet("QLabel { font-size: 10pt; padding: 5px; }")
            info_layout.addWidget(details_label)

            main_layout.addWidget(info_widget)

            # æ·»åŠ æ‰€æœ‰ç¼ºé™·ç‚¹ï¼ˆå¦‚æœæˆåŠŸä¸”æœ‰æ•°æ®ï¼‰
            if result['success'] and result['defect_points']:
                # æ·»åŠ åˆ†éš”çº¿
                separator = QLabel()
                separator.setFrameStyle(QLabel.HLine)
                separator.setStyleSheet("QLabel { background-color: #404040; }")
                separator.setFixedHeight(1)
                main_layout.addWidget(separator)

                # ç¼ºé™·ç‚¹æ ‡é¢˜
                defects_title = QLabel(f"æ‰€æœ‰ç¼ºé™·ç‚¹åæ ‡ ({len(result['defect_points'])} ä¸ª)")
                defects_title.setStyleSheet(
                    "QLabel { font-size: 11pt; font-weight: bold; color: #CE9178; padding: 5px; }")
                main_layout.addWidget(defects_title)

                # åˆ›å»ºæ»šåŠ¨åŒºåŸŸæ˜¾ç¤ºæ‰€æœ‰ç¼ºé™·ç‚¹
                scroll_area = QScrollArea()
                scroll_widget = QWidget()
                scroll_layout = QVBoxLayout(scroll_widget)

                # æ·»åŠ æ‰€æœ‰ç¼ºé™·ç‚¹
                defects_text = ""
                for i, point in enumerate(result['defect_points']):
                    defects_text += f"ç¼ºé™·ç‚¹ {i + 1}:\n"
                    defects_text += f"  åæ ‡: ({point['x']:.3f}, {point['y']:.3f}, {point['z']:.3f})\n"
                    defects_text += f"  è·ç¦»: {point['distance']:.3f}{result['unit']}\n"
                    defects_text += "-" * 60 + "\n\n"

                defects_edit = QTextEdit()
                defects_edit.setPlainText(defects_text)
                defects_edit.setReadOnly(True)
                defects_edit.setStyleSheet("font-family: Consolas, 'Courier New', monospace; font-size: 9pt;")
                scroll_layout.addWidget(defects_edit)

                scroll_area.setWidget(scroll_widget)
                scroll_area.setWidgetResizable(True)
                main_layout.addWidget(scroll_area)

            # æ·»åŠ ç¡®å®šæŒ‰é’®
            button_layout = QHBoxLayout()
            button_layout.addStretch()

            ok_button = QPushButton("ç¡®å®š")
            ok_button.clicked.connect(dialog.accept)
            button_layout.addWidget(ok_button)

            button_layout.addStretch()
            main_layout.addLayout(button_layout)

            dialog.exec_()

        except Exception as e:
            print(f"æ˜¾ç¤ºç»“æœå¯¹è¯æ¡†æ—¶å‡ºé”™: {e}")
            # å›é€€åˆ°ç®€å•æ¶ˆæ¯æ¡†ï¼Œä½¿ç”¨ä¸»ç•Œé¢æ ·å¼
            from PyQt5.QtWidgets import QMessageBox
            msg_box = QMessageBox(self)
            msg_box.setWindowTitle("3Dåæ ‡è·å–ç»“æœ")
            msg_box.setStyleSheet(self.styleSheet())

            if result['success']:
                msg_box.setIcon(QMessageBox.Information)
                msg_box.setText("æ“ä½œæˆåŠŸå®Œæˆï¼")
            else:
                msg_box.setIcon(QMessageBox.Warning)
                msg_box.setText(f"æ“ä½œå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

            msg_box.exec_()

    def display(self):

        try:
            image_path = "/home/er/MasterComputer/UI/default (3).jfif"
            if os.path.exists(image_path):
                pixmap = QPixmap(image_path)

                # ç¼©æ”¾å›¾åƒä»¥é€‚åº”æ ‡ç­¾å¤§å°
                scaled_pixmap = pixmap.scaled(
                    self.detection_label.width(),
                    self.detection_label.height(),
                    Qt.KeepAspectRatio,
                    Qt.SmoothTransformation
                )

                self.detection_label.setPixmap(scaled_pixmap)
                self.detection_label.setText("")
            else:
                print(f"å›¾ç‰‡ç‚¹äº‘ä¸å­˜åœ¨: {image_path}")

        except Exception as e:
            print(f"æ˜¾ç¤ºç‚¹äº‘å¤±è´¥: {str(e)}")


    def process_history_path_3d(self):
        """ä»å†å²è·¯å¾„å¤„ç†ä¸‰ç»´åæ ‡"""
        if not self.current_history_path:
            return []

        # å‡è®¾å†å²è·¯å¾„ä¸­å­˜å‚¨çš„æ˜¯ä¸‰ç»´åæ ‡
        if 'world_coords' in self.current_history_path and self.current_history_path['world_coords']:
            return self.current_history_path['world_coords']

        # å¦‚æœå†å²è·¯å¾„ä¸­åªæœ‰äºŒç»´ç‚¹ï¼Œè½¬æ¢ä¸ºä¸‰ç»´
        elif 'points' in self.current_history_path and self.current_history_path['points']:
            points_3d = []
            for point in self.current_history_path['points']:
                if len(point) >= 2:
                    # å°†äºŒç»´ç‚¹è½¬æ¢ä¸ºä¸‰ç»´ç‚¹ï¼ŒZåæ ‡è®¾ä¸º0
                    points_3d.append([point[0], point[1], 0])
            return points_3d

        return []

    def contour_to_3d(self, contour_points):
        """å°†è½®å»“ç‚¹è½¬æ¢ä¸ºä¸‰ç»´åæ ‡"""
        points_3d = []
        for point in contour_points:
            if len(point) >= 2:
                # å°†äºŒç»´è½®å»“ç‚¹è½¬æ¢ä¸ºä¸‰ç»´ç‚¹ï¼ŒZåæ ‡è®¾ä¸º0
                points_3d.append([point[0], point[1], 0])
        return points_3d

    def ensure_detection_system(self):
        """ç¡®ä¿æ£€æµ‹ç³»ç»Ÿå¯ç”¨"""
        # å¦‚æœæ£€æµ‹çº¿ç¨‹å’Œæ£€æµ‹ç³»ç»Ÿå·²ç»å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if hasattr(self, 'detection_thread') and hasattr(self.detection_thread, 'detection_system'):
            return True

        # åˆ›å»ºå¹¶åˆå§‹åŒ–æ£€æµ‹ç³»ç»Ÿ
        try:
            # åˆ›å»ºæ£€æµ‹çº¿ç¨‹
            self.detection_thread = ONNXDetectionThread(self.onnx_model_path)

            # åŠ è½½æ¨¡å‹
            if not self.detection_thread.load_model():
                QMessageBox.warning(self, "æ¨¡å‹åŠ è½½å¤±è´¥", "æ— æ³•åŠ è½½ONNXæ¨¡å‹")
                return False

            # åŠ è½½æ ‡å®šå‚æ•°
            self.detection_thread.detection_system.load_calibration_params()

            print("æ£€æµ‹ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼ˆç”¨äºå†å²è·¯å¾„å¤„ç†ï¼‰")
            return True
        except Exception as e:
            QMessageBox.critical(self, "åˆå§‹åŒ–å¤±è´¥", f"æ— æ³•åˆå§‹åŒ–æ£€æµ‹ç³»ç»Ÿ: {str(e)}")
            return False

    def process_history_path(self):
        """å¤„ç†å†å²è·¯å¾„ç”¨äºæ‰“ç£¨"""
        if not self.current_history_path:
            QMessageBox.warning(self, "æœªé€‰æ‹©è·¯å¾„", "è¯·å…ˆé€‰æ‹©å¹¶åº”ç”¨ä¸€ä¸ªå†å²è·¯å¾„")
            return None

        print(f"å¤„ç†å†å²è·¯å¾„: {self.current_history_path['name']}")

        # ç¡®ä¿æ£€æµ‹ç³»ç»Ÿå¯ç”¨
        if not self.ensure_detection_system():
            QMessageBox.critical(self, "æ£€æµ‹ç³»ç»Ÿé”™è¯¯", "æ— æ³•åˆå§‹åŒ–æ£€æµ‹ç³»ç»Ÿ")
            return None

        # æ£€æŸ¥è·¯å¾„ç‚¹
        if not self.current_history_path.get('points'):
            QMessageBox.warning(self, "è·¯å¾„æ•°æ®é”™è¯¯", "å†å²è·¯å¾„ç‚¹ä¸ºç©º")
            return None

        # æ£€æŸ¥åŸå§‹å°ºå¯¸
        if not self.current_history_path.get('original_size'):
            QMessageBox.warning(self, "è·¯å¾„æ•°æ®é”™è¯¯", "å†å²è·¯å¾„ç¼ºå°‘åŸå§‹å°ºå¯¸ä¿¡æ¯")
            return None

        rotation = self.current_history_path.get('rotation', 90)  # é»˜è®¤ä¸º90åº¦

        # å°è¯•é‡æ–°è®¡ç®—ä¸–ç•Œåæ ‡
        print("é‡æ–°è®¡ç®—å†å²è·¯å¾„çš„ä¸–ç•Œåæ ‡...")
        world_coords = self.convert_path_to_world_coords(
            self.current_history_path['points'],
            self.current_history_path['original_size']
        )

        if world_coords is None:
            QMessageBox.critical(self, "è½¬æ¢å¤±è´¥", "æ— æ³•å°†å†å²è·¯å¾„ç‚¹è½¬æ¢ä¸ºä¸–ç•Œåæ ‡ã€‚è¯·æ£€æŸ¥æ ‡å®šå‚æ•°ã€‚")
            return None

        # æ›´æ–°å†å²è·¯å¾„çš„ä¸–ç•Œåæ ‡
        self.current_history_path['world_coords'] = world_coords

        # æ›´æ–°å­˜å‚¨çš„å†å²è·¯å¾„
        self.save_history_paths()

        print(f"æˆåŠŸå¤„ç†å†å²è·¯å¾„ï¼Œç”Ÿæˆ {len(world_coords)} ä¸ªä¸–ç•Œåæ ‡ç‚¹")
        return world_coords

    def convert_path_to_world_coords(self, pixel_points, original_size):
        """ä½¿ç”¨ CameraDetectionSystem çš„è½¬æ¢æ–¹æ³•"""
        if not hasattr(self.detection_thread, 'detection_system'):
            print("é”™è¯¯ï¼šæ£€æµ‹ç³»ç»Ÿä¸å¯ç”¨")
            return None

        detection_system = self.detection_thread.detection_system

        world_coords = []

        # è·å–ç¼©æ”¾æ¯”ä¾‹
        scale_x = float(self.scale_factor_X_input.text() or 1.0)
        scale_y = float(self.scale_factor_Y_input.text() or 1.0)

        rotation = self.coordinate_rotation  # é»˜è®¤90åº¦

        for point in pixel_points:
            if len(point) < 2:
                continue

            # åº”ç”¨ç¼©æ”¾æ¯”ä¾‹
            scaled_x = point[0] * scale_x
            scaled_y = point[1] * scale_y

            # è½¬æ¢ä¸ºä¸–ç•Œåæ ‡
            world_x, world_y, success = detection_system.pixel_to_world_coords(
                scaled_x, scaled_y, rotation=rotation
            )
            if not success:
                continue

            # åº”ç”¨ç”¨æˆ·åç§»
            final_x = world_x + self.user_offset_x
            final_y = world_y + self.user_offset_y
            final_z = self.user_offset_z
            world_coords.append([final_x, final_y, final_z])

        return world_coords

    def save_history_paths(self):
        """ä¿å­˜å†å²è·¯å¾„åˆ°æ–‡ä»¶"""
        try:
            with open("history_paths.json", "w") as f:
                json.dump(self.history_paths, f)
        except Exception as e:
            print(f"ä¿å­˜å†å²è·¯å¾„å¤±è´¥: {str(e)}")

    def check_path_points(self, contour_points):
        """æ£€æŸ¥ç”Ÿæˆçš„è·¯å¾„ç‚¹"""
        if not contour_points:
            print("æ²¡æœ‰ç”Ÿæˆè·¯å¾„ç‚¹")
            return

        print(f"=== è·¯å¾„ç‚¹æ£€æŸ¥ ===")
        print(f"åŸå§‹ç‚¹æ•°: {len(contour_points)}")

        # è®¡ç®—è·¯å¾„è¾¹ç•Œ
        x_points = [p[0] for p in contour_points]
        y_points = [p[1] for p in contour_points]
        min_x, max_x = min(x_points), max(x_points)
        min_y, max_y = min(y_points), max(y_points)

        print(f"XèŒƒå›´: {min_x:.2f} - {max_x:.2f}, å®½åº¦: {max_x - min_x:.2f}")
        print(f"YèŒƒå›´: {min_y:.2f} - {max_y:.2f}, é«˜åº¦: {max_y - min_y:.2f}")

        # è®¡ç®—å‘¨é•¿
        perimeter = 0
        for i in range(len(contour_points)):
            p1 = contour_points[i]
            p2 = contour_points[(i + 1) % len(contour_points)]
            perimeter += math.sqrt((p2[0]-p1[0])**2 + (p2[1]-p1[1])**2)

        print(f"å‘¨é•¿: {perimeter:.2f}åƒç´ ")


    def execute_all_points(self):
        """æ‰§è¡Œæ‰€æœ‰ç¤ºæ•™ç‚¹"""
        if not self.teach_points:
            QMessageBox.warning(self, "æ— ç¤ºæ•™ç‚¹", "æ²¡æœ‰å¯æ‰§è¡Œçš„ç¤ºæ•™ç‚¹")
            return
        move_type = "MOVEJ" if self.move_type_combo.currentIndex() == 0 else "MOVEL"
        speed = self.speed_slider.value()
        self.execute_points(None, move_type, speed)

    def execute_selected_point(self):
        """æ‰§è¡Œé€‰å®šçš„ç¤ºæ•™ç‚¹"""
        point = self.get_selected_point()
        if not point:
            QMessageBox.warning(self, "æœªé€‰æ‹©", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªç¤ºæ•™ç‚¹")
            return
        move_type = "MOVEJ" if self.move_type_combo.currentIndex() == 0 else "MOVEL"
        speed = self.speed_slider.value()
        index = self.teach_points.index(point)
        self.execute_points([index], move_type, speed)

    def execute_points(self, point_indices=None, move_type='MOVEJ', speed=50):
        """æ‰§è¡Œç¤ºæ•™ç‚¹"""
        if not self.connection or not self.connection.is_connected():
            QMessageBox.warning(self, "æœªè¿æ¥", "æœºæ¢°è‡‚æœªè¿æ¥ï¼Œæ— æ³•æ‰§è¡Œ")
            return False
        if not self.teach_points:
            QMessageBox.warning(self, "æ— ç¤ºæ•™ç‚¹", "æ²¡æœ‰å¯æ‰§è¡Œçš„ç¤ºæ•™ç‚¹")
            return False

        if point_indices is None:
            points_to_execute = self.teach_points
        else:
            points_to_execute = [self.teach_points[i] for i in point_indices if 0 <= i < len(self.teach_points)]

        if not points_to_execute:
            QMessageBox.warning(self, "æ— æ•ˆç´¢å¼•", "æ²¡æœ‰æœ‰æ•ˆçš„ç¤ºæ•™ç‚¹ç´¢å¼•")
            return False

        self.execution_thread = threading.Thread(
            target=self.execute_points_thread,
            args=(points_to_execute, move_type, speed),
            daemon=True
        )
        self.execution_thread.start()
        print("æ‰§è¡Œçº¿ç¨‹å·²å¯åŠ¨")

        self.progress_timer = QTimer()
        self.progress_timer.timeout.connect(self.update_progress)
        self.progress_timer.start(500)
        return True

    def execute_points_thread(self, points_to_execute, move_type, speed):
        """æ‰§è¡Œç¤ºæ•™ç‚¹çš„çº¿ç¨‹å‡½æ•°"""
        try:
            mc = self.connection.get_robot()
            if mc.focus_all_servos() != 1:
                print("è­¦å‘Šï¼šä¸Šç”µæ‰€æœ‰å…³èŠ‚å¤±è´¥")

            print(f"å¼€å§‹æ‰§è¡Œ {len(points_to_execute)} ä¸ªç‚¹ä½ ({move_type}æ¨¡å¼)...")
            self.execution_paused = False
            self.execution_stopped = False
            self.execution_progress = 0

            for i, point in enumerate(points_to_execute):
                print(f"\næ‰§è¡Œç‚¹ä½ #{i + 1} ({point['name']})")
                self.execution_progress = int((i / len(points_to_execute)) * 100)

                if self.execution_stopped:
                    print("æ‰§è¡Œå·²è¢«åœæ­¢")
                    break

                while self.execution_paused:
                    print("æ‰§è¡Œæš‚åœä¸­...")
                    time.sleep(1)
                    if self.execution_stopped:
                        print("æ‰§è¡Œå·²è¢«åœæ­¢")
                        return False

                try:
                    target_position = None
                    if move_type == 'MOVEL':
                        target_position = point['coords']
                        result = mc.send_coords(target_position, speed, mode=1)
                        if result != 1:
                            print(f"å‘é€åæ ‡å‘½ä»¤å¤±è´¥: {result}")
                            continue
                    else:
                        target_position = point.get('positions', point.get('angles', []))
                        result = mc.send_angles(target_position, speed)
                        if result != 1:
                            print(f"å‘é€è§’åº¦å‘½ä»¤å¤±è´¥: {result}")
                            continue

                    start_time = time.time()
                    while True:
                        if not mc.is_moving():
                            break
                        if time.time() - start_time > 60:
                            print("è­¦å‘Šï¼šè¿åŠ¨è¶…æ—¶")
                            break
                        if self.execution_paused or self.execution_stopped:
                            mc.stop()
                            break
                        time.sleep(0.1)

                    if self.execution_paused:
                        print("è¿åŠ¨å·²è¢«æš‚åœ")
                        while self.execution_paused and not self.execution_stopped:
                            time.sleep(0.5)
                        if self.execution_stopped:
                            print("æ‰§è¡Œå·²è¢«åœæ­¢")
                            return False

                    if self.verification_enabled and target_position:
                        print("æ‰§è¡Œä½ç½®éªŒè¯...")
                        if not self.verify_position(point, move_type):
                            print("è­¦å‘Šï¼šä½ç½®éªŒè¯å¤±è´¥ï¼Œå¯èƒ½éœ€è¦é‡æ–°æ‰§è¡Œ")

                    self.last_executed_point = point
                    print(f"ç‚¹ä½ #{i + 1} æ‰§è¡Œå®Œæˆ")
                    time.sleep(0.5)
                except Exception as e:
                    print(f"æ‰§è¡Œç‚¹ä½ #{i + 1} æ—¶å‡ºé”™: {str(e)}")
                    if not self.connection.is_connected():
                        print("å°è¯•é‡æ–°è¿æ¥...")
                        self.connection.reconnect()
                    continue

            print("\nç‚¹ä½æ‰§è¡Œå®Œæ¯•" if not self.execution_stopped else "\næ‰§è¡Œå·²åœæ­¢")
            self.execution_progress = 100
            return True
        except Exception as e:
            print(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
            return False

    def update_progress(self):
        """æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º"""
        self.progress_bar.setValue(self.execution_progress)
        if self.execution_progress >= 100:
            self.progress_timer.stop()

    def verify_position(self, target_point, move_type):
        """éªŒè¯å½“å‰ä½ç½®æ˜¯å¦è¾¾åˆ°ç›®æ ‡ä½ç½®"""
        try:
            mc = self.connection.get_robot()
            current_angles = mc.get_angles()
            current_coords = mc.get_coords()

            if not current_angles or not current_coords:
                print("éªŒè¯å¤±è´¥ï¼šæ— æ³•è·å–å½“å‰ä½ç½®")
                return False

            if move_type == 'MOVEJ':
                target_angles = target_point.get('positions', target_point.get('angles', []))

                if len(current_angles) != 6 or len(target_angles) != 6:
                    print("éªŒè¯å¤±è´¥ï¼šè§’åº¦æ•°æ®ä¸å®Œæ•´")
                    return False

                errors = [abs(current_angles[i] - target_angles[i]) for i in range(6)]
                max_error = max(errors)

                if max_error > self.angle_tolerance:
                    print(f"éªŒè¯å¤±è´¥ï¼šæœ€å¤§è§’åº¦è¯¯å·® {max_error:.2f}Â° > å®¹å·® {self.angle_tolerance}Â°")
                    return False

                print(f"éªŒè¯é€šè¿‡ï¼šæœ€å¤§è§’åº¦è¯¯å·® {max_error:.2f}Â°")
                return True
            else:
                current_pos = current_coords[:3]
                target_pos = target_point.get('coords', [])[:3]

                if len(current_pos) != 3 or len(target_pos) != 3:
                    print("éªŒè¯å¤±è´¥ï¼šåæ ‡æ•°æ®ä¸å®Œæ•´")
                    return False

                error = sum((current_pos[i] - target_pos[i]) ** 2 for i in range(3)) ** 0.5

                if error > self.coord_tolerance:
                    print(f"éªŒè¯å¤±è´¥ï¼šä½ç½®è¯¯å·® {error:.2f}mm > å®¹å·® {self.coord_tolerance}mm")
                    return False

                print(f"éªŒè¯é€šè¿‡ï¼šä½ç½®è¯¯å·® {error:.2f}mm")
                return True
        except Exception as e:
            print(f"éªŒè¯ä½ç½®å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False

    def pause_execution(self):
        """æš‚åœæ‰§è¡Œ"""
        if not self.execution_thread or not self.execution_thread.is_alive():
            QMessageBox.warning(self, "æ— æ‰§è¡Œ", "æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„çº¿ç¨‹")
            return False

        try:
            mc = self.connection.get_robot()
            result = mc.pause()
            if result != 1:
                print(f"æš‚åœå‘½ä»¤å¤±è´¥: {result}")
            self.execution_paused = True
            print("æ‰§è¡Œå·²æš‚åœ")
            return True
        except Exception as e:
            QMessageBox.critical(self, "æš‚åœå¤±è´¥", f"æš‚åœæ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

    def resume_execution(self):
        """æ¢å¤æ‰§è¡Œ"""
        if not self.execution_thread or not self.execution_thread.is_alive():
            QMessageBox.warning(self, "æ— æ‰§è¡Œ", "æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„çº¿ç¨‹")
            return False

        try:
            mc = self.connection.get_robot()
            result = mc.resume()
            if result != 1:
                print(f"æ¢å¤å‘½ä»¤å¤±è´¥: {result}")
            self.execution_paused = False
            print("æ‰§è¡Œå·²æ¢å¤")
            return True
        except Exception as e:
            QMessageBox.critical(self, "æ¢å¤å¤±è´¥", f"æ¢å¤æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

    def stop_execution(self):
        """åœæ­¢æ‰§è¡Œ"""
        if not self.execution_thread or not self.execution_thread.is_alive():
            QMessageBox.warning(self, "æ— æ‰§è¡Œ", "æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„çº¿ç¨‹")
            return False

        try:
            mc = self.connection.get_robot()
            result = mc.stop()
            if result != 1:
                print(f"åœæ­¢å‘½ä»¤å¤±è´¥: {result}")
            self.execution_paused = False
            self.execution_stopped = True
            print("æ‰§è¡Œå·²åœæ­¢")
            return True
        except Exception as e:
            QMessageBox.critical(self, "åœæ­¢å¤±è´¥", f"åœæ­¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

    def closeEvent(self, event):
        """å…³é—­çª—å£æ—¶åœæ­¢æ‰€æœ‰çº¿ç¨‹"""
        if hasattr(self, 'camera_thread') and self.camera_thread and self.camera_thread.isRunning():
            self.camera_thread.stop()
            self.camera_thread = None

            # å…³é—­æ£€æµ‹çº¿ç¨‹
        if self.detection_thread:
            self.detection_thread.stop()
            self.detection_thread = None

        if self.connection:
            self.connection.disconnect()
            self.connection.stop_heartbeat()
            self.stop_speech_recognition()

        event.accept()

    def stop_speech_recognition(self):
        """åœæ­¢è¯­éŸ³è¯†åˆ«"""
        self.speech_recognition_active = False
        self.status_label.setText("è¯­éŸ³è¯†åˆ«å·²åœæ­¢")
        print("è¯­éŸ³è¯†åˆ«åœæ­¢")

    def change_camera_type(self, index):
        """åˆ‡æ¢æ‘„åƒå¤´ç±»å‹"""
        self.camera_type = "network" if index == 1 else "local"
        print(f"åˆ‡æ¢æ‘„åƒå¤´ç±»å‹ä¸º: {self.camera_type}")

    def load_onnx_model(self):
        """åŠ è½½ONNXæ¨¡å‹"""
        options = QFileDialog.Options()
        model_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©ONNXæ¨¡å‹æ–‡ä»¶", "",
            "ONNXæ¨¡å‹ (*.onnx);;æ‰€æœ‰æ–‡ä»¶ (*)",
            options=options
        )

        if model_path:
            # éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                QMessageBox.warning(self, "é”™è¯¯", "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
                return

            success = self.CameraDetectionSystem.load_model(model_path)

            if success:
                self.onnx_model_path_input.setText(model_path)
                self.onnx_model_path = model_path
                QMessageBox.information(self, "æ¨¡å‹åŠ è½½", f"æ¨¡å‹åŠ è½½æˆåŠŸ: {os.path.basename(model_path)}")
            else:
                QMessageBox.critical(self, "é”™è¯¯", "æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")

    # def toggle_detection(self):
    #     """åˆ‡æ¢ç›®æ ‡æ£€æµ‹çŠ¶æ€"""
    #     if self.detect_button.text() == "å¯åŠ¨æ£€æµ‹":
    #         # å¯åŠ¨æ£€æµ‹
    #         try:
    #             # ç¡®ä¿æ¨¡å‹è·¯å¾„æœ‰æ•ˆ
    #             if not self.onnx_model_path:
    #                 QMessageBox.warning(self, "æ¨¡å‹æœªåŠ è½½", "è¯·å…ˆåŠ è½½ONNXæ¨¡å‹")
    #                 return
    #
    #             # åˆ›å»ºæ–°çš„æ£€æµ‹çº¿ç¨‹ï¼ˆä½¿ç”¨ONNXï¼‰
    #             self.detection_thread = ONNXDetectionThread(self.onnx_model_path)
    #
    #             # ä¿®å¤5: åœ¨å¯åŠ¨çº¿ç¨‹å‰åŠ è½½æ¨¡å‹
    #             if not self.detection_thread.load_model():
    #                 QMessageBox.critical(self, "é”™è¯¯", "æ— æ³•åŠ è½½ONNXæ¨¡å‹")
    #                 return
    #
    #             # è®¾ç½®æ‘„åƒå¤´ç±»å‹
    #             if self.camera_type == "network":
    #                 ip = self.camera_ip_input.text()
    #                 port = int(self.camera_port_input.text())
    #                 self.detection_thread.set_camera_type("network")
    #             else:
    #                 self.detection_thread.set_camera_type("local")
    #
    #             # è¿æ¥ä¿¡å·
    #             self.detection_thread.update_frame.connect(self.update_frame)
    #             self.detection_thread.detection_result.connect(self.update_detection_result)
    #             self.detection_thread.detection_coords.connect(self.handle_detection_coords)
    #
    #             self.detection_thread.start()
    #             self.detect_button.setText("åœæ­¢æ£€æµ‹")
    #             self.detect_button.setStyleSheet("background-color: #FF4D4D;")
    #         except Exception as e:
    #             QMessageBox.critical(self, "é”™è¯¯", f"æ— æ³•å¯åŠ¨ç›®æ ‡æ£€æµ‹: {str(e)}")
    #     else:
    #         # åœæ­¢æ£€æµ‹
    #         if self.detection_thread:
    #             self.detection_thread.stop()
    #             self.detection_thread.wait(2000)  # ç­‰å¾…çº¿ç¨‹ç»“æŸ
    #             self.detection_thread = None
    #             self.detect_button.setText("å¯åŠ¨æ£€æµ‹")
    #             self.detect_button.setStyleSheet("")
    #             self.detection_label.clear()
    #             self.detection_label.setText("æ‘„åƒå¤´æœªå¯åŠ¨")


    def handle_detection_coords(self, coords_list):
        """å¤„ç†æ£€æµ‹åˆ°çš„åæ ‡"""
        for coords in coords_list:
            if coords:
                world_x, world_y = coords
                # print(f"æ£€æµ‹åˆ°ç‰©ä½“ä½ç½®: ä¸–ç•Œåæ ‡({world_x:.1f}, {world_y:.1f})")


    def move_to_xyz(self):
        """ç§»åŠ¨åˆ°æŒ‡å®šçš„XYZåæ ‡"""
        if not self.connection or not self.connection.is_connected():
            QMessageBox.warning(self, "æœªè¿æ¥", "æœªè¿æ¥åˆ°æœºå™¨äººï¼Œæ— æ³•ç§»åŠ¨")
            return

        try:
            # è·å–è¾“å…¥çš„åæ ‡å€¼
            x = float(self.target_x_input.text()) if self.target_x_input.text() else 0
            y = float(self.target_y_input.text()) if self.target_y_input.text() else 0
            z = float(self.target_z_input.text()) if self.target_z_input.text() else 0
            x += float(self.offset_x_input.text()) if self.offset_x_input.text() else 0
            y += float(self.offset_y_input.text()) if self.offset_y_input.text() else 0
            z += float(self.offset_z_input.text()) if self.offset_z_input.text() else 0

            # è·å–å½“å‰å§¿æ€
            coords = self.connection.get_robot().get_coords()
            if len(coords) < 6:
                QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•è·å–æœºå™¨äººå½“å‰ä½ç½®")
                return

            # åˆ›å»ºç›®æ ‡åæ ‡
            target_coords = [x, y, z] + coords[3:]

            # ç§»åŠ¨å‰è®°å½•4è½´è§’åº¦
            angles_before = self.connection.get_robot().get_angles()
            if angles_before and len(angles_before) >= 4:
                axis4_angle_before = angles_before[3]
                print(f"ç§»åŠ¨å‰è®°å½•çš„4è½´è§’åº¦: {axis4_angle_before}Â°")
            else:
                print("æ— æ³•è·å–ç§»åŠ¨å‰è§’åº¦")
                axis4_angle_before = None

            # æ‰§è¡Œç§»åŠ¨æŒ‡ä»¤
            self.connection.get_robot().send_coords(target_coords, 30, mode=1)

            # ç­‰å¾…ç§»åŠ¨å®Œæˆ
            while self.connection.get_robot().is_moving():
                time.sleep(0.1)

            # å¦‚æœå¯ç”¨è§’åº¦ä¿®æ­£
            if self.angle_correction_checkbox.isChecked():
                # ç§»åŠ¨å®Œæˆåæ£€æµ‹4è½´è§’åº¦
                angles_after = self.connection.get_robot().get_angles()

                if angles_after and len(angles_after) >= 4 and axis4_angle_before is not None:
                    axis4_angle_after = angles_after[3]
                    print(f"ç§»åŠ¨å4è½´å®é™…è§’åº¦: {axis4_angle_after}Â°")

                    # æ£€æŸ¥è§’åº¦å˜åŒ–
                    angle_diff = abs(axis4_angle_before - axis4_angle_after)
                    if angle_diff > 0.7:
                        print(f"æ£€æµ‹åˆ°4è½´è§’åº¦åç§» {angle_diff:.2f}Â°ï¼Œè¿›è¡Œä¿®æ­£...")

                        # æ„å»ºä¿®æ­£åçš„ç›®æ ‡è§’åº¦
                        correction_angles = list(angles_after)
                        correction_angles[3] = correction_angles[3] + 6.5  # ä¿®æ­£ç¬¬4è½´

                        # æ‰§è¡Œè§’åº¦ä¿®æ­£
                        self.connection.get_robot().send_angles(correction_angles, 20)

                        # éªŒè¯ä¿®æ­£ç»“æœ
                        time.sleep(0.5)
                        final_angles = self.connection.get_robot().get_angles()
                        if len(final_angles) >= 4:
                            print(f"ä¿®æ­£å4è½´è§’åº¦: {final_angles[3]}Â°")
                            print(f"æœ€ç»ˆè¯¯å·®: {abs(axis4_angle_before - final_angles[3]):.2f}Â°")
                    else:
                        print("4è½´è§’åº¦å˜åŒ–åœ¨å…è®¸èŒƒå›´å†…ï¼Œæ— éœ€ä¿®æ­£")

            QMessageBox.information(self, "ç§»åŠ¨å®Œæˆ", f"å·²ç§»åŠ¨åˆ°ä½ç½®: X={x}, Y={y}, Z={z}")

        except ValueError:
            QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—åæ ‡")
        except Exception as e:
            QMessageBox.critical(self, "ç§»åŠ¨é”™è¯¯", f"ç§»åŠ¨è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

    def detect_image(self):
        """æ£€æµ‹å•å¼ å›¾åƒ"""
        options = QFileDialog.Options()
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©å›¾åƒæ–‡ä»¶", "",
            "å›¾åƒæ–‡ä»¶ (*.png *.jpg *.jpeg *.bmp);;æ‰€æœ‰æ–‡ä»¶ (*)",
            options=options
        )

        if not file_path:
            return

        # åˆ›å»ºæ–°çš„æ£€æµ‹çº¿ç¨‹ç”¨äºå•å¼ å›¾åƒ
        image_detector = ONNXDetectionThread(self.onnx_model_path)

        #è®¾ç½®å•å¼ å›¾åƒè·¯å¾„
        image_detector.set_single_image(file_path)

        # è¿æ¥ä¿¡å·
        image_detector.single_image_result.connect(self.handle_single_image_result)
        image_detector.finished.connect(lambda: image_detector.deleteLater())

        # å¯åŠ¨çº¿ç¨‹
        image_detector.start()

        # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
        self.detection_label.clear()
        self.detection_label.setText("æ­£åœ¨æ£€æµ‹å›¾åƒ...")
        self.detection_result_text.setText("å¤„ç†ä¸­...")


    def calibrate_single_image(self):
        """ä½¿ç”¨å•å¼ å›¾åƒè¿›è¡Œæ ‡å®š"""
        options = QFileDialog.Options()
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©æ ‡å®šå›¾åƒ", "",
            "å›¾åƒæ–‡ä»¶ (*.png *.jpg *.jpeg *.bmp);;æ‰€æœ‰æ–‡ä»¶ (*)",
            options=options
        )

        if not file_path:
            return

        # ç¡®ä¿æ£€æµ‹çº¿ç¨‹å·²ç»åˆ›å»º
        if not self.detection_thread:
            self.create_detection_thread()

        # æ‰§è¡Œæ ‡å®š
        if self.detection_thread:
            success = self.detection_thread.calibrate_single_image(file_path)
            if success:
                QMessageBox.information(self, "æ ‡å®šæˆåŠŸ", "ä½¿ç”¨å•å¼ å›¾åƒæ ‡å®šæˆåŠŸï¼")
            else:
                QMessageBox.warning(self, "æ ‡å®šå¤±è´¥", "æ— æ³•å®Œæˆæ ‡å®šï¼Œè¯·ç¡®ä¿å›¾åƒä¸­åŒ…å«ä¸¤ä¸ªArUcoæ ‡è®°")

    def create_detection_thread(self):
        """åˆ›å»ºæ£€æµ‹çº¿ç¨‹"""
        try:
            # è·å–æ‘„åƒå¤´ç±»å‹å’Œå‚æ•°
            camera_type = "network" if self.camera_type_combo.currentIndex() == 1 else "local"
            ip = self.camera_ip_input.text()
            port = int(self.camera_port_input.text())

            # åˆ›å»ºæ£€æµ‹çº¿ç¨‹ï¼Œä¼ å…¥æ­£ç¡®çš„å‚æ•°
            self.detection_thread = ONNXDetectionThread(
                self.onnx_model_path,
                ip=ip,
                port=port
            )
            self.detection_thread.camera_type = camera_type

            # è¿æ¥ä¿¡å·
            self.detection_thread.update_frame.connect(self.update_frame)
            self.detection_thread.detection_result.connect(self.update_detection_result)
            self.detection_thread.detection_coords.connect(self.handle_detection_coords)

        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"åˆ›å»ºæ£€æµ‹çº¿ç¨‹å¤±è´¥: {str(e)}")
            self.detection_thread = None


        # ç¡®ä¿æ£€æµ‹çº¿ç¨‹å·²æ­£ç¡®åˆå§‹åŒ–
        if self.detection_thread and self.detection_thread.isRunning():
            try:
                self.detection_thread.perform_calibration()
            except Exception as e:
                QMessageBox.critical(self, "æ ‡å®šé”™è¯¯", f"æ ‡å®šè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        else:
            QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•å¯åŠ¨æ ‡å®šï¼Œè¯·å…ˆç¡®ä¿æ‘„åƒå¤´æ£€æµ‹å·²æ­£å¸¸å¯åŠ¨")

    def apply_offsets(self, show_message=True):
        """åº”ç”¨ç”¨æˆ·è®¾ç½®çš„åç§»é‡"""
        try:
            # è·å–åç§»å€¼
            self.user_offset_x = float(self.offset_x_input.text() or 0)
            self.user_offset_y = float(self.offset_y_input.text() or 0)
            self.user_offset_z = float(self.offset_z_input.text() or 0)
            
            # éªŒè¯åç§»å€¼
            if abs(self.user_offset_x) > 200 or abs(self.user_offset_y) > 200 or abs(self.user_offset_z) > 300:
                QMessageBox.warning(self, "åç§»è¿‡å¤§", "åç§»é‡ä¸èƒ½è¶…è¿‡Â±200mm,zä¸èƒ½è¶…è¿‡300mm")
                return
            
            # åªåœ¨éœ€è¦æ—¶æ˜¾ç¤ºæ¶ˆæ¯æ¡†
            if show_message:
                QMessageBox.information(self, "åç§»åº”ç”¨",
                                    f"åç§»é‡å·²è®¾ç½®:\nX: {self.user_offset_x}mm\nY: {self.user_offset_y}mm\nZ: {self.user_offset_z}mm")
            
            return True
        except ValueError:
            if show_message:
                QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—åç§»é‡")
        return False



    def toggle_speech_recognition(self):
        """åˆ‡æ¢è¯­éŸ³è¯†åˆ«çŠ¶æ€"""
        if self.is_recording:
            # åœæ­¢å½•éŸ³
            self.is_recording = False
            self.speech_recognition_btn.setText('å¯åŠ¨è¯­éŸ³è¯†åˆ«')
            self.speech_recognition_btn.setStyleSheet("""
                QPushButton {
                    background-color: #4CAF50;
                    color: white;
                    border-radius: 8px;
                }
            """)
            
            # åœæ­¢æ‰€æœ‰å½•éŸ³ç›¸å…³æ´»åŠ¨
            if self.recording_thread:
                self.recording_thread.stop_recording = True
            if self.recording_timer.isActive():
                self.recording_timer.stop()
            self.is_waiting_for_wake_word = False
            self.is_in_command_mode = False
            self.wake_word_detected = False
        else:
            # å¼€å§‹è¯­éŸ³è¯†åˆ«
            self.is_recording = True
            self.speech_recognition_btn.setText('åœæ­¢è¯­éŸ³è¯†åˆ«')
            self.speech_recognition_btn.setStyleSheet("""
                QPushButton {
                    background-color: #f44336;
                    color: white;
                    border-radius: 8px;
                }
            """)
            self.status_label.setText('ç­‰å¾…å”¤é†’è¯...')
            self.speak_response("å·²è¿›å…¥è¯­éŸ³æ§åˆ¶æ¨¡å¼")
            self.speak_response("ç­‰å¾…æ‚¨çš„å”¤é†’")
            
            # è¿›å…¥å”¤é†’è¯æ£€æµ‹æ¨¡å¼
            self.is_waiting_for_wake_word = True
            self.is_in_command_mode = False
            self.wake_word_detected = False
            
            # å¼€å§‹3ç§’çš„å”¤é†’è¯æ£€æµ‹å½•éŸ³
            self.start_wake_word_recording()

    def start_wake_word_recording(self):
        """å¼€å§‹å”¤é†’è¯æ£€æµ‹å½•éŸ³"""
        if not self.is_recording:
            return
            
        print("å¼€å§‹å”¤é†’è¯æ£€æµ‹å½•éŸ³...")
        self.status_label.setText("å”¤é†’è¯æ£€æµ‹å½•éŸ³ä¸­...")
        
        # åˆ›å»ºå½•éŸ³çº¿ç¨‹ï¼Œä½¿ç”¨é¢„æ ¡å‡†çš„é˜ˆå€¼
        self.recording_thread = RecordingThread(
            threshold=self.audio_threshold,
            max_duration=3.0,
            silence_duration=1.5
        )
        self.recording_thread.status_updated.connect(self.update_status)
        self.recording_thread.recording_finished.connect(self.process_wake_word_recording)
        self.recording_thread.start()
        
        # è®¾ç½®è¶…æ—¶å®šæ—¶å™¨
        self.recording_timer.start(5000)  # 5ç§’

    def process_wake_word_recording(self, audio_file):
        """å¤„ç†å”¤é†’è¯æ£€æµ‹å½•éŸ³"""
        if not self.is_recording:
            return
        
        if audio_file == '':
            print('å”¤é†’è¯å½•éŸ³å¤±è´¥')
            self.status_label.setText("å”¤é†’è¯å½•éŸ³å¤±è´¥")
            # ç»§ç»­ä¸‹ä¸€æ¬¡å”¤é†’è¯æ£€æµ‹
            self.start_wake_word_recording()
            return
        
        try:
            print('æ­£åœ¨æ£€æµ‹å”¤é†’è¯...')
            self.status_label.setText("æ­£åœ¨æ£€æµ‹å”¤é†’è¯...")
            # ä½¿ç”¨ASRæ¨¡å‹è¯†åˆ«è¯­éŸ³
            user_input = self.asr_model(audio_file)
            print(f'è¯†åˆ«ç»“æœ: {user_input}')
            self.status_label.setText(f"è¯†åˆ«ç»“æœ: {user_input}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å”¤é†’è¯
            if self.detect_wake_word(user_input):
                print(f"æ£€æµ‹åˆ°å”¤é†’è¯: {self.wake_word}")
                self.status_label.setText(f"æ£€æµ‹åˆ°å”¤é†’è¯: {self.wake_word}")
                self.wake_word_detected = True
                
                # è¿›å…¥æŒ‡ä»¤æ¨¡å¼
                self.is_waiting_for_wake_word = False
                self.is_in_command_mode = True
                
                # å¼€å§‹æŒ‡ä»¤å½•éŸ³
                self.start_command_recording()
            else:
                print("æœªæ£€æµ‹åˆ°å”¤é†’è¯")
                self.status_label.setText("æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œç»§ç»­ç›‘å¬...")
                
                # ç»§ç»­ä¸‹ä¸€æ¬¡å”¤é†’è¯æ£€æµ‹
                self.start_wake_word_recording()
        
        except Exception as e:
            print(f'å”¤é†’è¯æ£€æµ‹å‡ºé”™: {str(e)}')
            self.status_label.setText(f"å”¤é†’è¯æ£€æµ‹å‡ºé”™: {str(e)}")
            # ç»§ç»­ä¸‹ä¸€æ¬¡å”¤é†’è¯æ£€æµ‹
            self.start_wake_word_recording()

    def start_command_recording(self):
        """å¼€å§‹æŒ‡ä»¤å½•éŸ³ï¼ˆä¼˜åŒ–åœé¡¿å¤„ç†ï¼‰"""
        if not self.is_recording or not self.is_in_command_mode:
            return
            
        print("å¼€å§‹æŒ‡ä»¤å½•éŸ³...")
        self.status_label.setText("è¯·è¯´å‡ºæŒ‡ä»¤...")
        self.speak_response("ç­‰å¾…æ‚¨çš„æŒ‡ä»¤")
        
        # åˆ›å»ºå½•éŸ³çº¿ç¨‹ï¼ˆå¢åŠ é™éŸ³æ£€æµ‹æ—¶é—´ï¼‰
        self.recording_thread = RecordingThread(
            threshold=self.audio_threshold,
            max_duration=20.0,  # å»¶é•¿æœ€å¤§å½•éŸ³æ—¶é—´
            silence_duration=3.0  # å¢åŠ é™éŸ³æ£€æµ‹æ—¶é—´
        )
        self.recording_thread.status_updated.connect(self.update_status)
        self.recording_thread.recording_finished.connect(self.process_command_recording)
        self.recording_thread.start()
        
        # è®¾ç½®è¶…æ—¶å®šæ—¶å™¨ï¼ˆæ¯”æœ€å¤§å½•éŸ³æ—¶é—´é•¿ï¼‰
        self.recording_timer.start(25000)  # 25ç§’


    def process_response(self, content):
        """å¤„ç†LLMå“åº”å¹¶æ’­æ”¾"""
        # ç§»é™¤æ€è€ƒæ ‡ç­¾å¹¶åˆ†å¥
        content = self.remove_think_tag(content)
        sentences = self.split_into_sentences(content)
        
        if not sentences:
            return
        
        print('=' * 40)
        print('å¼€å§‹æ–‡æœ¬è½¬è¯­éŸ³...')
        
        # é€å¥ç”Ÿæˆè¯­éŸ³å¹¶æ·»åŠ åˆ°æ’­æ”¾é˜Ÿåˆ—
        for sentence in sentences:
            if sentence:  # ç¡®ä¿å¥å­ä¸ä¸ºç©º
                audio_path = self.tts_model.run(sentence)
                if audio_path:
                    self.audio_system.add_to_queue(audio_path)
        
        print('è¯­éŸ³å·²åŠ å…¥æ’­æ”¾é˜Ÿåˆ—')
    
    def shutdown(self):
        """å…³é—­ç³»ç»Ÿ"""
        self.audio_system.stop()

    # åˆ†å‰²æ–‡æœ¬æˆå¥å­
    def split_into_sentences(self, text):
        """å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­"""
        sentence_endings = r'(?<=[ï¼Œã€‚ï¼ï¼Ÿ])|(?<=\.)'
        return [s.strip() for s in re.split(sentence_endings, text) if s.strip()]
    
    def remove_think_tag(self,text):
        return re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

    def update_recording_status(self):
        """æ›´æ–°å½•éŸ³çŠ¶æ€æ˜¾ç¤º"""
        # if self.is_recording:
        #     # åˆ›å»ºä¸€ä¸ªåŠ¨æ€æ•ˆæœï¼Œæ˜¾ç¤ºå½•éŸ³æ­£åœ¨è¿›è¡Œ
        #     dots = '.' * ((int(time.time() * 2) % 4) + 1)
        #     self.status_label.setText(f'å½•éŸ³ä¸­{dots}')
    
    def update_status(self, message):
        """æ›´æ–°çŠ¶æ€ä¿¡æ¯"""
        print('User:',message)
    

    def process_command_recording(self, audio_file):
        """å¤„ç†å½•éŸ³ç»“æœï¼Œæ”¯æŒå‚æ•°ä¿®æ”¹"""
        try:
            # æ£€æŸ¥å½•éŸ³æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
            if audio_file == '' or not os.path.exists(audio_file):
                print('å½•éŸ³å¤±è´¥æˆ–æ–‡ä»¶ä¸å­˜åœ¨')
                self.status_label.setText("å½•éŸ³å¤±è´¥")
                self.speak_response("å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•")
                self.return_to_wake_word_mode()
                self.speak_response("å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•")
                return
        
            print('æ­£åœ¨è¯†åˆ«è¯­éŸ³...')
            self.status_label.setText("æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
            self.speak_response("æ­£åœ¨è¯†åˆ«æ‚¨çš„æŒ‡ä»¤")
            
            try:
                # ä½¿ç”¨ASRæ¨¡å‹è¯†åˆ«è¯­éŸ³
                user_input = self.asr_model(audio_file)
                print(f'è¯†åˆ«ç»“æœ: {user_input}')
                self.status_label.setText(f"è¯†åˆ«ç»“æœ: {user_input}")
                
                if not user_input or user_input.strip() == '':
                    print('æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³')
                    self.status_label.setText("æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³")
                    self.speak_response("æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œè¯·é‡è¯•")
                    self.return_to_wake_word_mode()
                    self.speak_response("æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å¬æ¸…")
                    return
                
            # æå–å‚æ•°
                parameters = self.extract_parameters(user_input)
                print(f"æå–åˆ°çš„å‚æ•°: {parameters}")
                self.speak_response("æ­£åœ¨åˆ†ææ‚¨çš„æŒ‡ä»¤")
                # åœ¨åŸæœ‰çš„å‚æ•°æå–åï¼Œæ·»åŠ å¯¹æ–°æŒ‡ä»¤çš„å¤„ç†
                if 'command' in parameters:
                    command = parameters['command']
                    value = parameters.get('value')
                    
                    # å¤„ç†ç‰¹å®šç±»å‹çš„æŒ‡ä»¤

                    if command in ["OPEN_CAMERA", "CLOSE_CAMERA", "CONNECT_ROBOT", "DISCONNECT_ROBOT",
                                "START_CALIBRATION", "START_GRINDING", "STOP_GRINDING",
                                "START_SPEECH_RECOGNITION", "STOP_SPEECH_RECOGNITION",
                                "MOTOR_START", "MOTOR_STOP", "MOTOR_FORWARD", "MOTOR_REVERSE",
                                "MOTOR_EMERGENCY_STOP", "MOVE_TO_SAFE_POSITION"]:
                        # æ‰§è¡Œä¸éœ€è¦é¢å¤–å‚æ•°çš„æŒ‡ä»¤
                        self.handle_single_parameter_command(command, value)
                        
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¹¶è¿”å›å”¤é†’è¯æ¨¡å¼
                        try:
                            os.remove(audio_file)
                        except:
                            pass
                        self.return_to_wake_word_mode()
                        return
                    
                    elif command in ["MOTOR_SET_SPEED", "MOVE_TO_TEACH_POINT", "MOVE_TO_COORDINATES"]:
                        # æ‰§è¡Œéœ€è¦å‚æ•°çš„æŒ‡ä»¤
                        if value is not None:
                            self.handle_single_parameter_command(command, value)
                        else:
                            self.speak_response("æœªæä¾›å¿…è¦çš„å‚æ•°å€¼")
                        
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¹¶è¿”å›å”¤é†’è¯æ¨¡å¼
                        try:
                            os.remove(audio_file)
                        except:
                            pass
                        self.return_to_wake_word_mode()
                        return
                
                # å¤„ç†å‚æ•°ä¿®æ”¹æŒ‡ä»¤
                if parameters:
                    # åº”ç”¨å‚æ•°ä¿®æ”¹
                    if self.apply_voice_parameters(parameters):
                        # ç”Ÿæˆåé¦ˆæ¶ˆæ¯
                        feedback = "å‚æ•°ä¿®æ”¹æˆåŠŸ"
                        if 'offset_x' in parameters:
                            feedback += f"ï¼ŒXåç§»è®¾ç½®ä¸º{parameters['offset_x']}æ¯«ç±³"
                        if 'offset_y' in parameters:
                            feedback += f"ï¼ŒYåç§»è®¾ç½®ä¸º{parameters['offset_y']}æ¯«ç±³"
                        if 'offset_z' in parameters:
                            feedback += f"ï¼ŒZåç§»è®¾ç½®ä¸º{parameters['offset_z']}æ¯«ç±³"
                        
                        # è¯­éŸ³åé¦ˆ
                        self.speak_response(feedback)
                        
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¹¶è¿”å›å”¤é†’è¯æ¨¡å¼
                        try:
                            os.remove(audio_file)
                        except:
                            pass
                        self.return_to_wake_word_mode()
                        return
                
                # 2. å¦‚æœæ²¡æœ‰ç›´æ¥æå–åˆ°å‚æ•°ï¼Œä½¿ç”¨LLMè¿›è¡Œåˆ¤æ–­
                # print('ä½¿ç”¨LLMåˆ†ææŒ‡ä»¤...')
                # self.status_label.setText("ä½¿ç”¨AIåˆ†ææŒ‡ä»¤...")
                # self.speak_response("æ­£åœ¨åˆ†ææ‚¨çš„æŒ‡ä»¤")
                
                # full_response = ""
                # detected_command = None
                # llm_parameters = {}
                
                # # æµå¼è·å–å“åº”
                # for chunk in self.llm_model.generate(user_input):
                #     print(chunk, end='', flush=True)
                #     full_response += chunk
                    
                #     # æ£€æŸ¥æ˜¯å¦åŒ…å«æŒ‡ä»¤æ ‡è®°
                #     detected_command = self.detect_command_in_response(full_response)
                #     if detected_command:
                #         # å®‰å…¨æå–LLMå‚æ•°
                #         try:
                #             llm_parameters = self.extract_parameters(full_response)
                #         except Exception as e:
                #             print(f"LLMå‚æ•°æå–å‡ºé”™: {str(e)}")
                #             llm_parameters = {}
                #         break
                
                # print('\nLLMåˆ†æå®Œæˆ')
                
                # 3. å¤„ç†æ£€æµ‹åˆ°çš„æŒ‡ä»¤å’Œå‚æ•°
                # if detected_command:
                #     print(f"æ£€æµ‹åˆ°æŒ‡ä»¤: {detected_command}")
                #     self.status_label.setText(f"æ£€æµ‹åˆ°æŒ‡ä»¤: {detected_command}")
                #     self.speak_response(f"æ£€æµ‹åˆ°æŒ‡ä»¤: {detected_command}")
                    
                #     # å®šä¹‰å•ç‹¬å‚æ•°æŒ‡ä»¤æ˜ å°„
                #     single_commands = {
                #         "MODIFY_X_OFFSET": 'offset_x',
                #         "MODIFY_Y_OFFSET": 'offset_y',
                #         "MODIFY_Z_OFFSET": 'offset_z',
                #         "MODIFY_X_STEP": 'grinding_x_step',
                #         "MODIFY_Y_STEP": 'grinding_y_step',
                #         "MODIFY_Z_STEP": 'grinding_z_step',
                #         "MODIFY_LOOPS": 'loops',
                #         "MODIFY_SPEED": 'speed'
                #     }
                    
                #     # æ£€æŸ¥æ˜¯å¦æ˜¯å•ç‹¬å‚æ•°æŒ‡ä»¤
                #     if detected_command in single_commands:
                #         param_key = single_commands[detected_command]
                #         param_value = None
                        
                #         # ä¼˜å…ˆä½¿ç”¨LLMæå–çš„å‚æ•°
                #         if param_key in llm_parameters:
                #             param_value = llm_parameters[param_key]
                #         # å…¶æ¬¡ä½¿ç”¨å…³é”®è¯æå–çš„å‚æ•°
                #         elif param_key in validated_params:
                #             param_value = validated_params[param_key]
                #         # æœ€åä½¿ç”¨è¯­éŸ³ä¸­çš„æ•°å­—ï¼ˆå–ç¬¬ä¸€ä¸ªï¼‰
                #         elif numbers:
                #             param_value = numbers[0]
                        
                #         if param_value is not None:
                #             # å¤„ç†å•ç‹¬å‚æ•°æŒ‡ä»¤
                #             self.handle_single_parameter_command(detected_command, param_value)
                #         else:
                #             print(f"æœªæ‰¾åˆ°{param_key}çš„æœ‰æ•ˆæ•°å€¼")
                #             self.speak_response(f"æœªæ‰¾åˆ°æœ‰æ•ˆæ•°å€¼ï¼Œè¯·é‡æ–°è®¾ç½®")
                #     else:
                #         # å¤„ç†å¤åˆå‚æ•°æŒ‡ä»¤
                #         if llm_parameters:
                #             print(f"ä»LLMå“åº”ä¸­æå–åˆ°å‚æ•°: {llm_parameters}")
                            
                #             # éªŒè¯å¹¶åº”ç”¨LLMå‚æ•°
                #             llm_validated = {}
                #             for key, value in llm_parameters.items():
                #                 if 'offset' in key:
                #                     llm_validated[key] = validate_parameter(key, value, -50, 50)
                #                 elif 'step' in key:
                #                     llm_validated[key] = validate_parameter(key, value, -10, 10)
                #                 elif key == 'loops':
                #                     llm_validated[key] = validate_parameter(key, value, 1, 100)
                #                 elif key == 'speed':
                #                     llm_validated[key] = validate_parameter(key, value, 1, 100)
                #                 else:
                #                     llm_validated[key] = value
                            
                #             self.apply_voice_parameters(llm_validated)
                        
                #         # å¤„ç†æŒ‡ä»¤
                #         self.process_command(detected_command)
                
                # # 4. å¤„ç†å›å¤å†…å®¹
                # if full_response.strip():
                #     clean_response = self.remove_think_tag(full_response)
                #     print(f"AIå›å¤: {clean_response.lstrip()}")
                #     self.status_label.setText(f"AIå›å¤: {clean_response}")
                    
                #     # è¯­éŸ³æ’­æŠ¥å›å¤å†…å®¹
                #     self.speak_response(clean_response)
                # else:
                #     self.speak_response("æŒ‡ä»¤å·²å¤„ç†")
                
                # å›åˆ°å”¤é†’è¯æ£€æµ‹æ¨¡å¼
                self.return_to_wake_word_mode()
                
            except Exception as e:
                print(f'å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}')
                self.status_label.setText(f"å¤„ç†å‡ºé”™: {str(e)}")
                self.speak_response("å¤„ç†æŒ‡ä»¤æ—¶å‡ºé”™")
                import traceback
                traceback.print_exc()
                # ç¡®ä¿å›åˆ°å”¤é†’è¯æ¨¡å¼
                self.return_to_wake_word_mode()
        
        except Exception as e:
            print(f'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}')
            self.status_label.setText(f"ä¸¥é‡é”™è¯¯: {str(e)}")
            self.speak_response("ç³»ç»Ÿå‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
            import traceback
            traceback.print_exc()
        finally:
        # ç¡®ä¿åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                if os.path.exists(audio_file):
                    os.remove(audio_file)
            except:
                pass

    def return_to_wake_word_mode(self):
        """è¿”å›åˆ°å”¤é†’è¯æ£€æµ‹æ¨¡å¼"""
        try:
            self.is_waiting_for_wake_word = True
            self.is_in_command_mode = False
            self.wake_word_detected = False
            self.status_label.setText('ç­‰å¾…å”¤é†’è¯...')
            self.speak_response("ç­‰å¾…æ‚¨çš„å”¤é†’")
            self.start_wake_word_recording()
        except Exception as e:
            print(f"è¿”å›å”¤é†’æ¨¡å¼å‡ºé”™: {str(e)}")
            # å°è¯•é‡ç½®çŠ¶æ€
            self.is_waiting_for_wake_word = True
            self.is_in_command_mode = False
            self.wake_word_detected = False
            self.status_label.setText('ç³»ç»Ÿå‡†å¤‡å°±ç»ª')

    def handle_single_parameter_command(self, command, value):
        """å¤„ç†å•ç‹¬å‚æ•°ä¿®æ”¹æŒ‡ä»¤"""
        try:
            self.speak_response("æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚")
            # æ ¹æ®æŒ‡ä»¤ç±»å‹åº”ç”¨å‚æ•°
            feedback = ""
            if command == "MODIFY_X_OFFSET":
                self.offset_x_input.setText(str(value))
                self.apply_offsets()
                feedback = f"Xåç§»å·²è®¾ç½®ä¸º{value}æ¯«ç±³"
            elif command == "MODIFY_Y_OFFSET":
                self.offset_y_input.setText(str(value))
                self.apply_offsets()
                feedback = f"Yåç§»å·²è®¾ç½®ä¸º{value}æ¯«ç±³"
            elif command == "MODIFY_Z_OFFSET":
                self.offset_z_input.setText(str(value))
                self.apply_offsets()
                feedback = f"Zåç§»å·²è®¾ç½®ä¸º{value}æ¯«ç±³"
            elif command == "MODIFY_X_STEP":
                self.x_step_input.setText(str(value))
                self.apply_grinding_params()
                feedback = f"Xè¿›æ·±å·²è®¾ç½®ä¸º{value}æ¯«ç±³"
            elif command == "MODIFY_Y_STEP":
                self.y_step_input.setText(str(value))
                self.apply_grinding_params()
                feedback = f"Yè¿›æ·±å·²è®¾ç½®ä¸º{value}æ¯«ç±³"
            elif command == "MODIFY_Z_STEP":
                self.z_step_input.setText(str(value))
                self.apply_grinding_params()
                feedback = f"Zè¿›æ·±å·²è®¾ç½®ä¸º{value}æ¯«ç±³"
            elif command == "MODIFY_LOOPS":
                # ç¡®ä¿å¾ªç¯æ¬¡æ•°æ˜¯æ•´æ•°
                value = int(value) if isinstance(value, float) else value
                self.loop_count_input.setText(str(value))
                self.apply_grinding_params()
                feedback = f"å¾ªç¯æ¬¡æ•°å·²è®¾ç½®ä¸º{value}æ¬¡"
            elif command == "MODIFY_SPEED":
                # ç¡®ä¿é€Ÿåº¦åœ¨1-100èŒƒå›´å†…
                value = max(1, min(100, int(value)))
                self.speed_slider.setValue(value)
                feedback = f"é€Ÿåº¦å·²è®¾ç½®ä¸º{value}"
            # æ–°å¢æŒ‡ä»¤ï¼šæ‘„åƒå¤´æ§åˆ¶
            elif command == "OPEN_CAMERA":
                self.toggle_camera()
                feedback = "æ‘„åƒå¤´å·²å¼€å¯"
            elif command == "CLOSE_CAMERA":
                self.close_camera()
                feedback = "æ‘„åƒå¤´å·²å…³é—­"
            # æ–°å¢æŒ‡ä»¤ï¼šæœºå™¨äººè¿æ¥æ§åˆ¶
            elif command == "CONNECT_ROBOT":
                self.toggle_connection()
                feedback = "æœºå™¨äººå·²è¿æ¥"
            elif command == "DISCONNECT_ROBOT":
                if self.connection and self.connection.is_connected():
                    self.connection.disconnect()
                    self.update_ui_state(False)
                feedback = "æœºå™¨äººå·²æ–­å¼€è¿æ¥"
            # æ–°å¢æŒ‡ä»¤ï¼šæ ‡å®šæ§åˆ¶
            elif command == "START_CALIBRATION":
                self.start_calibration()
                feedback = "å¼€å§‹æ ‡å®š"
            # æ–°å¢æŒ‡ä»¤ï¼šæ‰“ç£¨æ§åˆ¶
            elif command == "START_GRINDING":
                self.toggle_grinding()
                feedback = "å¼€å§‹æ‰“ç£¨"
            elif command == "STOP_GRINDING":
                self.toggle_grinding()
                feedback = "åœæ­¢æ‰“ç£¨"
            # æ–°å¢æŒ‡ä»¤ï¼šè¯­éŸ³è¯†åˆ«æ§åˆ¶
            elif command == "START_SPEECH_RECOGNITION":
                self.toggle_speech_recognition()
                feedback = "è¯­éŸ³è¯†åˆ«å·²å¼€å¯"
            elif command == "STOP_SPEECH_RECOGNITION":
                self.toggle_speech_recognition()
                feedback = "è¯­éŸ³è¯†åˆ«å·²å…³é—­"
            # æ–°å¢æŒ‡ä»¤ï¼šç”µæœºæ§åˆ¶
            elif command == "MOTOR_START":
                if hasattr(self, 'motor_controller') and self.motor_controller:
                    self.motor_controller.start()
                feedback = "ç”µæœºå·²å¯åŠ¨"
            elif command == "MOTOR_STOP":
                if hasattr(self, 'motor_controller') and self.motor_controller:
                    self.motor_controller.stop()
                feedback = "ç”µæœºå·²åœæ­¢"
            elif command == "MOTOR_FORWARD":
                if hasattr(self, 'motor_controller') and self.motor_controller:
                    self.motor_controller.forward()
                feedback = "ç”µæœºæ­£è½¬"
            elif command == "MOTOR_REVERSE":
                if hasattr(self, 'motor_controller') and self.motor_controller:
                    self.motor_controller.reverse()
                feedback = "ç”µæœºåè½¬"
            elif command == "MOTOR_EMERGENCY_STOP":
                if hasattr(self, 'motor_controller') and self.motor_controller:
                    self.motor_controller.emergency_stop()
                feedback = "ç”µæœºæ€¥åœ"
            elif command == "MOTOR_SET_SPEED":
                if hasattr(self, 'motor_controller') and self.motor_controller:
                    self.motor_controller.set_speed(value)
                feedback = f"ç”µæœºé€Ÿåº¦è®¾ç½®ä¸º{value}"
            # æ–°å¢æŒ‡ä»¤ï¼šæœºæ¢°è‡‚å®‰å…¨ä½ç½®
            elif command == "MOVE_TO_SAFE_POSITION":
                self.move_to_safe_position()
                feedback = "æœºæ¢°è‡‚å·²ç§»åŠ¨åˆ°å®‰å…¨ä½ç½®"
            # æ–°å¢æŒ‡ä»¤ï¼šç§»åŠ¨åˆ°æŒ‡å®šç¤ºæ•™ç‚¹
            elif command == "MOVE_TO_TEACH_POINT":
                point_name = str(value)  # è¿™é‡Œvalueåº”è¯¥æ˜¯ç¤ºæ•™ç‚¹åç§°
                self.move_to_named_teach_point(point_name)
                feedback = f"æœºæ¢°è‡‚å·²ç§»åŠ¨åˆ°{point_name}"
            # æ–°å¢æŒ‡ä»¤ï¼šç§»åŠ¨åˆ°æŒ‡å®šåæ ‡
            elif command == "MOVE_TO_COORDINATES":
                # è¿™é‡Œvalueåº”è¯¥æ˜¯ä¸€ä¸ªåŒ…å«åæ ‡çš„å­—ç¬¦ä¸²ï¼Œå¦‚"100,200,300"
                coords = [float(coord.strip()) for coord in str(value).split(',')]
                if len(coords) >= 3:
                    self.move_to_xyz_coords(coords[0], coords[1], coords[2])
                    feedback = f"æœºæ¢°è‡‚å·²ç§»åŠ¨åˆ°åæ ‡({coords[0]}, {coords[1]}, {coords[2]})"
                else:
                    feedback = "åæ ‡æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨x,y,zæ ¼å¼"
            
            if feedback:
                self.status_label.setText(feedback)
                self.speak_response(feedback)
            self.speak_response("æŒ‡ä»¤æ‰§è¡ŒæˆåŠŸ")
            return True
        except Exception as e:
            error_msg = f"å‚æ•°ä¿®æ”¹å¤±è´¥: {str(e)}"
            print(f"{error_msg}: {str(e)}")
            self.status_label.setText(error_msg)
            self.speak_response(error_msg)
            return False
        
    def move_to_safe_position(self):
        """ç§»åŠ¨æœºæ¢°è‡‚åˆ°å®‰å…¨ä½ç½®"""
        if not self.connection or not self.connection.is_connected():
            QMessageBox.warning(self, "æœªè¿æ¥", "æœªè¿æ¥åˆ°æœºå™¨äººï¼Œæ— æ³•ç§»åŠ¨")
            return
        
        try:
            # å®‰å…¨ä½ç½®åæ ‡æˆ–è§’åº¦
            safe_position = [0, 0, 0, 0, 0, 0] 
            self.connection.get_robot().send_angles(safe_position, 50)
            QMessageBox.information(self, "ç§»åŠ¨", "æœºæ¢°è‡‚æ­£åœ¨ç§»åŠ¨åˆ°å®‰å…¨ä½ç½®")
        except Exception as e:
            QMessageBox.critical(self, "ç§»åŠ¨é”™è¯¯", f"ç§»åŠ¨è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

    def move_to_named_teach_point(self, point_name):
        """ç§»åŠ¨åˆ°æŒ‡å®šåç§°çš„ç¤ºæ•™ç‚¹"""
        point = None
        for teach_point in self.teach_points:
            if teach_point.get('name') == point_name:
                point = teach_point
                break
        
        if point:
            self.move_to_teach_point(point)
        else:
            QMessageBox.warning(self, "æœªæ‰¾åˆ°", f"æœªæ‰¾åˆ°åä¸º'{point_name}'çš„ç¤ºæ•™ç‚¹")

    def move_to_xyz_coords(self, x, y, z):
        """ç§»åŠ¨åˆ°æŒ‡å®šçš„XYZåæ ‡"""
        if not self.connection or not self.connection.is_connected():
            QMessageBox.warning(self, "æœªè¿æ¥", "æœªè¿æ¥åˆ°æœºå™¨äººï¼Œæ— æ³•ç§»åŠ¨")
            return
        
        try:
            # è·å–å½“å‰å§¿æ€
            coords = self.connection.get_robot().get_coords()
            if len(coords) < 6:
                QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•è·å–æœºå™¨äººå½“å‰ä½ç½®")
                return
            
            # åˆ›å»ºç›®æ ‡åæ ‡
            target_coords = [x, y, z] + coords[3:]
            self.connection.get_robot().send_coords(target_coords, 30, mode=1)
            QMessageBox.information(self, "ç§»åŠ¨", f"æœºæ¢°è‡‚æ­£åœ¨ç§»åŠ¨åˆ°åæ ‡({x}, {y}, {z})")
        except Exception as e:
            QMessageBox.critical(self, "ç§»åŠ¨é”™è¯¯", f"ç§»åŠ¨è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        
    def speak_response(self, text):
        """æ’­æ”¾è¯­éŸ³å“åº”"""
        self.audio_system.add_to_queue(text)
    
    def system_start(self):
        """ç³»ç»Ÿå¯åŠ¨æ—¶æ’­æ”¾é¢„åŠ è½½è¯­éŸ³"""
        self.audio_system.add_to_queue("system_start")
        
    def custom_message(self, text):
        """æ’­æ”¾è‡ªå®šä¹‰æ¶ˆæ¯ï¼ˆåŠ¨æ€ç”Ÿæˆï¼‰"""
        self.audio_system.add_to_queue(text)


    def detect_direct_command(self, user_input):
        """ç›´æ¥å…³é”®è¯åŒ¹é…æŒ‡ä»¤"""
        user_input = user_input.lower()
        
        command_map = {
            "å¯åŠ¨": "START_GRINDING",
            "å¼€å§‹": "START_GRINDING",
            "åœæ­¢": "STOP_GRINDING",
            "ç»“æŸ": "STOP_GRINDING",
            "æ ‡å®š": "START_CALIBRATION",
            "æ ¡å‡†": "START_CALIBRATION",
            "è¿æ¥æœºå™¨äºº": "CONNECT_ROBOT",
            "æ–­å¼€æœºå™¨äºº": "DISCONNECT_ROBOT",
            "è¿æ¥éº¦å…‹é£": "CONNECT_MICROPHONE",
            "æ–­å¼€éº¦å…‹é£": "DISCONNECT_MICROPHONE",
            "å¯åŠ¨è¯­éŸ³è¯†åˆ«": "START_SPEECH_RECOGNITION",
            "åœæ­¢è¯­éŸ³è¯†åˆ«": "STOP_SPEECH_RECOGNITION"
        }
        
        # æ£€æŸ¥æ˜¯å¦å®Œå…¨åŒ¹é…æŸä¸ªæŒ‡ä»¤
        for keyword, command in command_map.items():
            if keyword in user_input:
                return command
        
        return None

    def detect_command_in_response(self, response):
        """ä»å“åº”ä¸­æ£€æµ‹æŒ‡ä»¤"""
        # æ–¹æ³•1ï¼šæ­£åˆ™åŒ¹é…
        match = re.search(r'<command>(.*?)</command>', response, re.IGNORECASE)
        if match:
            return match.group(1)
        
        # æ–¹æ³•2ï¼šå…³é”®è¯åŒ¹é…ï¼ˆå¤‡ç”¨ï¼‰
        command_keywords = {
            "START_GRINDING": ["å¯åŠ¨æ‰“ç£¨", "å¼€å§‹æ‰“ç£¨"],
            "STOP_GRINDING": ["åœæ­¢æ‰“ç£¨", "ç»“æŸæ‰“ç£¨"],
            "START_CALIBRATION": ["å¼€å§‹æ ‡å®š", "è¿›è¡Œæ ¡å‡†"],
            "CONNECT_ROBOT": ["è¿æ¥æœºå™¨äºº", "æœºå™¨äººè¿æ¥"],
            "DISCONNECT_ROBOT": ["æ–­å¼€æœºå™¨äºº", "æœºå™¨äººæ–­å¼€"],
            "CONNECT_MICROPHONE": ["è¿æ¥éº¦å…‹é£", "éº¦å…‹é£è¿æ¥"],
            "DISCONNECT_MICROPHONE": ["æ–­å¼€éº¦å…‹é£", "éº¦å…‹é£æ–­å¼€"],
            "START_SPEECH_RECOGNITION": ["å¯åŠ¨è¯­éŸ³è¯†åˆ«", "è¯­éŸ³è¯†åˆ«å¼€å¯"],
            "STOP_SPEECH_RECOGNITION": ["åœæ­¢è¯­éŸ³è¯†åˆ«", "è¯­éŸ³è¯†åˆ«å…³é—­"]
        }
        
        for command, keywords in command_keywords.items():
            for keyword in keywords:
                if keyword in response:
                    return command
        
        return None
    
    def process_command(self, command):
        """å¤„ç†ä»LLMè¿”å›çš„æŒ‡ä»¤"""
        print(f"æ‰§è¡ŒæŒ‡ä»¤: {command}")
        self.status_label.setText(f"æ‰§è¡ŒæŒ‡ä»¤: {command}")
        
        # æ ¹æ®æŒ‡ä»¤è°ƒç”¨å¯¹åº”å‡½æ•°
        if command == "START_GRINDING":
            self.toggle_grinding()
        elif command == "STOP_GRINDING":
            self.toggle_grinding()  # åœæ­¢å’Œå¯åŠ¨å¯èƒ½æ˜¯åŒä¸€ä¸ªæŒ‰é’®
        elif command == "START_CALIBRATION":
            self.start_calibration()
        elif command == "CONNECT_ROBOT":
            self.toggle_connection()  # ç›´æ¥è°ƒç”¨è¿æ¥/æ–­å¼€æ–¹æ³•
        elif command == "DISCONNECT_ROBOT":
            self.toggle_connection()  # æ–­å¼€è¿æ¥ä¹Ÿæ˜¯åŒä¸€ä¸ªæ–¹æ³•
        elif command == "START_SPEECH_RECOGNITION":
            self.toggle_speech_recognition()
        elif command == "STOP_SPEECH_RECOGNITION":
            self.toggle_speech_recognition()

        elif command == "MODIFY_OFFSET":
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç‰¹å®šçš„åç§»ä¿®æ”¹é€»è¾‘
            self.status_label.setText("åæ ‡åç§»å·²ä¿®æ”¹")
        elif command == "MODIFY_GRINDING_PARAMS":
            self.status_label.setText("æ‰“ç£¨å‚æ•°å·²ä¿®æ”¹")
        elif command == "MODIFY_LOOPS":
            self.status_label.setText("å¾ªç¯æ¬¡æ•°å·²ä¿®æ”¹")
        elif command == "MODIFY_SPEED":
            self.status_label.setText("é€Ÿåº¦å·²ä¿®æ”¹")

    def extract_parameters(self, text):
        """ä½¿ç”¨ä¼˜åŒ–çš„ä¸­æ–‡æ•°å­—å¤„ç†æ–¹æ¡ˆ"""
            # åˆå§‹åŒ–ç»“æœå­—å…¸
        result = {}
        text_lower = text.lower().strip()
        
        # === 1. å¤„ç†ç‰¹æ®ŠæŒ‡ä»¤===
        # æ‘„åƒå¤´æ§åˆ¶
        if any(word in text_lower for word in ["æ‰“å¼€æ‘„åƒå¤´", "å¯åŠ¨æ‘„åƒå¤´", "å¼€å¯æ‘„åƒå¤´"]):
            return {"command": "OPEN_CAMERA"}
        elif any(word in text_lower for word in ["å…³é—­æ‘„åƒå¤´", "åœæ­¢æ‘„åƒå¤´", "å…³æ‰æ‘„åƒå¤´"]):
            return {"command": "CLOSE_CAMERA"}
        
        # æœºå™¨äººè¿æ¥æ§åˆ¶
        elif any(word in text_lower for word in ["è¿æ¥æœºå™¨äºº", "è¿æ¥æœºæ¢°è‡‚", "æœºå™¨äººè¿æ¥"]):
            return {"command": "CONNECT_ROBOT"}
        elif any(word in text_lower for word in ["æ–­å¼€æœºå™¨äºº", "æ–­å¼€è¿æ¥", "æœºå™¨äººæ–­å¼€"]):
            return {"command": "DISCONNECT_ROBOT"}
        
        # æ ‡å®šæ§åˆ¶
        elif any(word in text_lower for word in ["å¼€å§‹æ ‡å®š", "è¿›è¡Œæ ‡å®š", "æ ¡å‡†", "æ ‡å®šæ‘„åƒå¤´"]):
            return {"command": "START_CALIBRATION"}
        
        # æ‰“ç£¨æ§åˆ¶
        elif any(word in text_lower for word in ["å¼€å§‹æ‰“ç£¨", "å¯åŠ¨æ‰“ç£¨", "è¿è¡Œæ‰“ç£¨"]):
            return {"command": "START_GRINDING"}
        elif any(word in text_lower for word in ["åœæ­¢æ‰“ç£¨", "ç»“æŸæ‰“ç£¨", "æš‚åœæ‰“ç£¨"]):
            return {"command": "STOP_GRINDING"}
        
        # è¯­éŸ³è¯†åˆ«æ§åˆ¶
        elif any(word in text_lower for word in ["å¼€å¯è¯­éŸ³è¯†åˆ«", "å¯åŠ¨è¯­éŸ³è¯†åˆ«", "è¯­éŸ³æ§åˆ¶å¼€å¯"]):
            return {"command": "START_SPEECH_RECOGNITION"}
        elif any(word in text_lower for word in ["å…³é—­è¯­éŸ³è¯†åˆ«", "åœæ­¢è¯­éŸ³è¯†åˆ«", "è¯­éŸ³æ§åˆ¶å…³é—­"]):
            return {"command": "STOP_SPEECH_RECOGNITION"}
        
        # ç”µæœºæ§åˆ¶
        elif any(word in text_lower for word in ["å¯åŠ¨ç”µæœº", "å¼€å¯ç”µæœº", "ç”µæœºå¯åŠ¨"]):
            return {"command": "MOTOR_START"}
        elif any(word in text_lower for word in ["åœæ­¢ç”µæœº", "å…³é—­ç”µæœº", "ç”µæœºå…³é—­"]):
            return {"command": "MOTOR_STOP"}
        elif any(word in text_lower for word in ["ç”µæœºæ­£è½¬", "æ­£è½¬", "ç”µæœºå‘å‰"]):
            return {"command": "MOTOR_FORWARD"}
        elif any(word in text_lower for word in ["ç”µæœºåè½¬", "åè½¬", "ç”µæœºå‘å"]):
            return {"command": "MOTOR_REVERSE"}
        elif any(word in text_lower for word in ["ç”µæœºæ€¥åœ", "ç´§æ€¥åœæ­¢", "æ€¥åœ"]):
            return {"command": "MOTOR_EMERGENCY_STOP"}
        
        # æœºæ¢°è‡‚å®‰å…¨ä½ç½®
        elif any(word in text_lower for word in ["å®‰å…¨ä½ç½®", "å›åˆ°åŸç‚¹", "å½’ä½", "è¿”å›é›¶ç‚¹"]):
            return {"command": "MOVE_TO_SAFE_POSITION"}
        
        # === 2. å¤„ç†å¸¦å‚æ•°çš„æŒ‡ä»¤ ===
        # è®¾ç½®ç”µæœºé€Ÿåº¦
        if "ç”µæœºé€Ÿåº¦" in text_lower or "è½¬é€Ÿ" in text_lower:
            numbers = re.findall(r'\d+', text_lower)
            if numbers:
                try:
                    speed = int(numbers[0])
                    return {"command": "MOTOR_SET_SPEED", "value": speed}
                except ValueError:
                    pass
        
        # è®¾ç½®X/Y/Zåç§»
        if "åç§»" in text_lower or "åä¸€" in text_lower:
            # æå–è½´ä¿¡æ¯
            axis = None
            if "x" in text_lower or "å‰" in text_lower:
                axis = "x"
            elif "y" in text_lower or "y" in text_lower:
                axis = "y"
            elif "z" in text_lower or "z" in text_lower:
                axis = "z"
            
            # æå–æ•°å€¼
            numbers = re.findall(r'[-+]?\d*\.?\d+', text_lower)
            if numbers:
                try:
                    value = float(numbers[0])
                    return {"command": f"MODIFY_{axis.upper()}_OFFSET", "value": value}
                except (ValueError, TypeError):
                    pass
        
        # è®¾ç½®å¾ªç¯æ¬¡æ•°
        if "å¾ªç¯" in text_lower or "æ¬¡æ•°" in text_lower:
            numbers = re.findall(r'\d+', text_lower)
            if numbers:
                try:
                    loops = int(numbers[0])
                    return {"command": "MODIFY_LOOPS", "value": loops}
                except ValueError:
                    pass
        
        # è®¾ç½®é€Ÿåº¦
        if "é€Ÿåº¦" in text_lower and ("æ‰“ç£¨" not in text_lower and "ç”µæœº" not in text_lower):
            numbers = re.findall(r'\d+', text_lower)
            if numbers:
                try:
                    speed = int(numbers[0])
                    return {"command": "MODIFY_SPEED", "value": speed}
                except ValueError:
                    pass
        
        # ç§»åŠ¨åˆ°æŒ‡å®šç¤ºæ•™ç‚¹
        if "ç§»åŠ¨åˆ°" in text_lower and ("ç‚¹" in text_lower or "ä½ç½®" in text_lower):
            # æå–ç‚¹åç§°
            point_match = re.search(r'ç§»åŠ¨åˆ°(.+?)(ç‚¹|ä½ç½®)', text_lower)
            if point_match:
                point_name = point_match.group(1).strip()
                return {"command": "MOVE_TO_TEACH_POINT", "value": point_name}
        
        # ç§»åŠ¨åˆ°æŒ‡å®šåæ ‡
        if "ç§»åŠ¨åˆ°" in text_lower and ("åæ ‡" in text_lower or "ä½ç½®" in text_lower):
            # æå–åæ ‡å€¼
            coords = re.findall(r'[-+]?\d*\.?\d+', text_lower)
            if len(coords) >= 3:
                try:
                    x = float(coords[0])
                    y = float(coords[1])
                    z = float(coords[2])
                    return {"command": "MOVE_TO_COORDINATES", "value": [x, y, z]}
                except ValueError:
                    pass
            elif len(coords) == 1:
                # å¯èƒ½æ˜¯å•ç‹¬æŒ‡å®šZé«˜åº¦
                try:
                    z = float(coords[0])
                    return {"command": "MODIFY_Z_OFFSET", "value": z}
                except ValueError:
                    pass

        parameters = {}
        text_lower = text.lower()
        print(f"[DEBUG] åŸå§‹è¯†åˆ«ç»“æœ: {text_lower}")
        
        # === å£è¯­åŒ–è¡¨è¾¾æ ‡å‡†åŒ– ===
        text_lower = self.normalize_colloquial_expressions(text_lower)
        print(f"[DEBUG] æ ‡å‡†åŒ–åçš„æ–‡æœ¬: {text_lower}")
        
        # === å®¹é”™å…³é”®è¯æ˜ å°„ ===
        keyword_map = {
            'åç§»': ['åç§»', 'ç‰‡ä»¥', 'åç§»é‡', 'åä¸€', 'ç‰‡ç§»', 'åç§»å€¼'],
            'x': ['x', 'å‰', 'xè½´', 'xæ–¹å‘'],
            'y': ['y', 'y', 'yè½´', 'yæ–¹å‘'],
            'z': ['z', 'z', 'zè½´', 'zæ–¹å‘'],
            'è½´': ['è½´', 'åˆ™', 'å‘¨', 'å·', 'å', 'ä½œ', 'é€', 'è¿½é€'],  # æ·»åŠ æ›´å¤šå¯èƒ½çš„è¯¯è¯†åˆ«
            'åæ ‡': ['åæ ‡', 'åšæ ‡', 'åè¡¨', 'ä½œè¡¨']  # æ·»åŠ åæ ‡çš„æ˜ å°„
        }
        
        # æ›¿æ¢è¯†åˆ«é”™è¯¯çš„å…³é”®è¯
        normalized_text = text_lower
        for correct_word, variants in keyword_map.items():
            for variant in variants:
                if variant in normalized_text:
                    normalized_text = normalized_text.replace(variant, correct_word)
                    print(f"[DEBUG] æ›¿æ¢å…³é”®è¯: {variant} -> {correct_word}")
        
        print(f"[DEBUG] è§„èŒƒåŒ–åçš„æ–‡æœ¬: {normalized_text}")
        
        # === ä½¿ç”¨cn2anä¸¥æ ¼æ¨¡å¼è½¬æ¢ä¸­æ–‡æ•°å­— ===
        # å…ˆæå–æ‰€æœ‰ä¸­æ–‡æ•°å­—ç‰‡æ®µ
        chinese_digits = 'é›¶ä¸€äºŒä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡'
        number_pattern = r'([{}]+)'.format(chinese_digits)
        matches = re.findall(number_pattern, normalized_text)
        
        processed_text = normalized_text
        for match in matches:
            try:
                # ä½¿ç”¨ä¸¥æ ¼æ¨¡å¼è½¬æ¢ä¸­æ–‡æ•°å­—
                arabic_num = cn2an.cn2an(match, "strict")
                processed_text = processed_text.replace(match, str(arabic_num), 1)
                print(f"[DEBUG] è½¬æ¢ä¸­æ–‡æ•°å­—: {match} -> {arabic_num}")
            except Exception as e:
                print(f"[WARNING] ä¸­æ–‡æ•°å­—è½¬æ¢å¤±è´¥: {match} - {str(e)}")
        
        print(f"[DEBUG] å¤„ç†åçš„æ–‡æœ¬: {processed_text}")
        
        # === ç²¾ç¡®å‚æ•°æå– ===
        param_patterns = {
            'offset_x': r'(?:x|X)[\sï¼š:]*[è½´]?[å‘ä½]?åç§»[\sï¼š:]*([-+]?\d*\.?\d+)',
            'offset_y': r'(?:y|Y)[\sï¼š:]*[è½´]?[å‘ä½]?åç§»[\sï¼š:]*([-+]?\d*\.?\d+)',
            'offset_z': r'(?:z|Z)[\sï¼š:]*[è½´]?[å‘ä½]?åç§»[\sï¼š:]*([-+]?\d*\.?\d+)'
        }
        
        for param, pattern in param_patterns.items():
            matches = re.findall(pattern, processed_text)
            if matches:
                try:
                    parameters[param] = float(matches[0])
                    print(f"[DEBUG] ç²¾ç¡®åŒ¹é…å‚æ•°: {param}={matches[0]}")
                except ValueError:
                    pass
        
        if not parameters:
            # æ£€æµ‹è½´å…³é”®è¯
            axis_detected = None
            if re.search(r'(?:x|X)[\sï¼š:]*[è½´]?', processed_text):
                axis_detected = 'x'
            elif re.search(r'(?:y|Y)[\sï¼š:]*[è½´]?', processed_text):
                axis_detected = 'y'
            elif re.search(r'(?:z|Z)[\sï¼š:]*[è½´]?', processed_text):
                axis_detected = 'z'
            
            # æ£€æµ‹åç§»å…³é”®è¯
            offset_detected = re.search(r'åç§»', processed_text) is not None
            
            # æå–æ‰€æœ‰æ•°å­—
            numbers = []
            number_pattern = r'[-+]?\d*\.?\d+'
            number_strings = re.findall(number_pattern, processed_text)
            
            for num_str in number_strings:
                try:
                    numbers.append(float(num_str))
                except ValueError:
                    continue
            
            print(f"[DEBUG] åå¤‡æ•°å­—åˆ—è¡¨: {numbers}")
            
            # æ™ºèƒ½åˆ†é…å‚æ•°
            if offset_detected and axis_detected and numbers:
                parameters[f'offset_{axis_detected}'] = numbers[0]
                print(f"[DEBUG] æ™ºèƒ½åˆ†é…: offset_{axis_detected}={numbers[0]}")
            elif offset_detected and numbers:
                # é»˜è®¤åˆ†é…åˆ°Zè½´
                parameters['offset_z'] = numbers[0]
                print(f"[DEBUG] é»˜è®¤åˆ†é…: offset_z={numbers[0]}")
        
        print(f"[DEBUG] æœ€ç»ˆæå–å‚æ•°: {parameters}")
        return parameters
    
    def normalize_colloquial_expressions(self, text):
        """å°†å£è¯­åŒ–è¡¨è¾¾è½¬æ¢ä¸ºæ ‡å‡†ä¸­æ–‡æ•°å­—"""
        # å£è¯­åŒ–æ•°å­—è½¬æ¢
        colloquial_map = {
            'ä¸¤': 'äºŒ',  # ä¸¤ç™¾ -> äºŒç™¾
            'ä¿©': 'äºŒ',  # ä¿©ç™¾ -> äºŒç™¾
            'ä»¨': 'ä¸‰',  # ä»¨ç™¾ -> ä¸‰ç™¾
            'å»¿': 'äºŒå', # å»¿ä¸€ -> äºŒåä¸€
            'å…': 'ä¸‰å', # å…ä¸€ -> ä¸‰åä¸€
            'åŒ': 'å››å'  # åŒä¸€ -> å››åä¸€
        }
        
        # å£è¯­åŒ–é‡è¯è½¬æ¢
        measure_word_map = {
            'ä¸ª': '',
            'åª': '',
            'æ¡': '',
            'å¼ ': '',
            'å—': '',
            'æš': ''
        }
        
        # æ›¿æ¢å£è¯­åŒ–æ•°å­—
        for colloquial, standard in colloquial_map.items():
            text = text.replace(colloquial, standard)
        
        # æ›¿æ¢å£è¯­åŒ–é‡è¯
        for measure_word in measure_word_map:
            text = text.replace(measure_word, measure_word_map[measure_word])
        
        return text
    
    def apply_voice_parameters(self, parameters):
        """åº”ç”¨ä»è¯­éŸ³ä¸­æå–çš„å‚æ•°"""
        try:
            print(f"[DEBUG] åº”ç”¨è¯­éŸ³å‚æ•°: {parameters}")
            
            # ç¡®ä¿ä½¿ç”¨æå–çš„å‚æ•°
            if not parameters:
                print("[WARNING] æ²¡æœ‰æå–åˆ°å‚æ•°")
                self.speak_response("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå‚æ•°")
                return False
            
            # æ›´æ–°UIæ˜¾ç¤º
            if 'offset_x' in parameters:
                self.offset_x_input.setText(str(parameters['offset_x']))
                self.user_offset_x = parameters['offset_x']
            if 'offset_y' in parameters:
                self.offset_y_input.setText(str(parameters['offset_y']))
                self.user_offset_y = parameters['offset_y']
            if 'offset_z' in parameters:
                self.offset_z_input.setText(str(parameters['offset_z']))
                self.user_offset_z = parameters['offset_z']
            
            # ç”Ÿæˆåé¦ˆæ¶ˆæ¯
            feedback = "å‚æ•°ä¿®æ”¹æˆåŠŸ"
            if 'offset_x' in parameters:
                feedback += f"ï¼ŒXåç§»è®¾ç½®ä¸º{parameters['offset_x']}æ¯«ç±³"
            if 'offset_y' in parameters:
                feedback += f"ï¼ŒYåç§»è®¾ç½®ä¸º{parameters['offset_y']}æ¯«ç±³"
            if 'offset_z' in parameters:
                feedback += f"ï¼ŒZåç§»è®¾ç½®ä¸º{parameters['offset_z']}æ¯«ç±³"
            
            # è¯­éŸ³åé¦ˆ
            self.speak_response(feedback)
            
            return True
        except Exception as e:
            print(f"[ERROR] åº”ç”¨å‚æ•°å¤±è´¥: {str(e)}")
            self.speak_response("å‚æ•°åº”ç”¨å¤±è´¥")
            return False
    
    def detect_wake_word(self, text):
        """ä½¿ç”¨æ‹¼éŸ³ç›¸ä¼¼åº¦æ£€æµ‹å”¤é†’è¯"""
        # å”¤é†’è¯åˆ—è¡¨
        wake_words = ["å°æ™º", "å°å¿—", "å°åˆ¶", "å°çŸ¥", "å°ä¹‹", "å°ç›´", "å°çº¸"]
        
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºæ‹¼éŸ³
        text_pinyin = ''.join(lazy_pinyin(text, style=Style.NORMAL))
        
        # æ£€æŸ¥æ¯ä¸ªå”¤é†’è¯çš„æ‹¼éŸ³ç›¸ä¼¼åº¦
        for word in wake_words:
            word_pinyin = ''.join(lazy_pinyin(word, style=Style.NORMAL))
            
            # ç®€å•ç›¸ä¼¼åº¦æ£€æŸ¥
            if word_pinyin in text_pinyin:
                return True
            if len(word_pinyin) > 2 and text_pinyin.startswith(word_pinyin[:2]):
                return True
        return False










































 
    def toggle_camera(self):
        """åˆ‡æ¢æ‘„åƒå¤´çŠ¶æ€"""
        if not hasattr(self, 'camera_thread') or not self.camera_thread or not self.camera_thread.isRunning():
            # è·å–æ‘„åƒå¤´ç±»å‹å’Œå‚æ•°
            camera_type = "network" if self.camera_type_combo.currentIndex() == 1 else "local"
            ip = self.camera_ip_input.text()
            port = int(self.camera_port_input.text())

            # åˆ›å»ºæ‘„åƒå¤´çº¿ç¨‹
            self.camera_thread = CameraThread(camera_type, ip, port)
            self.camera_thread.update_frame.connect(self.update_frame)
            self.camera_thread.status_changed.connect(self.update_camera_status)
            self.camera_thread.start()

            self.open_camera_btn.setText("æ‘„åƒå¤´è¿è¡Œä¸­")
            self.open_camera_btn.setEnabled(False)
            self.close_camera_btn.setEnabled(True)
        else:
            QMessageBox.information(self, "æ‘„åƒå¤´çŠ¶æ€", "æ‘„åƒå¤´å·²åœ¨è¿è¡Œä¸­")

    def close_camera(self):
        """å…³é—­æ‘„åƒå¤´"""
        if hasattr(self, 'camera_thread') and self.camera_thread and self.camera_thread.isRunning():
            self.camera_thread.stop()
            self.camera_thread = None

            # æ¸…ç©ºç”»é¢
            self.detection_label.clear()
            self.detection_label.setText("æ‘„åƒå¤´å·²å…³é—­")

            self.open_camera_btn.setText("æ‰“å¼€æ‘„åƒå¤´")
            self.open_camera_btn.setEnabled(True)
            self.close_camera_btn.setEnabled(False)
            self.update_camera_status("æ‘„åƒå¤´: å…³é—­")

    def update_camera_status(self, message):
        """æ›´æ–°æ‘„åƒå¤´çŠ¶æ€"""
        self.camera_status_label.setText(message)
        if "æ‘„åƒå¤´: " not in message:
            self.camera_status_label.setText(f"æ‘„åƒå¤´: {message}")

    def handle_task_completed(self, task_id, result):
        """å¤„ç†ä»»åŠ¡å®Œæˆ"""
        print(f"ä»»åŠ¡ {task_id} å®Œæˆï¼Œç»“æœç±»å‹: {type(result)}")

        # æ ¹æ®ä»»åŠ¡IDæ‰§è¡Œç›¸åº”çš„åç»­æ“ä½œ
        if task_id == self.task_ids.get('camera'):
            self.update_camera_frame(result)
        elif task_id == self.task_ids.get('point_cloud'):
            # ç‚¹äº‘æ•°æ®è·å–ä»»åŠ¡å®Œæˆ
            self._handle_point_cloud_completed(result)
            # æ¸…ç†ä»»åŠ¡ID
            self.task_ids['point_cloud'] = None
        elif task_id == getattr(self, 'current_grinding_task_id', None):
            # æ‰“ç£¨ä»»åŠ¡å®Œæˆ
            print("æ‰“ç£¨ä»»åŠ¡å®Œæˆ")
            # åœ¨ä¸»çº¿ç¨‹ä¸­å®‰å…¨æ›´æ–°UI
            self.grinding_button.setText("å¯åŠ¨æ‰“ç£¨")
            self.grinding_button.setStyleSheet("")
            self.grinding_status_indicator.setStyleSheet("background-color: #FF0000; border-radius: 10px;")
            self.grinding_progress_label.setText("æ‰“ç£¨: å®Œæˆ")
            self.speak_response("æ‰“ç£¨å·²å®Œæˆ")

            # æ¸…ç†ä»»åŠ¡ID
            self.current_grinding_task_id = None
        else:
            # å…¶ä»–ç±»å‹çš„ä»»åŠ¡
            print(f"æœªçŸ¥ä»»åŠ¡ {task_id} å®Œæˆ")

    def handle_task_failed(self, task_id, exception):
        """å¤„ç†ä»»åŠ¡å¤±è´¥"""
        print(f"ä»»åŠ¡ {task_id} å¤±è´¥: {exception}")

        if task_id == self.task_ids.get('camera'):
            # æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯æˆ–æ‰§è¡Œæ¢å¤æ“ä½œ
            pass
        elif task_id == self.task_ids.get('point_cloud'):
            # ç‚¹äº‘æ•°æ®è·å–ä»»åŠ¡å¤±è´¥
            self._handle_point_cloud_failed(exception)
            # æ¸…ç†ä»»åŠ¡ID
            self.task_ids['point_cloud'] = None
        elif task_id == getattr(self, 'current_grinding_task_id', None):
            # æ‰“ç£¨ä»»åŠ¡å¤±è´¥
            print(f"æ‰“ç£¨ä»»åŠ¡å¤±è´¥: {exception}")
            # åœ¨ä¸»çº¿ç¨‹ä¸­å®‰å…¨æ›´æ–°UI
            self.grinding_button.setText("å¯åŠ¨æ‰“ç£¨")
            self.grinding_button.setStyleSheet("")
            self.grinding_status_indicator.setStyleSheet("background-color: #FF0000; border-radius: 10px;")
            self.grinding_progress_label.setText("æ‰“ç£¨: å¤±è´¥")
            self.speak_response("æ‰“ç£¨ä»»åŠ¡å¤±è´¥")

            # æ¸…ç†ä»»åŠ¡ID
            self.current_grinding_task_id = None
        else:
            # å…¶ä»–ç±»å‹çš„ä»»åŠ¡å¤±è´¥
            print(f"æœªçŸ¥ä»»åŠ¡ {task_id} å¤±è´¥")

    def start_camera_task(self):
        """å¯åŠ¨æ‘„åƒå¤´ä»»åŠ¡"""
        if self.task_ids.get('camera') is not None:
            print("æ‘„åƒå¤´ä»»åŠ¡å·²åœ¨è¿è¡Œ")
            return

        task_id = self.thread_pool.submit_task(self._camera_worker)
        self.task_ids['camera'] = task_id
        print(f"å¯åŠ¨æ‘„åƒå¤´ä»»åŠ¡ï¼ŒID: {task_id}")

    def _camera_worker(self):
        """æ‘„åƒå¤´å·¥ä½œçº¿ç¨‹"""
        try:
            # æ‘„åƒå¤´å¤„ç†é€»è¾‘
            while self.camera_active:
                frame = self.capture_frame()
                if frame is not None:
                    # å¤„ç†å¸§å¹¶è¿”å›ç»“æœ
                    processed_frame = self.process_frame(frame)
                    return processed_frame
                time.sleep(0.03)
        except Exception as e:
            print(f"æ‘„åƒå¤´å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
            raise

    def start_detection_task(self, image):
        """å¯åŠ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡"""
        task_id = self.thread_pool.submit_task(self._detection_worker, image)
        self.task_ids['detection'] = task_id
        return task_id

    def _detection_worker(self, image):
        """ç›®æ ‡æ£€æµ‹å·¥ä½œçº¿ç¨‹"""
        try:
            # ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹
            boxes, scores, class_ids = self.yolo_model.detect(image)

            # å¤„ç†æ£€æµ‹ç»“æœ
            result = {
                'boxes': boxes,
                'scores': scores,
                'class_ids': class_ids,
                'timestamp': time.time()
            }

            return result
        except Exception as e:
            print(f"ç›®æ ‡æ£€æµ‹å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
            raise

    def start_audio_processing_task(self, audio_data):
        """å¯åŠ¨éŸ³é¢‘å¤„ç†ä»»åŠ¡"""
        task_id = self.thread_pool.submit_task(self._audio_worker, audio_data)
        self.task_ids['audio'] = task_id
        return task_id

    def _audio_worker(self, audio_data):
        """éŸ³é¢‘å¤„ç†å·¥ä½œçº¿ç¨‹"""
        try:
            # è¯­éŸ³è¯†åˆ«å¤„ç†
            text = self.asr_model.transcribe(audio_data)

            # è‡ªç„¶è¯­è¨€å¤„ç†
            command = self.nlp_model.process(text)

            return {
                'text': text,
                'command': command,
                'timestamp': time.time()
            }
        except Exception as e:
            print(f"éŸ³é¢‘å¤„ç†å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
            raise

    def start_motion_task(self, target_position):
        """å¯åŠ¨è¿åŠ¨æ§åˆ¶ä»»åŠ¡"""
        task_id = self.thread_pool.submit_task(self._motion_worker, target_position)
        self.task_ids['motion'] = task_id
        return task_id

    def _motion_worker(self, target_position):
        """è¿åŠ¨æ§åˆ¶å·¥ä½œçº¿ç¨‹"""
        try:
            # è¿åŠ¨è§„åˆ’å’Œæ§åˆ¶é€»è¾‘
            trajectory = self.planner.plan_trajectory(
                self.robot.get_current_position(),
                target_position
            )

            # æ‰§è¡Œè½¨è¿¹
            for point in trajectory:
                self.robot.move_to(point)
                time.sleep(0.1)  # æ§åˆ¶è¿åŠ¨é€Ÿåº¦

            return {
                'success': True,
                'final_position': self.robot.get_current_position(),
                'timestamp': time.time()
            }
        except Exception as e:
            print(f"è¿åŠ¨æ§åˆ¶å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': time.time()
            }

    def start_calibration_task(self):
        """å¯åŠ¨æ ‡å®šä»»åŠ¡"""
        task_id = self.thread_pool.submit_task(self._calibration_worker)
        self.task_ids['calibration'] = task_id
        return task_id

    def _calibration_worker(self):
        """æ ‡å®šå·¥ä½œçº¿ç¨‹"""
        try:
            # æ‰§è¡Œæ ‡å®šæµç¨‹
            calibration_data = self.calibrator.perform_calibration()

            # ä¿å­˜æ ‡å®šç»“æœ
            self.calibrator.save_calibration(calibration_data)

            return {
                'success': True,
                'data': calibration_data,
                'timestamp': time.time()
            }
        except Exception as e:
            print(f"æ ‡å®šå·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': time.time()
            }

    def stop_all_tasks(self):
        """åœæ­¢æ‰€æœ‰ä»»åŠ¡"""
        # åœæ­¢ç‰¹å®šç±»å‹çš„ä»»åŠ¡
        self.camera_active = False

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        self.thread_pool.shutdown(wait=True)

        # é‡ç½®ä»»åŠ¡ID
        for key in self.task_ids:
            self.task_ids[key] = None

    def closeEvent(self, event):
        """å…³é—­åº”ç”¨ç¨‹åºæ—¶æ¸…ç†èµ„æº"""
        self.stop_all_tasks()
        super().closeEvent(event)