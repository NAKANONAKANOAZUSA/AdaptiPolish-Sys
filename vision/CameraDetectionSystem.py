import cv2
import numpy as np
import json
import time
import os
import queue
import threading
import socket
import struct
import onnxruntime as ort


class CameraDetectionSystem:
    """æ‘„åƒå¤´æ¥æ”¶ã€ç›®æ ‡æ£€æµ‹ã€åæ ‡è½¬æ¢çš„ç³»ç»Ÿ"""

    def __init__(self,config,server_ip='0.0.0.0', server_port=9999):
        self.config = config
        #self.model_path = model_path  # ONNXæ¨¡å‹æ–‡ä»¶è·¯å¾„
        self.server_ip = server_ip  # æœåŠ¡å™¨IPåœ°å€ï¼ˆé»˜è®¤ç›‘å¬æ‰€æœ‰æ¥å£ï¼‰
        self.server_port = server_port  # æœåŠ¡å™¨ç«¯å£å·
        self.input_size = (640, 640)  # æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼ˆå®½åº¦ï¼Œé«˜åº¦ï¼‰
        self.conf_thres = 0.25  # ç›®æ ‡æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ25%ä»¥ä¸Šæ‰ä¿ç•™ï¼‰
        self.nms_thres = 0.45  # éæå¤§å€¼æŠ‘åˆ¶é˜ˆå€¼ï¼ˆè¿‡æ»¤é‡å æ£€æµ‹æ¡†ï¼‰
        self.num_classes = 80  # ç›®æ ‡ç±»åˆ«æ•°é‡ï¼ˆåˆå§‹å€¼ï¼Œå®é™…ä»æ¨¡å‹è·å–ï¼‰
        self.calibration_complete = False  # æ ‡å®šå®Œæˆæ ‡å¿—ï¼ˆæ‘„åƒå¤´æ ‡å®šçŠ¶æ€ï¼‰
        self.c_x = 0  # æ ‡å®šä¸­å¿ƒç‚¹Xåæ ‡ï¼ˆåƒç´ åæ ‡ç³»ï¼‰
        self.c_y = 0  # æ ‡å®šä¸­å¿ƒç‚¹Yåæ ‡ï¼ˆåƒç´ åæ ‡ç³»ï¼‰
        self.ratio = 0  # åƒç´ åˆ°ä¸–ç•Œåæ ‡è½¬æ¢æ¯”ä¾‹ï¼ˆæ¯«ç±³/åƒç´ ï¼‰
        self.camera_offset_x = 165  # ç›¸æœºç›¸å¯¹äºæœºå™¨äººåŸºåº§çš„Xåç§»(mm)
        self.camera_offset_y = 5  # ç›¸æœºç›¸å¯¹äºæœºå™¨äººåŸºåº§çš„Yåç§»(mm)
        self.calibration_frames = []  # å­˜å‚¨æ ‡å®šè¿‡ç¨‹ä¸­æ”¶é›†çš„å¸§æ•°æ®
        self.calibration_in_progress = False  # æ ‡å®šè¿›è¡Œä¸­æ ‡å¿—
        self.frame_queue = queue.Queue(maxsize=10)  # å¸§é˜Ÿåˆ—ï¼ˆå­˜å‚¨æ¥æ”¶çš„è§†é¢‘å¸§ï¼‰
        self.stop_event = threading.Event()  # åœæ­¢äº‹ä»¶ï¼ˆç”¨äºçº¿ç¨‹å®‰å…¨åœæ­¢ï¼‰
        self.receive_thread = None  # è§†é¢‘æ¥æ”¶çº¿ç¨‹
        self.session = None  # ONNXè¿è¡Œæ—¶ä¼šè¯
        self.input_name = None  # æ¨¡å‹è¾“å…¥èŠ‚ç‚¹åç§°
        self.output_name = None  # æ¨¡å‹è¾“å‡ºèŠ‚ç‚¹åç§°
        self.output_dir = "contour_data"  # è½®å»“æ•°æ®è¾“å‡ºç›®å½•
        self.frame_counter = 0  # å¸§è®¡æ•°å™¨ï¼ˆè®°å½•å¤„ç†å¸§æ•°ï¼‰
        self.fixed_contour = None  # å­˜å‚¨å›ºå®šè½®å»“æ•°æ®
        self.fixed_contour_size = None  # å­˜å‚¨å›ºå®šè½®å»“å¯¹åº”çš„å›¾åƒå°ºå¯¸
        self.save_as_fixed = False  # ä¿å­˜ä¸ºå›ºå®šè½®å»“æ ‡å¿—
        self.init_aruco()  # åˆå§‹åŒ–ArUcoæ£€æµ‹å™¨
        self.num_mask = 32  # æ©è†œé€šé“æ•°ï¼ˆç”¨äºå®ä¾‹åˆ†å‰²ï¼‰
        self.num_classes = 0  # é‡ç½®ç±»åˆ«æ•°é‡ï¼ˆå®é™…ä»æ¨¡å‹è·å–ï¼‰
        self.image_width = 640  # é»˜è®¤å›¾åƒå®½åº¦
        self.image_height = 480  # é»˜è®¤å›¾åƒé«˜åº¦
        self.model_path = None

    def preprocess(self, image):
        """å›¾åƒé¢„å¤„ç†"""
        orig_h, orig_w = image.shape[:2]
        input_tensor = cv2.resize(image, (640, 640))
        input_tensor = cv2.cvtColor(input_tensor, cv2.COLOR_BGR2RGB)
        input_tensor = input_tensor.astype(np.float32) / 255.0
        input_tensor = np.transpose(input_tensor, (2, 0, 1))
        return np.expand_dims(input_tensor, axis=0), (orig_w, orig_h)

    def infer(self, image):
        """æ¨ç†å‡½æ•°"""
        input_tensor, orig_size = self.preprocess(image)
        outputs = self.session.run(self.output_names, {self.input_name: input_tensor})
        det_output, mask_output = outputs
        predictions = np.squeeze(det_output).T
        mask_protos = mask_output[0]

        boxes, masks = [], []
        orig_w, orig_h = orig_size

        best_confidence = self.config.CONFIDENCE_THRESHOLD
        best_pred = None

        # å¾ªç¯å¯»æ‰¾æœ€é«˜ç½®ä¿¡åº¦ç›®æ ‡
        for pred in predictions:
            if self.num_classes > 0:
                scores = pred[5:5 + self.num_classes]
                class_id = np.argmax(scores)
                confidence = scores[class_id]
            else:
                confidence = pred[4]
                class_id = 0

            # æ›´æ–°æœ€ä½³ç›®æ ‡
            if confidence > 0.5 and confidence > best_confidence:
                best_confidence = confidence
                best_pred = pred

        # å¤„ç†æ‰¾åˆ°çš„æœ€ä½³ç›®æ ‡
        if best_pred is not None:
            if self.num_classes > 0:
                scores = best_pred[5:5 + self.num_classes]
                class_id = int(np.argmax(scores))
            else:
                class_id = 0

            # åæ ‡è½¬æ¢å’Œæ•°æ®å¤„ç†
            x, y, w, h = best_pred[0:4]
            x *= orig_w / 640
            y *= orig_h / 640
            w *= orig_w / 640
            h *= orig_h / 640
            mask_coeffs = best_pred[-self.num_mask:]

            boxes.append({
                'class_id': class_id,
                'confidence': float(best_confidence),
                'bbox': [float(x), float(y), float(w), float(h)]
            })
            masks.append(mask_coeffs)

        return boxes, masks, mask_protos, (orig_w, orig_h)

    def extract_contour_data(image, boxes, masks, protos, img_size):
        """æå–å¹¶è¿”å›ç›®æ ‡çš„è½®å»“æ•°æ®"""
        if not boxes:
            return None, image

        # è·å–ç›®æ ‡è¾¹ç•Œæ¡†ä¿¡æ¯
        x, y, w, h = boxes[0]['bbox']
        bbox_x1 = int(x - w / 2)
        bbox_y1 = int(y - h / 2)
        bbox_x2 = int(x + w / 2)
        bbox_y2 = int(y + h / 2)
        bbox_area = w * h

        # å¤„ç†æ©è†œ
        masks_np = np.stack(masks, axis=0)
        protos_flat = protos.reshape(32, -1)
        mask_output = masks_np @ protos_flat
        mask_output = 1 / (1 + np.exp(-mask_output))
        mask_output = mask_output.reshape(-1, protos.shape[1], protos.shape[2])
        m = mask_output[0]
        m = cv2.resize(m, img_size, interpolation=cv2.INTER_LINEAR)

        # äºŒå€¼åŒ–æ©è†œ
        _, binary_mask = cv2.threshold(m, 0.5, 255, cv2.THRESH_BINARY)
        binary_mask = binary_mask.astype(np.uint8)
        kernel = np.ones((3, 3), np.uint8)
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

        # æŸ¥æ‰¾æ‰€æœ‰è½®å»“
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None, image

        # ç­›é€‰æœ‰æ•ˆè½®å»“
        valid_contours = []
        for contour in contours:
            contour_x, contour_y, contour_w, contour_h = cv2.boundingRect(contour)
            contour_x2 = contour_x + contour_w
            contour_y2 = contour_y + contour_h

            overlap_x1 = max(bbox_x1, contour_x)
            overlap_y1 = max(bbox_y1, contour_y)
            overlap_x2 = min(bbox_x2, contour_x2)
            overlap_y2 = min(bbox_y2, contour_y2)

            overlap_width = max(0, overlap_x2 - overlap_x1)
            overlap_height = max(0, overlap_y2 - overlap_y1)
            overlap_area = overlap_width * overlap_height

            contour_area = cv2.contourArea(contour)

            if overlap_area > 0.5 * bbox_area and 0.1 * bbox_area < contour_area < 2.0 * bbox_area:
                valid_contours.append(contour)

        if not valid_contours:
            return None, image

        # å¤„ç†ä¸»è½®å»“
        main_contour = max(valid_contours, key=cv2.contourArea)
        contour_points = []

        # è‡ªé€‚åº”è½®å»“ç®€åŒ–
        if main_contour is not None and len(main_contour) > 4:
            # è®¡ç®—è½®å»“å‘¨é•¿
            contour_length = cv2.arcLength(main_contour, True)
            base_epsilon = 0.005 * contour_length

            # è®¡ç®—æ›²ç‡å˜åŒ–
            curvature_scores = []
            for i in range(1, len(main_contour) - 1):
                p1 = main_contour[i - 1][0]
                p2 = main_contour[i][0]
                p3 = main_contour[i + 1][0]

                # è®¡ç®—å‘é‡
                vec1 = (p1[0] - p2[0], p1[1] - p2[1])
                vec2 = (p3[0] - p2[0], p3[1] - p2[1])

                # è®¡ç®—è§’åº¦å·®
                angle1 = np.arctan2(vec1[1], vec1[0])
                angle2 = np.arctan2(vec2[1], vec2[0])
                angle_diff = np.abs(np.degrees(angle1 - angle2))
                angle_diff = min(angle_diff, 360 - angle_diff)
                curvature_scores.append(angle_diff)

            # ç‚¹çº§åˆ«è‡ªé€‚åº”ç®€åŒ–
            for i in range(len(main_contour)):
                if i == 0 or i == len(main_contour) - 1:
                    # ä¿ç•™èµ·ç‚¹å’Œç»ˆç‚¹
                    contour_points.append(main_contour[i][0].tolist())
                    continue

                # è·å–å±€éƒ¨æ›²ç‡
                prev_score = curvature_scores[i - 1] if i >= 1 else 0
                curr_score = curvature_scores[i] if i < len(curvature_scores) else 0
                max_curvature = max(prev_score, curr_score)

                # åœ¨å¹³ç›´åŒºåŸŸåº”ç”¨æ›´å¼ºçš„ç®€åŒ–
                epsilon = base_epsilon
                if max_curvature < 60:  # å°è§’åº¦
                    # åˆ›å»ºå±€éƒ¨ç‰‡æ®µ
                    start_idx = max(0, i - 1)
                    end_idx = min(len(main_contour), i + 2)
                    segment = main_contour[start_idx:end_idx]

                    # ç®€åŒ–å±€éƒ¨ç‰‡æ®µ
                    if len(segment) > 2:
                        segment = segment.reshape(-1, 1, 2)
                        simplified = cv2.approxPolyDP(segment, epsilon, False)

                        # åªä¿ç•™ä¸­é—´ç‚¹
                        if len(simplified) == 3:
                            contour_points.append(simplified[1][0].tolist())
                    else:
                        contour_points.append(main_contour[i][0].tolist())
                else:
                    # åœ¨æ‹ç‚¹å¤„ä¿ç•™åŸå§‹ç‚¹
                    contour_points.append(main_contour[i][0].tolist())
        else:
            # ç®€åŒ–çŸ­è½®å»“
            contour_points = main_contour.squeeze().tolist()

        # ç¡®ä¿æ ¼å¼æ­£ç¡®
        if len(contour_points) > 0 and not isinstance(contour_points[0], list):
            contour_points = [contour_points]

        # è½®å»“ç‚¹åå¤„ç† - ç§»é™¤å¼‚å¸¸ç‚¹
        if len(contour_points) > 2:
            filtered_points = []
            max_distance = min(img_size) * 0.05  # æœ€å¤§å…è®¸è·ç¦»ï¼ˆå›¾åƒå°ºå¯¸çš„5%ï¼‰

            for i in range(len(contour_points)):
                current_point = contour_points[i]

                if len(filtered_points) > 0:
                    prev_point = filtered_points[-1]
                    distance = np.sqrt((current_point[0] - prev_point[0]) ** 2 +
                                       (current_point[1] - prev_point[1]) ** 2)

                    if distance < max_distance:
                        filtered_points.append(current_point)
                    else:
                        # æ·»åŠ ä¸­ç‚¹ä½œä¸ºè¿‡æ¸¡ç‚¹
                        mid_point = [
                            (prev_point[0] + current_point[0]) / 2,
                            (prev_point[1] + current_point[1]) / 2
                        ]
                        filtered_points.append(mid_point)
                        filtered_points.append(current_point)
                else:
                    filtered_points.append(current_point)

            contour_points = filtered_points

        # åˆ›å»ºè½®å»“æ•°æ®ç»“æ„
        contour_data = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "confidence": boxes[0]['confidence'],
            "class_id": boxes[0]['class_id'],
            "bbox": boxes[0]['bbox'],
            "contour_points": contour_points,
            "image_size": img_size
        }

        # å‡†å¤‡è½®å»“ç‚¹ç”¨äºç»˜åˆ¶
        contour_array = np.array(contour_points, dtype=np.int32).reshape((-1, 1, 2))

        # ç»˜åˆ¶è½®å»“
        overlay = image.copy()
        cv2.rectangle(overlay, (bbox_x1, bbox_y1), (bbox_x2, bbox_y2), (0, 255, 0), 2)
        cv2.drawContours(overlay, [contour_array], -1, (0, 0, 255), 3)

        if len(contour_points) > 0:
            start_point = tuple(map(int, contour_points[0]))
            cv2.circle(overlay, start_point, 8, (255, 0, 0), -1)
            cv2.putText(overlay, "Start", (start_point[0] + 10, start_point[1]),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        cv2.putText(overlay, f"Conf: {boxes[0]['confidence']:.2f}",
                    (bbox_x1, bbox_y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # æ·»åŠ ç‚¹æ•°é‡æ˜¾ç¤º
        cv2.putText(overlay, f"Points: {len(contour_points)}",
                    (10, image.shape[0] - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        return contour_data, overlay

    def draw_fixed_contour(image, fixed_contour, original_size):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶å›ºå®šè½®å»“"""
        overlay = image.copy()

        if not fixed_contour:
            return overlay

        # è½¬æ¢ä¸ºå¯ç»˜åˆ¶çš„æ ¼å¼
        points_array = np.array(fixed_contour, dtype=np.int32).reshape((-1, 1, 2))

        # ç»˜åˆ¶è½®å»“
        cv2.drawContours(overlay, [points_array], -1, (0, 255, 255), 3)

        # æ ‡è®°è½®å»“èµ·ç‚¹
        if len(points_array) > 0:
            start_point = tuple(points_array[0][0])
            cv2.circle(overlay, start_point, 8, (255, 100, 0), -1)
            cv2.putText(overlay, "Fixed", (start_point[0] + 10, start_point[1]),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 100, 0), 2)

        # æ·»åŠ å›ºå®šè½®å»“æ ‡è®°
        cv2.putText(overlay, "Fixed Contour", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        return overlay

    def save_contour_data(self,contour_data, frame_count, is_fixed=False):
        """ä¿å­˜è½®å»“æ•°æ®åˆ°JSONæ–‡ä»¶"""
        if contour_data is None:
            return

        prefix = "fixed_" if is_fixed else ""
        filename = os.path.join(self.config.OUTPUT_DIR, f"{prefix}contour_{frame_count}.json")
        with open(filename, 'w') as f:
            json.dump(contour_data, f, indent=2)

        print(f"ğŸ’¾ è½®å»“æ•°æ®å·²ä¿å­˜åˆ°: {filename}")

    def draw_masks_on_image(self, image, boxes, mask_coeffs, mask_protos, img_size):
        """æ©ç å åŠ """
        masks = []
        for coeff in mask_coeffs:
            mask = np.tensordot(coeff.astype(np.float32), mask_protos.astype(np.float32), axes=([0], [0]))
            mask = 1 / (1 + np.exp(-mask))
            mask = cv2.resize(mask, img_size)
            mask = (mask > 0.5).astype(np.uint8) * 255
            masks.append(mask)

        for m in masks:
            color = np.random.randint(0, 255, (3,), dtype=np.uint8)
            overlay = np.zeros_like(image)
            for c in range(3):
                overlay[:, :, c] = m * color[c] // 255
            image = cv2.addWeighted(image, 1.0, overlay, 0.5, 0)
        return image

    def init_aruco(self):
        """åˆå§‹åŒ–ArUcoæ£€æµ‹å™¨"""
        # try:
        #     # ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ArUco API
        #     self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)
        #     self.aruco_params = cv2.aruco.DetectorParameters()
        # except AttributeError:
        #     # å¯¹äºæ—§ç‰ˆæœ¬çš„OpenCVä½¿ç”¨æ—§API
        #     self.aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250)
        #     self.aruco_params = cv2.aruco.DetectorParameters_create()

        # å¯¹äºæ—§ç‰ˆæœ¬çš„OpenCVä½¿ç”¨æ—§API
        self.aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250)
        self.aruco_params = cv2.aruco.DetectorParameters_create()

    def load_model(self,model_path):
        """åŠ è½½ONNXæ¨¡å‹"""
        if not model_path or not os.path.exists(model_path):
            raise ValueError(f"æ— æ•ˆçš„æ¨¡å‹è·¯å¾„: {model_path}")
        try:
            self.model_path = model_path
            print(f"[INFO] åŠ è½½æ¨¡å‹: {self.model_path}")
            self.session = ort.InferenceSession(
                self.model_path,
                providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
            )
            print("Providers:", self.session.get_providers())
            self.input_name = self.session.get_inputs()[0].name
            self.output_names = [o.name for o in self.session.get_outputs()]
            print(f"[INFO] æ¨¡å‹åŠ è½½æˆåŠŸ! è¾“å…¥å: {self.input_name}, è¾“å‡ºå: {self.output_names}")

            # è·å–æ¨¡å‹è¾“å…¥å°ºå¯¸
            input_info = self.session.get_inputs()[0]
            input_shape = input_info.shape
            if len(input_shape) == 4:  # [batch, channel, height, width]
                height = input_shape[2]
                width = input_shape[3]
                self.input_size = (width, height)
                print(f"[INFO] æ¨¡å‹è¾“å…¥å°ºå¯¸ä¸º: {self.input_size}")
            elif len(input_shape) == 3:  # [batch, height, width]
                height = input_shape[1]
                width = input_shape[2]
                self.input_size = (width, height)
                print(f"[INFO] æ¨¡å‹è¾“å…¥å°ºå¯¸ä¸º: {self.input_size}")
            else:
                print(f"[WARNING] æ— æ³•è¯†åˆ«çš„è¾“å…¥å½¢çŠ¶: {input_shape}, ä½¿ç”¨é»˜è®¤å°ºå¯¸")
                self.input_size = (640, 640)

            # åŠ¨æ€æ£€æµ‹ç±»åˆ«æ•°é‡ï¼ˆå…³é”®æ›´æ–°ï¼‰
            output_info = self.session.get_outputs()[0]
            output_shape = output_info.shape
            if len(output_shape) >= 2:
                # è¾“å‡ºå½¢çŠ¶ä¸º [batch, 84, 8400]
                # 84 = (x, y, w, h, obj_conf) + num_classes + num_mask
                self.num_classes = output_shape[1] - 5 - self.num_mask
                print(f"[INFO] æ£€æµ‹åˆ° {self.num_classes} ä¸ªç±»åˆ«")
            else:
                self.num_classes = 80
                print("[WARNING] æ— æ³•ç¡®å®šç±»åˆ«æ•°é‡ï¼Œä½¿ç”¨é»˜è®¤å€¼80")

            return True
        except Exception as e:
            print(f"[ERROR] åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            return False

    def start_receiving(self):
        """å¯åŠ¨æ¥æ”¶çº¿ç¨‹"""
        if self.receive_thread and self.receive_thread.is_alive():
            return True

        self.receive_thread = threading.Thread(target=self.receive_video_thread, daemon=True)
        self.receive_thread.start()
        print("[SERVER] æ¥æ”¶çº¿ç¨‹å·²å¯åŠ¨")
        return True

    def save_calibration_params(self, file_path=None):
        """ä¿å­˜æ ‡å®šå‚æ•°åˆ°æ–‡ä»¶"""
        #file_path = file_path or os.path.join(self.config.CALIBRATION_FILE, file_path)
        try:
            file_path = self.config.CALIBRATION_FILE
            # os.path.join æ‹¼æ¥è·¯å¾„
            params = {
                'c_x': self.c_x,
                'c_y': self.c_y,
                'ratio': self.ratio,
                'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
            }
            with open(file_path, 'w') as f:
                json.dump(params, f, indent=4)
            print(f"[CALIBRATION] æ ‡å®šå‚æ•°å·²ä¿å­˜åˆ°: {file_path}")
            return True
        except Exception as e:
            print(f"[ERROR] ä¿å­˜æ ‡å®šå‚æ•°å¤±è´¥: {str(e)}")
            return False

    def load_calibration_params(self, file_path=None):
        """ä»æ–‡ä»¶åŠ è½½æ ‡å®šå‚æ•°"""
        try:
            file_path = file_path or os.path.join(self.config.CALIBRATION_FILE, file_path)
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    params = json.load(f)
                self.c_x = params.get('c_x', 0)
                self.c_y = params.get('c_y', 0)
                self.ratio = params.get('ratio', 0)
                self.calibration_complete = True
                print(f"[CALIBRATION] æ ‡å®šå‚æ•°å·²åŠ è½½: c_x={self.c_x}, c_y={self.c_y}, ratio={self.ratio}")
                return True
            else:
                print("[CALIBRATION] æœªæ‰¾åˆ°æ ‡å®šæ–‡ä»¶")
                return False
        except Exception as e:
            print(f"[ERROR] åŠ è½½æ ‡å®šå‚æ•°å¤±è´¥: {str(e)}")
            return False

    def receive_video_thread(self):
        """åœ¨å­çº¿ç¨‹ä¸­æ¥æ”¶è§†é¢‘å¸§"""
        try:
            server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            server_socket.bind((self.server_ip, self.server_port))
            server_socket.listen(5)
            print(f"[SERVER] æœåŠ¡ç«¯å·²å¯åŠ¨ï¼Œæ­£åœ¨ç›‘å¬ {self.server_ip}:{self.server_port}")

            client_socket, client_addr = server_socket.accept()
            print(f"[SERVER] å·²æ¥å—æ¥è‡ª {client_addr} çš„è¿æ¥")
            payload_size = struct.calcsize('>I')

            data = b""
            while not self.stop_event.is_set():
                try:
                    # è¯»å–å¸§é•¿åº¦ä¿¡æ¯
                    while len(data) < payload_size:
                        packet = client_socket.recv(4096)
                        if not packet:
                            print("[SERVER] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
                            break
                        data += packet

                    if len(data) < payload_size:
                        print("[SERVER] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
                        break

                    packed_msg_size = data[:payload_size]
                    data = data[payload_size:]
                    msg_size = struct.unpack('>I', packed_msg_size)[0]

                    # è¯»å–å®Œæ•´çš„å¸§æ•°æ®
                    while len(data) < msg_size:
                        to_receive = min(4096, msg_size - len(data))
                        packet = client_socket.recv(to_receive)
                        if not packet:
                            print("[SERVER] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
                            break
                        data += packet

                    if len(data) < msg_size:
                        print("[SERVER] è¿æ¥ä¸­æ–­ï¼Œæœªèƒ½æ¥æ”¶å®Œæ•´å¸§")
                        break

                    # åˆ†å‰²å‡ºå½“å‰å¸§æ•°æ®
                    frame_data = data[:msg_size]
                    data = data[msg_size:]
                    frame_array = np.frombuffer(frame_data, dtype=np.uint8)
                    frame = cv2.imdecode(frame_array, flags=cv2.IMREAD_COLOR)
                    if frame is not None:
                        self.image_height, self.image_width = frame.shape[:2]
                        self.frame_queue.put(frame.copy(), block=True, timeout=0.5)
                    if frame is None:
                        print("[SERVER] è§£ç å¸§å¤±è´¥")
                        continue

                    # å°†å¸§æ”¾å…¥é˜Ÿåˆ—ä¾›ä¸»çº¿ç¨‹ä½¿ç”¨
                    try:
                        self.frame_queue.put(frame.copy(), block=True, timeout=0.5)
                    except queue.Full:
                        # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œè·³è¿‡æ­¤å¸§
                        print("[SERVER] å¸§é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡å¸§")
                except socket.timeout:
                    print("[SERVER] å¥—æ¥å­—è¶…æ—¶")
                    continue
                except socket.error as e:
                    if not self.stop_event.is_set():
                        print(f"[SERVER] å¥—æ¥å­—é”™è¯¯: {str(e)}")
                    break
                except Exception as e:
                    print(f"[SERVER] æ¥æ”¶é”™è¯¯: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    break

        except Exception as e:
            print(f"[SERVER] æ¥æ”¶çº¿ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            print("[SERVER] æ¸…ç†æ¥æ”¶çº¿ç¨‹èµ„æº")
            if 'client_socket' in locals():
                client_socket.close()
            server_socket.close()
            print("[SERVER] æ¥æ”¶çº¿ç¨‹å·²åœæ­¢")

    def detect_aruco_markers(self, img):
        """æ£€æµ‹ArUcoæ ‡è®°å¹¶ç»˜åˆ¶åˆ°å›¾åƒä¸Šï¼Œè¿”å›æ£€æµ‹ç»“æœ"""
        if not self.calibration_complete or self.calibration_in_progress:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            try:
                # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ArUco API
                detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.aruco_params)
                corners, ids, _ = detector.detectMarkers(gray)
            except (AttributeError, TypeError):
                # å¯¹äºæ—§ç‰ˆæœ¬çš„OpenCVä½¿ç”¨æ—§API
                corners, ids, _ = cv2.aruco.detectMarkers(gray, self.aruco_dict, parameters=self.aruco_params)

            if ids is None or len(ids) < 2:
                return None

            marker_positions = []
            for i, corner in enumerate(corners):
                pts = corner[0]
                x = int(np.mean(pts[:, 0]))
                y = int(np.mean(pts[:, 1]))
                marker_positions.append((ids[i][0], x, y))

            # æŒ‰IDæ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
            marker_positions.sort(key=lambda x: x[0])

            if len(marker_positions) < 2:
                return None

            _, x1, y1 = marker_positions[0]
            _, x2, y2 = marker_positions[1]

            # ç»˜åˆ¶ArUcoæ ‡è®°
            try:
                # æ–°ç‰ˆæœ¬ç»˜åˆ¶æ–¹æ³•
                cv2.aruco.drawDetectedMarkers(img, corners, ids)
            except (AttributeError, TypeError):
                # æ—§ç‰ˆæœ¬ç»˜åˆ¶æ–¹æ³•
                cv2.aruco.drawDetectedMarkers(img, corners, ids)

            # åœ¨æ ‡è®°ä¸­å¿ƒç»˜åˆ¶åœ†ç‚¹
            cv2.circle(img, (x1, y1), 10, (0, 255, 0), 2)
            cv2.circle(img, (x2, y2), 10, (0, 255, 0), 2)
            cv2.putText(img, f"Marker 1", (x1 - 40, y1 - 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, f"Marker 2", (x2 - 40, y2 - 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            return x1, x2, y1, y2

        return None

    def pixel_to_world_coords(self, pixel_x, pixel_y, rotation=0):
        """
        å°†åƒç´ åæ ‡è½¬æ¢ä¸ºä¸–ç•Œåæ ‡ç³»åæ ‡
        """
        if not self.calibration_complete:
            return 0, 0, False

        if not hasattr(self, 'image_width') or not hasattr(self, 'image_height'):
            self.image_width = 640
            self.image_height = 480

        # å¤„ç†åæ ‡ç³»æ—‹è½¬
        if rotation == 90:
            # é¡ºæ—¶é’ˆæ—‹è½¬90åº¦
            temp = pixel_x
            pixel_x = self.image_height - pixel_y
            pixel_y = temp
        elif rotation == 180:
            pixel_x = self.image_width - pixel_x
            pixel_y = self.image_height - pixel_y
        elif rotation == 270:
            # é€†æ—¶é’ˆæ—‹è½¬90åº¦
            temp = pixel_x
            pixel_x = pixel_y
            pixel_y = self.image_width - temp

        # åº”ç”¨æ ‡å®šå‚æ•°
        offset_x = (pixel_y - self.c_y) * self.ratio
        offset_y = (pixel_x - self.c_x) * self.ratio

        world_x = offset_x + self.camera_offset_x
        world_y = offset_y + self.camera_offset_y

        return world_x, world_y, True

    def non_max_suppression(self, boxes, scores, iou_threshold):
        """æ‰§è¡Œéæå¤§å€¼æŠ‘åˆ¶ï¼Œè¿‡æ»¤é‡å çš„æ£€æµ‹æ¡†"""
        if len(boxes) == 0:
            return []

        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]

        areas = (x2 - x1 + 1) * (y2 - y1 + 1)

        idxs = scores.argsort()[::-1]

        keep = []

        while len(idxs) > 0:
            i = idxs[0]
            keep.append(i)

            xx1 = np.maximum(x1[i], x1[idxs[1:]])
            yy1 = np.maximum(y1[i], y1[idxs[1:]])
            xx2 = np.minimum(x2[i], x2[idxs[1:]])
            yy2 = np.minimum(y2[i], y2[idxs[1:]])

            w = np.maximum(0.0, xx2 - xx1 + 1)
            h = np.maximum(0.0, yy2 - yy1 + 1)

            intersection = w * h
            iou = intersection / (areas[i] + areas[idxs[1:]] - intersection)

            mask = iou <= iou_threshold
            idxs = idxs[1:][mask]

        return keep

    def draw_fixed_contour(self, image, fixed_contour, original_size):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶å›ºå®šè½®å»“ï¼ˆæ–°å¢æ–¹æ³•ï¼‰"""
        overlay = image.copy()
        w, h = original_size

        if not fixed_contour:
            return overlay

        # è½¬æ¢ä¸ºå¯ç»˜åˆ¶çš„æ ¼å¼
        points_array = np.array(fixed_contour, dtype=np.int32).reshape((-1, 1, 2))

        # ç»˜åˆ¶è½®å»“
        cv2.drawContours(overlay, [points_array], -1, (0, 255, 255), 3)  # é’è‰²è½®å»“è¡¨ç¤ºå›ºå®šè½®å»“

        # æ ‡è®°è½®å»“èµ·ç‚¹
        if len(points_array) > 0:
            start_point = tuple(points_array[0][0])
            cv2.circle(overlay, start_point, 8, (255, 100, 0), -1)  # æ©™è“è‰²ç‚¹
            cv2.putText(overlay, "Fixed", (start_point[0] + 10, start_point[1]),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 100, 0), 2)

        # æ·»åŠ å›ºå®šè½®å»“æ ‡è®°
        cv2.putText(overlay, "Fixed Contour", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        return overlay

    def save_contour_data(self, contour_data, frame_count, is_fixed=False):
        """ä¿å­˜è½®å»“æ•°æ®åˆ°JSONæ–‡ä»¶ï¼ˆæ–°å¢æ–¹æ³•ï¼‰"""
        if contour_data is None:
            return

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        prefix = "fixed_" if is_fixed else ""
        filename = os.path.join(self.output_dir, f"{prefix}contour_{frame_count}.json")
        with open(filename, 'w') as f:
            json.dump(contour_data, f, indent=2)

        print(f"ğŸ’¾ è½®å»“æ•°æ®å·²ä¿å­˜åˆ°: {filename}")

    def detect_objects(self, frame):
        """æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡ï¼ˆæ•´åˆè½®å»“å¤„ç†å’Œå›ºå®šè½®å»“ï¼‰"""
        if not self.session or not self.calibration_complete:
            return frame, [], []

        # å¸§è®¡æ•°å™¨é€’å¢
        self.frame_counter += 1

        try:
            # ä½¿ç”¨æ›´æ–°åçš„æ¨ç†å‡½æ•°
            boxes, mask_coeffs, mask_protos, img_size = self.infer(frame)
            orig_w, orig_h = img_size
            detections = []
            world_coords = []

            # å¤„ç†è½®å»“
            contour_data = None
            if boxes:
                box = boxes[0]
                mask = mask_coeffs[0] if mask_coeffs else None

                # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
                x, y, w, h = box['bbox']
                x1 = int(max(0, min(x - w / 2, orig_w - 1)))
                y1 = int(max(0, min(y - h / 2, orig_h - 1)))
                x2 = int(max(0, min(x + w / 2, orig_w - 1)))
                y2 = int(max(0, min(y + h / 2, orig_h - 1)))

                # è®¡ç®—ä¸­å¿ƒç‚¹
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2

                # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡
                world_x, world_y, success = self.pixel_to_world_coords(center_x, center_y)

                # å¤„ç†æ©è†œå’Œè½®å»“ï¼ˆæ–°å¢è½®å»“å¤„ç†ï¼‰
                if mask is not None and mask_protos is not None:
                    contour_data, frame = self.process_contour(
                        frame, box, [mask], mask_protos, (orig_w, orig_h)
                    )

                    # ä»è½®å»“æ•°æ®ä¸­è·å–æ›´ç²¾ç¡®çš„ä¸­å¿ƒç‚¹
                    if contour_data and contour_data.get("contour_points"):
                        contour_points = np.array(contour_data["contour_points"])
                        contour_center = np.mean(contour_points, axis=0).astype(int)
                        center_x, center_y = contour_center

                        # ä½¿ç”¨è½®å»“ä¸­å¿ƒé‡æ–°è®¡ç®—ä¸–ç•Œåæ ‡
                        world_x, world_y, success = self.pixel_to_world_coords(center_x, center_y)

                        # ä¿å­˜å½“å‰è½®å»“ä½œä¸ºå›ºå®šè½®å»“çš„é€‰é¡¹
                        if self.save_as_fixed:
                            self.fixed_contour = contour_points.tolist()
                            self.save_as_fixed = False  # é‡ç½®æ ‡å¿—
                else:
                    # å¦‚æœæ²¡æœ‰æ©è†œæ•°æ®ï¼Œä½¿ç”¨è¾¹ç•Œæ¡†ç»˜åˆ¶
                    color = (0, 255, 0)  # ç»¿è‰²è¾¹æ¡†
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    label_text = f"{box['class_id']}:{box['confidence']:.2f}"
                    cv2.putText(frame, label_text, (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                # ç»˜åˆ¶ä¸­å¿ƒç‚¹å’Œåæ ‡
                cv2.circle(frame, (center_x, center_y), 5, (0, 255, 255), -1)
                if success:
                    coord_text = f"({world_x:.1f}, {world_y:.1f}) mm"
                    cv2.putText(frame, coord_text, (center_x + 10, center_y - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

                # è®°å½•æ£€æµ‹ä¿¡æ¯
                detections.append({
                    'center': (center_x, center_y),
                    'world_coords': (world_x, world_y),
                    'bbox': (x1, y1, x2, y2),
                    'label': box['class_id'],
                    'score': box['confidence'],
                    'contour': contour_data  # è½®å»“æ•°æ®
                })
                world_coords.append((world_x, world_y))

                # ä¿å­˜è½®å»“æ•°æ®
                if contour_data and self.save_contour_data:
                    self.save_contour_data(contour_data, self.frame_counter)

            # ç»˜åˆ¶å›ºå®šè½®å»“
            if self.fixed_contour:
                frame = self.draw_fixed_contour(frame, self.fixed_contour, (orig_w, orig_h))

                # ä¿å­˜å›ºå®šè½®å»“æ•°æ®
                if self.save_fixed_contour:
                    self.save_contour_data({
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                        "fixed_contour": True,
                        "contour_points": self.fixed_contour,
                        "image_size": (orig_w, orig_h)
                    }, self.frame_counter, is_fixed=True)
                    self.save_fixed_contour = False  # é‡ç½®æ ‡å¿—

            return frame, detections, world_coords

        except Exception as e:
            print(f"ç›®æ ‡æ£€æµ‹é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return frame, [], []

    def process_contour(self, image, box, masks, protos, img_size):
        """å¤„ç†è½®å»“æ•°æ®ï¼ˆåŸºäºæ–°å‡½æ•°å®ç°ï¼‰"""
        # è·å–ç›®æ ‡è¾¹ç•Œæ¡†ä¿¡æ¯
        x, y, w, h = box['bbox']
        bbox_x1 = int(x - w / 2)
        bbox_y1 = int(y - h / 2)
        bbox_x2 = int(x + w / 2)
        bbox_y2 = int(y + h / 2)
        bbox_area = w * h

        # å¤„ç†æ©è†œ
        masks_np = np.stack(masks, axis=0)
        protos_flat = protos.reshape(protos.shape[0], -1)
        mask_output = masks_np @ protos_flat
        mask_output = 1 / (1 + np.exp(-mask_output))
        mask_output = mask_output.reshape(-1, protos.shape[1], protos.shape[2])
        m = mask_output[0]
        m = cv2.resize(m, img_size, interpolation=cv2.INTER_LINEAR)

        # äºŒå€¼åŒ–æ©è†œ
        _, binary_mask = cv2.threshold(m, 0.5, 255, cv2.THRESH_BINARY)
        binary_mask = binary_mask.astype(np.uint8)
        kernel = np.ones((3, 3), np.uint8)
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

        # æŸ¥æ‰¾æ‰€æœ‰è½®å»“
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None, image

        # ç­›é€‰æœ‰æ•ˆè½®å»“
        valid_contours = []
        for contour in contours:
            contour_x, contour_y, contour_w, contour_h = cv2.boundingRect(contour)
            contour_x2 = contour_x + contour_w
            contour_y2 = contour_y + contour_h

            overlap_x1 = max(bbox_x1, contour_x)
            overlap_y1 = max(bbox_y1, contour_y)
            overlap_x2 = min(bbox_x2, contour_x2)
            overlap_y2 = min(bbox_y2, contour_y2)

            overlap_width = max(0, overlap_x2 - overlap_x1)
            overlap_height = max(0, overlap_y2 - overlap_y1)
            overlap_area = overlap_width * overlap_height

            contour_area = cv2.contourArea(contour)

            if overlap_area > 0.5 * bbox_area and 0.1 * bbox_area < contour_area < 2.0 * bbox_area:
                valid_contours.append(contour)

        if not valid_contours:
            return None, image

        # å¤„ç†ä¸»è½®å»“
        main_contour = max(valid_contours, key=cv2.contourArea)
        contour_points = []

        # è‡ªé€‚åº”è½®å»“ç®€åŒ–
        if main_contour is not None and len(main_contour) > 4:
            contour_length = cv2.arcLength(main_contour, True)
            base_epsilon = 0.005 * contour_length

            # è®¡ç®—æ›²ç‡å˜åŒ–
            curvature_scores = []
            for i in range(1, len(main_contour) - 1):
                p1 = main_contour[i - 1][0]
                p2 = main_contour[i][0]
                p3 = main_contour[i + 1][0]

                vec1 = (p1[0] - p2[0], p1[1] - p2[1])
                vec2 = (p3[0] - p2[0], p3[1] - p2[1])

                angle1 = np.arctan2(vec1[1], vec1[0])
                angle2 = np.arctan2(vec2[1], vec2[0])
                angle_diff = np.abs(np.degrees(angle1 - angle2))
                angle_diff = min(angle_diff, 360 - angle_diff)
                curvature_scores.append(angle_diff)

            # ç‚¹çº§åˆ«è‡ªé€‚åº”ç®€åŒ–
            for i in range(len(main_contour)):
                if i == 0 or i == len(main_contour) - 1:
                    contour_points.append(main_contour[i][0].tolist())
                    continue

                # è·å–å±€éƒ¨æ›²ç‡
                prev_score = curvature_scores[i - 1] if i >= 1 else 0
                curr_score = curvature_scores[i] if i < len(curvature_scores) else 0
                max_curvature = max(prev_score, curr_score)

                epsilon = base_epsilon
                if max_curvature < 60:
                    start_idx = max(0, i - 1)
                    end_idx = min(len(main_contour), i + 2)
                    segment = main_contour[start_idx:end_idx]

                    if len(segment) > 2:
                        segment = segment.reshape(-1, 1, 2)
                        simplified = cv2.approxPolyDP(segment, epsilon, False)

                        if len(simplified) == 3:
                            contour_points.append(simplified[1][0].tolist())
                    else:
                        contour_points.append(main_contour[i][0].tolist())
                else:
                    contour_points.append(main_contour[i][0].tolist())
        else:
            contour_points = main_contour.squeeze().tolist()

        # ç¡®ä¿æ ¼å¼æ­£ç¡®
        if len(contour_points) > 0 and not isinstance(contour_points[0], list):
            contour_points = [contour_points]

        # === æ–°å¢: å›ºå®šé—´è·é‡‡æ · ===
        if len(contour_points) > 1:
            fixed_distance_contour = []
            # è®¡ç®—å›ºå®šè·ç¦»ç‚¹ (5åƒç´ )
            fixed_distance = 5

            # æ·»åŠ èµ·ç‚¹
            start_point = np.array(contour_points[0])
            fixed_distance_contour.append(start_point.tolist())
            segment_start = start_point
            remaining_distance = fixed_distance

            # éå†æ‰€æœ‰è½®å»“ç‚¹
            for i in range(1, len(contour_points)):
                current_point = np.array(contour_points[i])
                segment_vector = current_point - segment_start
                segment_length = np.linalg.norm(segment_vector)

                # å¦‚æœå½“å‰æ®µé•¿åº¦å¤§äºå‰©ä½™è·ç¦»
                while segment_length > remaining_distance:
                    # è®¡ç®—æ–°ç‚¹ä½ç½®
                    ratio = remaining_distance / segment_length
                    new_point = segment_start + ratio * segment_vector
                    fixed_distance_contour.append(new_point.tolist())

                    # æ›´æ–°å‰©ä½™è·ç¦»å’Œèµ·ç‚¹
                    segment_start = new_point
                    segment_vector = current_point - segment_start
                    segment_length = np.linalg.norm(segment_vector)
                    remaining_distance = fixed_distance
                else:
                    # æ›´æ–°å‰©ä½™è·ç¦»
                    remaining_distance -= segment_length
                    segment_start = current_point

            # ç¡®ä¿é—­åˆï¼ˆå¦‚æœèµ·ç‚¹å’Œç»ˆç‚¹ä¸åŒï¼‰
            if len(fixed_distance_contour) > 2:
                last_point = np.array(fixed_distance_contour[-1])
                first_point = np.array(fixed_distance_contour[0])
                distance_to_start = np.linalg.norm(last_point - first_point)

                if distance_to_start > fixed_distance * 0.5:  # å¦‚æœä¸æ¥è¿‘èµ·ç‚¹
                    segment_vector = first_point - last_point
                    segment_length = np.linalg.norm(segment_vector)

                    # æ·»åŠ ç‚¹åˆ°èµ·ç‚¹
                    while segment_length > remaining_distance:
                        ratio = remaining_distance / segment_length
                        new_point = last_point + ratio * segment_vector
                        fixed_distance_contour.append(new_point.tolist())
                        last_point = new_point
                        segment_vector = first_point - last_point
                        segment_length = np.linalg.norm(segment_vector)
                        remaining_distance = fixed_distance

                    # æ·»åŠ èµ·ç‚¹
                    fixed_distance_contour.append(first_point.tolist())

            # ä½¿ç”¨å›ºå®šé—´è·çš„ç‚¹æ›¿æ¢åŸå§‹ç‚¹
            contour_points = fixed_distance_contour
            print(f"å›ºå®šé—´è·è½®å»“ç‚¹ç”Ÿæˆ | ç‚¹æ•°: {len(contour_points)} | é—´è·: {fixed_distance}åƒç´ ")

        # åˆ›å»ºè½®å»“æ•°æ®ç»“æ„
        contour_data = {
            "confidence": box['confidence'],
            "class_id": box['class_id'],
            "bbox": box['bbox'],
            "contour_points": contour_points,
            "image_size": img_size
        }

        # å‡†å¤‡è½®å»“ç‚¹ç”¨äºç»˜åˆ¶
        contour_array = np.array(contour_points, dtype=np.int32).reshape((-1, 1, 2))

        # ç»˜åˆ¶è½®å»“
        overlay = image.copy()
        cv2.rectangle(overlay, (bbox_x1, bbox_y1), (bbox_x2, bbox_y2), (0, 255, 0), 2)
        cv2.drawContours(overlay, [contour_array], -1, (0, 0, 255), 3)

        if len(contour_points) > 0:
            start_point = tuple(map(int, contour_points[0]))
            cv2.circle(overlay, start_point, 8, (255, 0, 0), -1)
            cv2.putText(overlay, "Start", (start_point[0] + 10, start_point[1]),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        cv2.putText(overlay, f"Conf: {box['confidence']:.2f}",
                    (bbox_x1, bbox_y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # æ·»åŠ ç‚¹æ•°é‡æ˜¾ç¤º
        cv2.putText(overlay, f"Points: {len(contour_points)}",
                    (10, image.shape[0] - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        return contour_data, overlay

    def stop(self):
        """åœæ­¢æ‰€æœ‰æ“ä½œ"""
        self.stop_event.set()
        if self.receive_thread and self.receive_thread.is_alive():
            self.receive_thread.join(timeout=2.0)
        cv2.destroyAllWindows()
        print("[SYSTEM] æ‘„åƒå¤´æ£€æµ‹ç³»ç»Ÿå·²åœæ­¢")